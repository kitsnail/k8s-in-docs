# KEDAï¼šåŸºäºäº‹ä»¶é©±åŠ¨çš„ Kubernetes å¼¹æ€§ä¼¸ç¼©æ·±åº¦è§£æ

> **ä¸šåŠ¡åœºæ™¯**ï¼šAI å¤§æ¨¡å‹æ¨ç†æœåŠ¡æ‰©ç¼©å®¹  
> **è´¯ç©¿ç±»æ¯”**ï¼šé¤å…çš„ç‚¹å•å°ç¥¨æœºï¼ˆåŸºäºé˜Ÿåˆ—æ·±åº¦ï¼‰  
> **æŠ€æœ¯æ ˆ**ï¼šKubernetes (Kubespray éƒ¨ç½²) + KEDA 2.19

---

## ğŸŒ€ èºæ—‹ 1:æ¦‚å¿µå±‚ - Why/What

### æœ¬å±‚ç›®æ ‡
è®©ä½ ç”¨ä¸€å¥è¯è¯´æ¸…æ¥š:"KEDA æ˜¯ä»€ä¹ˆ?ä¸ºä»€ä¹ˆéœ€è¦å®ƒ?"

---

### 1.1 ä¸šåŠ¡ç—›ç‚¹:å½“ HPA é‡åˆ° AI æ¨ç†æœåŠ¡

**åœºæ™¯é‡ç°:æŸ AI æ¨ç†å¹³å°çš„åˆå¤œå‘Šè­¦**

å‡Œæ™¨ 2 ç‚¹,å€¼ç­ SRE æ”¶åˆ°å‘Šè­¦:

```bash
# Prometheus å‘Šè­¦æ¶ˆæ¯
[CRITICAL] inference-service: 
  - CPU: 85% (æ­£å¸¸)
  - å†…å­˜: 70% (æ­£å¸¸)
  - è¯·æ±‚é˜Ÿåˆ—ç§¯å‹: 12,000 æ¡ âš ï¸
  - P99 å»¶è¿Ÿ: 8.5s (SLO: 2s)
```

**å¥‡æ€ªçš„ç°è±¡:**
- Pod CPU/å†…å­˜éƒ½ä¸é«˜,æ ‡å‡† HPA æ²¡æœ‰è§¦å‘æ‰©å®¹
- ä½†æ¨ç†è¯·æ±‚é˜Ÿåˆ—(Redis Stream)ç§¯å‹ä¸¥é‡
- ç”¨æˆ·æŠ•è¯‰å“åº”æ…¢,ä¸šåŠ¡å—æŸ

**æ ¹å› åˆ†æ:**

| æ‰©ç¼©å®¹ä¾æ® | Kubernetes åŸç”Ÿ HPA | å®é™…ä¸šåŠ¡éœ€æ±‚ |
|-----------|---------------------|--------------|
| **è§¦å‘æŒ‡æ ‡** | CPU / å†…å­˜ | é˜Ÿåˆ—æ·±åº¦ / è¯·æ±‚ç§¯å‹é‡ |
| **é€‚ç”¨åœºæ™¯** | è®¡ç®—å¯†é›†å‹ä»»åŠ¡ | äº‹ä»¶é©±åŠ¨å‹ä»»åŠ¡(AI æ¨ç†ã€æ¶ˆæ¯å¤„ç†) |
| **æ‰©å®¹æ—¶æœº** | èµ„æºä½¿ç”¨ç‡é«˜æ—¶ | ä¸šåŠ¡è´Ÿè½½é«˜æ—¶(å¯èƒ½ CPU è¿˜å¾ˆé—²) |

**çœŸç›¸:**
AI æ¨ç†æœåŠ¡çš„ç“¶é¢ˆå¾€å¾€ä¸åœ¨è®¡ç®—èµ„æº,è€Œåœ¨:
- æ¨¡å‹åŠ è½½è€—æ—¶(é¦–æ¬¡æ¨ç†æ…¢)
- GPU æ’é˜Ÿç­‰å¾…
- ä¸‹æ¸¸ä¾èµ–å“åº”æ…¢
- **è¯·æ±‚é˜Ÿåˆ—ç§¯å‹** â† è¿™æ‰æ˜¯æ ¸å¿ƒçŸ›ç›¾

> **ç±»æ¯”ç†è§£:**  
> è¿™å°±åƒé¤å…å¨æˆ¿(Pod)çš„ç‚‰ç¶(CPU)è¿˜æ²¡æ»¡è´Ÿè·è¿è½¬,ä½†**ç‚¹å•å°ç¥¨æœº**(æ¶ˆæ¯é˜Ÿåˆ—)å·²ç»æ‰“å°å‡ºä¸€é•¿ä¸²è®¢å•,å¨å¸ˆæ¥ä¸åŠå¤„ç†ã€‚  
> ä¼ ç»Ÿ HPA åªçœ‹"ç‚‰ç¶ä½¿ç”¨ç‡",KEDA çœ‹çš„æ˜¯"å°ç¥¨æœºå¾…å¤„ç†è®¢å•æ•°"ã€‚

---

### 1.2 KEDA çš„æ ¸å¿ƒä»·å€¼ä¸»å¼ 

**KEDA = Kubernetes Event-Driven Autoscaling**

```mermaid
flowchart LR
    A["å¤–éƒ¨äº‹ä»¶æº<br/>(Redis/Kafka/SQS...)"] -->|"å®æ—¶æŒ‡æ ‡"| B["KEDA<br/>Scaler"]
    B -->|"è½¬æ¢ä¸ºæ ‡å‡†æŒ‡æ ‡"| C["Kubernetes<br/>HPA"]
    C -->|"è§¦å‘æ‰©ç¼©å®¹"| D["Pod å‰¯æœ¬æ•°<br/>(0 â†” N)"]
    
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style D fill:#fce4ec
```

**ä¸‰å¥è¯è¯´æ¸… KEDA:**

1. **æ˜¯ä»€ä¹ˆ:**  
   åœ¨ Kubernetes åŸç”Ÿ HPA ä¹‹ä¸ŠåŠ ä¸€å±‚"äº‹ä»¶æ„ŸçŸ¥èƒ½åŠ›",è®©æ‰©ç¼©å®¹ä¾æ®ä»"èµ„æºæŒ‡æ ‡"æ‹“å±•åˆ°"ä¸šåŠ¡æŒ‡æ ‡"

2. **åšä»€ä¹ˆ:**  
   ç›‘å¬å¤–éƒ¨äº‹ä»¶æº(é˜Ÿåˆ—æ·±åº¦ã€æ•°æ®åº“è¿æ¥æ•°ã€API è¯·æ±‚é€Ÿç‡...),å°†å…¶è½¬æ¢ä¸º Kubernetes HPA èƒ½ç†è§£çš„ External Metrics,é©±åŠ¨ Pod æ‰©ç¼©å®¹

3. **ç‰¹ç‚¹:**  
   - **éä¾µå…¥å¼:** ä¸æ›¿æ¢ HPA,è€Œæ˜¯å¢å¼ºå®ƒ(æ¡¥æ¥å±‚)
   - **é›¶å‰¯æœ¬èƒ½åŠ›:** æ”¯æŒç¼©å®¹åˆ° 0,æ— è¯·æ±‚æ—¶ä¸å èµ„æº
   - **ä¸°å¯Œçš„ Scaler ç”Ÿæ€:** 60+ å¼€ç®±å³ç”¨çš„äº‹ä»¶æºé€‚é…å™¨

---

### 1.3 æ¶æ„å…¨æ™¯:KEDA åœ¨ Kubernetes ä¸­çš„ä½ç½®

```mermaid
flowchart TB
    subgraph "å¤–éƒ¨ä¸–ç•Œ"
        ES1["Redis Stream<br/>(æ¨ç†è¯·æ±‚é˜Ÿåˆ—)"]
        ES2["Prometheus<br/>(ä¸šåŠ¡æŒ‡æ ‡)"]
        ES3["Kafka<br/>(æ—¥å¿—æµ)"]
    end
    
    subgraph "KEDA æ§åˆ¶å¹³é¢"
        SO["ScaledObject<br/>(æ‰©ç¼©å®¹è§„åˆ™)"]
        KO["KEDA Operator<br/>(åè°ƒå™¨)"]
        MS["Metrics Server<br/>(æŒ‡æ ‡é€‚é…å™¨)"]
    end
    
    subgraph "Kubernetes åŸç”Ÿç»„ä»¶"
        HPA["HPA<br/>(å†³ç­–å™¨)"]
        Deploy["Deployment<br/>(å·¥ä½œè´Ÿè½½)"]
    end
    
    ES1 & ES2 & ES3 -->|"1. å®æ—¶æŸ¥è¯¢"| KO
    KO -->|"2. è½¬æ¢ä¸º External Metrics"| MS
    MS -->|"3. æä¾›ç»™ HPA"| HPA
    HPA -->|"4. ä¿®æ”¹å‰¯æœ¬æ•°"| Deploy
    SO -.->|"å®šä¹‰è§„åˆ™"| KO
    
    style ES1 fill:#e3f2fd
    style ES2 fill:#e3f2fd
    style ES3 fill:#e3f2fd
    style SO fill:#fff9c4
    style KO fill:#fff3e0
    style MS fill:#fff3e0
    style HPA fill:#e8f5e9
    style Deploy fill:#f3e5f5
```

**å…³é”®ç»„ä»¶èŒè´£:**

| ç»„ä»¶ | è§’è‰² | ç±»æ¯”(é¤å…åœºæ™¯) |
|------|------|----------------|
| **ScaledObject** | å£°æ˜å¼æ‰©ç¼©å®¹è§„åˆ™ | èœå•ä¸Šçš„"æ¯ 10 ä»½è®¢å•åŠ  1 ä¸ªå¨å¸ˆ" |
| **KEDA Operator** | ç›‘å¬äº‹ä»¶æº,åè°ƒæ‰©ç¼©å®¹é€»è¾‘ | é¤å…ç»ç†,ç›¯ç€å°ç¥¨æœºå†³å®šåŠ äºº |
| **Metrics Server** | ç¿»è¯‘å¤–éƒ¨æŒ‡æ ‡ä¸º HPA èƒ½æ‡‚çš„æ ¼å¼ | æŠŠ"å¾…å¤„ç†è®¢å•æ•°"è½¬æ¢ä¸º"CPU ä½¿ç”¨ç‡ç­‰ä»·å€¼" |
| **HPA** | æ‰§è¡Œæœ€ç»ˆçš„å‰¯æœ¬æ•°è°ƒæ•´ | äººäº‹éƒ¨é—¨,å®é™…å»è°ƒé…å¨å¸ˆ |

---

### 1.4 æ ¸å¿ƒæ¦‚å¿µé€ŸæŸ¥è¡¨

| æœ¯è¯­ | å®šä¹‰ | ç¤ºä¾‹ |
|------|------|------|
| **Scaler** | è¿æ¥ç‰¹å®šäº‹ä»¶æºçš„é€‚é…å™¨ | Redis Scaler æŸ¥è¯¢é˜Ÿåˆ—æ·±åº¦ |
| **ScaledObject** | å®šä¹‰ Deployment/StatefulSet çš„æ‰©ç¼©å®¹è§„åˆ™ | ç›‘å¬ Redis,é˜Ÿåˆ— >100 æ—¶æ‰©å®¹ |
| **ScaledJob** | å®šä¹‰æ‰¹å¤„ç† Job çš„æ‰©ç¼©å®¹è§„åˆ™ | æ¯ 50 æ¡æ¶ˆæ¯åˆ›å»º 1 ä¸ª Job |
| **TriggerAuthentication** | è®¿é—®äº‹ä»¶æºçš„å‡­è¯ç®¡ç† | Redis å¯†ç å­˜å‚¨åœ¨ Secret |
| **External Metrics** | HPA çš„æ‰©å±•æŒ‡æ ‡ç±»å‹ | `redis_stream_length` |

---

### âœ… èºæ—‹ 1 éªŒæ”¶æ ‡å‡†

å®Œæˆæœ¬å±‚å,ä½ åº”è¯¥èƒ½å¤Ÿ:

- [ ] **ä¸€å¥è¯è¯´æ¸…:** KEDA æ˜¯ Kubernetes çš„äº‹ä»¶é©±åŠ¨æ‰©ç¼©å®¹å¢å¼ºå±‚,è®© Pod æ ¹æ®ä¸šåŠ¡æŒ‡æ ‡(è€Œéä»…èµ„æºæŒ‡æ ‡)è‡ªåŠ¨ä¼¸ç¼©
- [ ] **è¯†åˆ«ç—›ç‚¹:** è¯´å‡ºä¸ºä»€ä¹ˆ AI æ¨ç†æœåŠ¡ç”¨ä¼ ç»Ÿ HPA æ‰©ç¼©å®¹ä¸å¤Ÿç”¨(é˜Ÿåˆ—ç§¯å‹æ—¶ CPU å¯èƒ½è¿˜å¾ˆä½)
- [ ] **ç”»å‡ºæ¶æ„:** èƒ½æ ‡å‡º KEDA Operatorã€Metrics Serverã€HPA çš„å…³ç³»
- [ ] **ç±»æ¯”ç†è§£:** ç”¨"é¤å…å°ç¥¨æœº"ç±»æ¯”è§£é‡Šé˜Ÿåˆ—é©±åŠ¨çš„æ‰©ç¼©å®¹é€»è¾‘

---

### ğŸ”— ä¸‹ä¸€æ­¥:è®¤çŸ¥é™å‹ â†’ èºæ—‹ 2

ä½ å¯èƒ½åœ¨æƒ³:
- "KEDA æ˜¯æ€ä¹ˆæŠŠ Redis é˜Ÿåˆ—é•¿åº¦è½¬æ¢æˆ HPA èƒ½æ‡‚çš„æŒ‡æ ‡çš„?"
- "ScaledObject å’Œ HPA æ˜¯ä»€ä¹ˆå…³ç³»?ä¼šå†²çªå—?"
- "æ‰©ç¼©å®¹çš„å†³ç­–é€»è¾‘æ˜¯æ€æ ·çš„?(å¤šå¿«è§¦å‘?å¤šå¿«ç¼©å®¹?)"

**è®¤çŸ¥é™å‹:**  
ä¸ç”¨æ‹…å¿ƒå¤æ‚æ€§ã€‚ä¸‹ä¸€å±‚(èºæ—‹ 2)æˆ‘ä»¬ä¼šç”¨æ—¶åºå›¾æ‹†è§£å®Œæ•´çš„æ‰©ç¼©å®¹é“¾è·¯,è®©ä½ çœ‹æ¸…æ¯ä¸ªç»„ä»¶åœ¨ä»€ä¹ˆæ—¶æœºåšäº†ä»€ä¹ˆäº‹ã€‚æ ¸å¿ƒé€»è¾‘å…¶å®å’Œ"é¤å…ç»ç†çœ‹å°ç¥¨æœºåŠ å¨å¸ˆ"ä¸€æ ·ç›´è§‚ã€‚

**å‡†å¤‡å¥½å,ç»§ç»­èºæ—‹ 2 â†’**

---

## ğŸŒ€ èºæ—‹ 2ï¼šæœºåˆ¶å±‚ - How-åŸç†

### æœ¬å±‚ç›®æ ‡
æ­å¼€ KEDA çš„å†…éƒ¨è¿ä½œæœºåˆ¶,è®©ä½ èƒ½ç”»å‡ºå®Œæ•´çš„æ‰©ç¼©å®¹æ—¶åºå›¾ã€‚

---

### 2.1 æ‰©ç¼©å®¹å®Œæ•´æ—¶åº:ä»é˜Ÿåˆ—ç§¯å‹åˆ° Pod å¯åŠ¨

**åœºæ™¯:**  
Redis Stream ç§¯å‹äº† 500 æ¡æ¨ç†è¯·æ±‚,è§¦å‘ KEDA æ‰©å®¹

```mermaid
sequenceDiagram
    participant Redis as Redis Stream<br/>(å°ç¥¨æœº)
    participant Scaler as KEDA Scaler<br/>(æ•°å°ç¥¨)
    participant Operator as KEDA Operator<br/>(é¤å…ç»ç†)
    participant MS as Metrics Server<br/>(ç¿»è¯‘å®˜)
    participant HPA as HPA<br/>(äººäº‹éƒ¨)
    participant K8s as Kubernetes API<br/>(è°ƒåº¦ä¸­å¿ƒ)
    participant Pod as Pod<br/>(å¨å¸ˆ)
    
    Note over Redis: é˜Ÿåˆ—ç§¯å‹ 500 æ¡
    
    loop æ¯ 30 ç§’è½®è¯¢
        Operator->>Scaler: æŸ¥è¯¢ Redis é˜Ÿåˆ—æ·±åº¦
        Scaler->>Redis: XPENDING å‘½ä»¤
        Redis-->>Scaler: è¿”å›: 500 æ¡
        Scaler-->>Operator: åŸå§‹æŒ‡æ ‡: 500
    end
    
    Operator->>MS: æ¨é€ External Metric<br/>redis_stream_length=500
    
    Note over HPA: æ¯ 15 ç§’ä» Metrics Server æ‹‰å–æŒ‡æ ‡
    
    HPA->>MS: æŸ¥è¯¢ External Metric
    MS-->>HPA: redis_stream_length=500
    
    Note over HPA: è®¡ç®—æœŸæœ›å‰¯æœ¬æ•°<br/>desiredReplicas = ceil(500 / 10) = 50
    
    HPA->>K8s: ä¿®æ”¹ Deployment.spec.replicas = 50
    K8s->>Pod: åˆ›å»º 49 ä¸ªæ–° Pod<br/>(åŸæœ‰ 1 ä¸ª)
    
    Note over Pod: Pod å¯åŠ¨,å¼€å§‹æ¶ˆè´¹é˜Ÿåˆ—
    
    Note over Redis: é˜Ÿåˆ—é™è‡³ 100 æ¡
```

**å…³é”®æ—¶é—´å‚æ•°:**

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | ç±»æ¯” |
|------|-------|------|------|
| **pollingInterval** | 30s | KEDA æŸ¥è¯¢äº‹ä»¶æºçš„é¢‘ç‡ | ç»ç†å¤šä¹…çœ‹ä¸€æ¬¡å°ç¥¨æœº |
| **HPA sync period** | 15s | HPA ä» Metrics Server æ‹‰å–æŒ‡æ ‡çš„é¢‘ç‡ | äººäº‹éƒ¨å¤šä¹…é—®ä¸€æ¬¡ç»ç† |
| **cooldownPeriod** | 300s | æ‰©å®¹åçš„å†·å´æœŸ,é˜²æ­¢æŠ–åŠ¨ | æ–°å¨å¸ˆä¸Šå²—åçš„è§‚å¯ŸæœŸ |
| **scaleDownPeriod** | 300s | ç¼©å®¹çš„ç­‰å¾…æ—¶é—´ | è§£é›‡å¨å¸ˆå‰çš„è§‚æœ›æœŸ |

---

### 2.2 æ ¸å¿ƒæœºåˆ¶ 1:Scaler çš„æŒ‡æ ‡è½¬æ¢é€»è¾‘

**é—®é¢˜:**  
HPA åªè®¤è¯† `Resource Metrics`(CPU/å†…å­˜) å’Œ `External Metrics`,ä½† Redis é˜Ÿåˆ—é•¿åº¦æ€ä¹ˆå˜æˆ External Metric?

**ç­”æ¡ˆ: KEDA Metrics Server çš„ç¿»è¯‘è¿‡ç¨‹**

```mermaid
flowchart LR
    subgraph "1. Scaler æŸ¥è¯¢"
        A["Redis Scaler"] -->|"XLEN mystream"| B["Redis<br/>è¿”å›: 500"]
    end
    
    subgraph "2. æŒ‡æ ‡æ ‡å‡†åŒ–"
        B --> C["MetricValue{<br/>name: redis_stream_length<br/>value: 500<br/>timestamp: now<br/>}"]
    end
    
    subgraph "3. æ³¨å†Œä¸º External Metric"
        C --> D["Metrics Server<br/>å®ç° External Metrics API"]
    end
    
    subgraph "4. HPA æ¶ˆè´¹"
        D -->|"GET /apis/external.metrics.k8s.io/..."| E["HPA è·å– value: 500"]
    end
    
    style A fill:#fff3e0
    style D fill:#e8f5e9
```

**å®é™… API è°ƒç”¨:**

```bash
# HPA å‘ Metrics Server æŸ¥è¯¢ External Metric
GET /apis/external.metrics.k8s.io/v1beta1/namespaces/default/redis_stream_length

# Metrics Server è¿”å›
{
  "kind": "ExternalMetricValueList",
  "apiVersion": "external.metrics.k8s.io/v1beta1",
  "metadata": {},
  "items": [
    {
      "metricName": "redis_stream_length",
      "metricLabels": {
        "scaledObjectName": "inference-scaler"
      },
      "timestamp": "2026-02-07T12:00:00Z",
      "value": "500"  # â† è¿™æ˜¯ KEDA ä» Redis æŸ¥å‡ºæ¥çš„
    }
  ]
}
```

**ç±»æ¯”ç†è§£:**  
- **å°ç¥¨æœº**(Redis)æ‰“å° 500 ä»½è®¢å•
- **æ•°å°ç¥¨çš„äºº**(Scaler)æ•°å®Œåå‘Šè¯‰ç»ç†:"500 ä»½"
- **ç»ç†**(Operator)ç¿»è¯‘æˆ"ç­‰ä»· CPU ä½¿ç”¨ç‡"å‘Šè¯‰äººäº‹éƒ¨
- **äººäº‹éƒ¨**(HPA)æŒ‰æ ‡å‡†å…¬å¼è®¡ç®—éœ€è¦å¤šå°‘å¨å¸ˆ

---

### 2.3 æ ¸å¿ƒæœºåˆ¶ 2:ScaledObject ä¸ HPA çš„åä½œ

**å¸¸è§è¯¯è§£:** "ScaledObject ä¼šå’Œæ‰‹åŠ¨åˆ›å»ºçš„ HPA å†²çªå—?"

**çœŸç›¸:** KEDA è‡ªåŠ¨åˆ›å»ºå¹¶æ‰˜ç®¡ HPA,ä½ ä¸éœ€è¦æ‰‹åŠ¨åˆ›å»º

```yaml
# ä½ å†™çš„ ScaledObject
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: inference-scaler
spec:
  scaleTargetRef:
    name: inference-deployment  # â† è¦æ‰©ç¼©å®¹çš„ Deployment
  minReplicaCount: 1
  maxReplicaCount: 100
  triggers:
    - type: redis-streams
      metadata:
        address: redis:6379
        stream: inference-requests
        pendingEntriesCount: "10"  # â† æ¯ 10 æ¡æ¶ˆæ¯åˆ†é… 1 ä¸ª Pod
```

**KEDA Operator è‡ªåŠ¨åˆ›å»ºçš„ HPA:**

```yaml
# KEDA è‡ªåŠ¨ç”Ÿæˆ(ä½ çœ‹ä¸è§ä½†å®ƒåœ¨å·¥ä½œ)
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: keda-hpa-inference-scaler
  ownerReferences:
    - apiVersion: keda.sh/v1alpha1
      kind: ScaledObject
      name: inference-scaler  # â† ä»å±äº ScaledObject
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: inference-deployment
  minReplicas: 1
  maxReplicas: 100
  metrics:
    - type: External
      external:
        metric:
          name: redis_stream_length
        target:
          type: AverageValue
          averageValue: "10"  # â† å¯¹åº” pendingEntriesCount
```

**çŠ¶æ€æœº:**

```mermaid
stateDiagram-v2
    [*] --> Inactive: ScaledObject åˆ›å»º
    Inactive --> Active: æ£€æµ‹åˆ°äº‹ä»¶æºæœ‰æ•°æ®
    Active --> Inactive: é˜Ÿåˆ—ä¸ºç©ºä¸” cooldown åˆ°æœŸ
    Active --> Scaling: HPA è®¡ç®—å‰¯æœ¬æ•°
    Scaling --> Active: å‰¯æœ¬æ•°è°ƒæ•´å®Œæˆ
    
    note right of Inactive
        å‰¯æœ¬æ•° = minReplicaCount
        (é—²æ—¶å¾…å‘½)
    end note
    
    note right of Active
        å‰¯æœ¬æ•°åŠ¨æ€è°ƒæ•´
        (å¿™ç¢ŒçŠ¶æ€)
    end note
```

**ç±»æ¯”ç†è§£:**  
- **ScaledObject** = é¤å…ç»ç†çš„"æ’ç­è§„åˆ™æ‰‹å†Œ"
- **HPA** = æ‰§è¡Œæ’ç­çš„äººäº‹ç³»ç»Ÿ
- ç»ç†(KEDA)æ ¹æ®å°ç¥¨æœº(äº‹ä»¶æº)è‡ªåŠ¨æ›´æ–°æ’ç­è¡¨,äººäº‹éƒ¨(HPA)ç…§åšå³å¯

---

### 2.4 æ ¸å¿ƒæœºåˆ¶ 3:ç¼©å®¹åˆ°é›¶çš„ç‰¹æ®Šé€»è¾‘

**åœºæ™¯:**  
å‡Œæ™¨ 3 ç‚¹,æ¨ç†è¯·æ±‚é˜Ÿåˆ—ä¸ºç©º,æ˜¯å¦å¯ä»¥ç¼©å®¹åˆ° 0 ä¸ª Pod èŠ‚çœæˆæœ¬?

**KEDA çš„ç‹¬ç‰¹èƒ½åŠ›:Scale to Zero**

```mermaid
stateDiagram-v2
    [*] --> Zero: minReplicaCount=0<br/>ä¸”é˜Ÿåˆ—ä¸ºç©º
    Zero --> ScalingUp: æ£€æµ‹åˆ°æ–°æ¶ˆæ¯
    ScalingUp --> Running: Pod å¯åŠ¨å®Œæˆ
    Running --> Cooldown: é˜Ÿåˆ—æ¸…ç©º
    Cooldown --> Zero: å†·å´æœŸåˆ°æœŸ<br/>(é»˜è®¤ 300s)
    
    note right of Zero
        0 ä¸ª Pod
        æˆæœ¬ = 0
        å†·å¯åŠ¨å»¶è¿Ÿ ~30s
    end note
    
    note right of Running
        åŠ¨æ€å‰¯æœ¬æ•°
        æŒ‰å®é™…è´Ÿè½½ä»˜è´¹
    end note
```

**é…ç½®ç¤ºä¾‹:**

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: inference-scaler
spec:
  minReplicaCount: 0  # â† å…è®¸ç¼©å®¹åˆ° 0
  cooldownPeriod: 300  # â† é˜Ÿåˆ—æ¸…ç©ºåç­‰å¾… 5 åˆ†é’Ÿå†ç¼©å®¹
  triggers:
    - type: redis-streams
      metadata:
        stream: inference-requests
        lagThreshold: "5"  # â† ç§¯å‹ <5 æ¡æ—¶è§¦å‘ç¼©å®¹
```

**æƒè¡¡åˆ†æ:**

| æŒ‡æ ‡ | minReplicaCount=0 | minReplicaCount=1 |
|------|-------------------|-------------------|
| **æˆæœ¬** | ä½(é—²æ—¶æ— è´¹ç”¨) | ä¸­(è‡³å°‘ 1 ä¸ª Pod å¸¸é©») |
| **å†·å¯åŠ¨å»¶è¿Ÿ** | é«˜(é¦–ä¸ªè¯·æ±‚ç­‰å¾… Pod å¯åŠ¨,~30s) | ä½(ç«‹å³å“åº”) |
| **é€‚ç”¨åœºæ™¯** | é—´æ­‡æ€§ä»»åŠ¡(å¤œé—´æ‰¹å¤„ç†) | å®æ—¶æœåŠ¡(SLA ä¸¥æ ¼) |

**ç±»æ¯”ç†è§£:**  
- **minReplicaCount=0**: é¤å…æ·±å¤œå…³é—¨,å¨å¸ˆå…¨éƒ¨ä¸‹ç­,æ—©ä¸Šé¡¾å®¢æ¥äº†å†å–Šäººå›æ¥(çœé’±ä½†å¼€é—¨æ…¢)
- **minReplicaCount=1**: é¤å… 24 å°æ—¶è¥ä¸š,è‡³å°‘ç•™ 1 ä¸ªå¨å¸ˆå€¼ç­(è´¹é’±ä½†éšæ—¶èƒ½æ¥å•)

---

### 2.5 æ ¸å¿ƒæœºåˆ¶ 4:å¤šè§¦å‘å™¨çš„èšåˆé€»è¾‘

**åœºæ™¯:**  
AI æ¨ç†æœåŠ¡åŒæ—¶ç›‘å¬ Redis é˜Ÿåˆ—å’Œ Kafka æ¶ˆæ¯,å¦‚ä½•å†³ç­–æ‰©ç¼©å®¹?

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: multi-trigger-scaler
spec:
  triggers:
    - type: redis-streams
      metadata:
        stream: high-priority-requests
        pendingEntriesCount: "5"  # é«˜ä¼˜å…ˆçº§:æ¯ 5 æ¡ 1 ä¸ª Pod
    - type: kafka
      metadata:
        topic: batch-requests
        lagThreshold: "100"  # æ‰¹é‡ä»»åŠ¡:æ¯ 100 æ¡ 1 ä¸ª Pod
```

**èšåˆç­–ç•¥:**

```mermaid
flowchart TD
    A["Redis Scaler<br/>è®¡ç®—: éœ€è¦ 20 ä¸ª Pod"] --> C["å–æœ€å¤§å€¼"]
    B["Kafka Scaler<br/>è®¡ç®—: éœ€è¦ 15 ä¸ª Pod"] --> C
    C --> D["æœ€ç»ˆå‰¯æœ¬æ•°: max(20, 15) = 20"]
    
    style C fill:#fff3e0
```

**å†³ç­–å…¬å¼:**

```python
# KEDA å†…éƒ¨é€»è¾‘(ç®€åŒ–ç‰ˆ)
def calculate_replicas(triggers):
    replica_counts = []
    for trigger in triggers:
        metric_value = trigger.get_metric()  # æŸ¥è¯¢äº‹ä»¶æº
        threshold = trigger.metadata['threshold']
        replicas = ceil(metric_value / threshold)
        replica_counts.append(replicas)
    
    return max(replica_counts)  # â† å–æœ€å¤§å€¼,ç¡®ä¿æ»¡è¶³æ‰€æœ‰è§¦å‘å™¨

# ç¤ºä¾‹
# Redis: 100 æ¡æ¶ˆæ¯ / 5 = 20 ä¸ª Pod
# Kafka: 1500 æ¡æ¶ˆæ¯ / 100 = 15 ä¸ª Pod
# æœ€ç»ˆ: max(20, 15) = 20 ä¸ª Pod
```

**ç±»æ¯”ç†è§£:**  
- é¤å…åŒæ—¶æ¥æ”¶"å ‚é£Ÿè®¢å•"(Redis)å’Œ"å¤–å–è®¢å•"(Kafka)
- ç»ç†åˆ†åˆ«è®¡ç®—ä¸¤ç§è®¢å•éœ€è¦çš„å¨å¸ˆæ•°
- å–è¾ƒå¤§å€¼æ’ç­,ç¡®ä¿ä¸¤è¾¹éƒ½ä¸å»¶è¯¯

---

### âœ… èºæ—‹ 2 éªŒæ”¶æ ‡å‡†

å®Œæˆæœ¬å±‚å,ä½ åº”è¯¥èƒ½å¤Ÿ:

- [ ] **ç”»å‡ºæ—¶åºå›¾:** ä»äº‹ä»¶æºç§¯å‹åˆ° Pod å¯åŠ¨çš„å®Œæ•´æµç¨‹,æ ‡æ³¨å…³é”®æ—¶é—´å‚æ•°
- [ ] **ç†è§£ç¿»è¯‘æœºåˆ¶:** è§£é‡Š Scaler å¦‚ä½•æŠŠ Redis é˜Ÿåˆ—é•¿åº¦è½¬æ¢ä¸º HPA çš„ External Metric
- [ ] **åŒºåˆ†èŒè´£:** è¯´å‡º ScaledObject å’Œ HPA çš„å…³ç³»(KEDA è‡ªåŠ¨åˆ›å»ºå¹¶æ‰˜ç®¡ HPA)
- [ ] **ç®—å‡ºå‰¯æœ¬æ•°:** ç»™å®šé˜Ÿåˆ—é•¿åº¦å’Œé˜ˆå€¼,æ‰‹åŠ¨è®¡ç®—æœŸæœ›å‰¯æœ¬æ•°
- [ ] **æƒè¡¡å†³ç­–:** è¯´å‡º minReplicaCount=0 çš„åˆ©å¼Šå’Œé€‚ç”¨åœºæ™¯

---

### ğŸ”— ä¸‹ä¸€æ­¥:å®æˆ˜å‡†å¤‡ â†’ èºæ—‹ 3

ç°åœ¨ä½ å·²ç»ç†è§£äº† KEDA çš„å·¥ä½œåŸç†,ä¸‹ä¸€å±‚æˆ‘ä»¬å°†è¿›å…¥ç”Ÿäº§å®æˆ˜:
- å¦‚ä½•ç¼–å†™ç”Ÿäº§çº§ ScaledObject é…ç½®?
- å¸¸è§æ•…éšœåœºæ™¯çš„æ’æŸ¥æ€è·¯?(æ‰©å®¹ä¸ç”Ÿæ•ˆã€æŒ‡æ ‡é‡‡é›†å¤±è´¥...)
- å¦‚ä½•ç›‘æ§ KEDA æœ¬èº«çš„å¥åº·çŠ¶æ€?
- å¦‚ä½•è®¾è®¡åˆç†çš„æ‰©ç¼©å®¹ç­–ç•¥é¿å…æŠ–åŠ¨?

**å‡†å¤‡å¥½å,ç»§ç»­èºæ—‹ 3 â†’**

---

## ğŸŒ€ èºæ—‹ 3ï¼šå®æˆ˜å±‚ - How-è¿ç»´

### æœ¬å±‚ç›®æ ‡
è®©ä½ å…·å¤‡ç”Ÿäº§ç¯å¢ƒé…ç½® KEDA å’Œæ’éšœçš„å®æˆ˜èƒ½åŠ›ã€‚

---

### 3.1 ç”Ÿäº§çº§ ScaledObject é…ç½®æ¸…å•

**åœºæ™¯:**  
ä¸º AI æ¨ç†æœåŠ¡é…ç½®é«˜å¯ç”¨çš„äº‹ä»¶é©±åŠ¨æ‰©ç¼©å®¹

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: inference-scaler
  namespace: ai-inference
  annotations:
    # è°ƒè¯•æ—¶æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
    autoscaling.keda.sh/paused: "false"
spec:
  # 1. ç›®æ ‡å·¥ä½œè´Ÿè½½
  scaleTargetRef:
    name: inference-deployment
    kind: Deployment
    apiVersion: apps/v1
  
  # 2. å‰¯æœ¬æ•°è¾¹ç•Œ(æ ¹æ®æˆæœ¬å’Œ SLA æƒè¡¡)
  minReplicaCount: 2           # â† ç”Ÿäº§å»ºè®® â‰¥2(é«˜å¯ç”¨)
  maxReplicaCount: 100         # â† è®¾ç½®ä¸Šé™é˜²æ­¢æˆæœ¬å¤±æ§
  
  # 3. æ‰©ç¼©å®¹è¡Œä¸ºè°ƒä¼˜
  pollingInterval: 15          # æŸ¥è¯¢é¢‘ç‡(ç§’),é»˜è®¤ 30
  cooldownPeriod: 180          # æ‰©å®¹åå†·å´æœŸ(ç§’),é»˜è®¤ 300
  
  advanced:
    restoreToOriginalReplicaCount: false  # åˆ é™¤ ScaledObject åä¸æ¢å¤åŸå‰¯æœ¬æ•°
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 300  # ç¼©å®¹è§‚å¯Ÿçª—å£,é˜²æ­¢æŠ–åŠ¨
          policies:
            - type: Percent
              value: 50        # æ¯æ¬¡æœ€å¤šç¼©å®¹ 50%
              periodSeconds: 60
            - type: Pods
              value: 5         # æ¯æ¬¡æœ€å¤šç¼©å®¹ 5 ä¸ª Pod
              periodSeconds: 60
          selectPolicy: Min    # å–ä¿å®ˆç­–ç•¥
        scaleUp:
          stabilizationWindowSeconds: 0   # æ‰©å®¹ç«‹å³ç”Ÿæ•ˆ
          policies:
            - type: Percent
              value: 100       # æ¯æ¬¡æœ€å¤šæ‰©å®¹ 100%(ç¿»å€)
              periodSeconds: 15
            - type: Pods
              value: 20        # æ¯æ¬¡æœ€å¤šæ‰©å®¹ 20 ä¸ª Pod
              periodSeconds: 15
          selectPolicy: Max    # å–æ¿€è¿›ç­–ç•¥
  
  # 4. è§¦å‘å™¨é…ç½®
  triggers:
    - type: redis-streams
      metadata:
        address: redis-cluster.middleware.svc.cluster.local:6379
        stream: inference-requests
        consumerGroup: inference-workers
        pendingEntriesCount: "10"  # æ¯ 10 æ¡æ¶ˆæ¯åˆ†é… 1 ä¸ª Pod
        streamLength: "50"         # å¤‡ç”¨æŒ‡æ ‡:é˜Ÿåˆ—æ€»é•¿åº¦
      authenticationRef:
        name: redis-auth           # å¼•ç”¨å‡­è¯
  
  # 5. å›é€€é…ç½®(Scaler æ•…éšœæ—¶çš„ä¿åº•ç­–ç•¥)
  fallback:
    failureThreshold: 3            # è¿ç»­å¤±è´¥ 3 æ¬¡è§¦å‘å›é€€
    replicas: 5                    # å›é€€åˆ°å›ºå®šå‰¯æœ¬æ•°
```

**é…ç½®æƒè¡¡åˆ†æ:**

| å‚æ•° | æ¿€è¿›å€¼ | ä¿å®ˆå€¼ | æ¨è(ç”Ÿäº§) |
|------|--------|--------|-----------|
| **pollingInterval** | 5s | 60s | 15-30s(å¹³è¡¡å®æ—¶æ€§å’Œ API å‹åŠ›) |
| **cooldownPeriod** | 60s | 600s | 180-300s(é¿å…é¢‘ç¹æ‰©ç¼©) |
| **scaleUp rate** | 200%/15s | 10%/60s | 100%/15s(å¿«é€Ÿå“åº”æµé‡) |
| **scaleDown rate** | 50%/15s | 10%/300s | 50%/60s(ç¼“æ…¢é‡Šæ”¾èµ„æº) |

**ç±»æ¯”ç†è§£:**  
- **æ¿€è¿›ç­–ç•¥**: é¤å…ä¸€æœ‰è®¢å•å°±ç«‹åˆ»å–Šå¨å¸ˆ,ä¸€æ²¡è®¢å•å°±è®©äººå›å®¶(ååº”å¿«ä½†æŠ˜è…¾äºº)
- **ä¿å®ˆç­–ç•¥**: è®¢å•å †ç§¯ä¸€ä¼šå„¿å†åŠ äºº,ç©ºé—²å¾ˆä¹…æ‰è£äºº(ç¨³å®šä½†å¯èƒ½å»¶è¯¯)
- **ç”Ÿäº§æ¨è**: æ‰©å®¹å¿«ã€ç¼©å®¹æ…¢(å®å¯å¤šä»˜ç‚¹é’±,ä¸èƒ½è®©é¡¾å®¢ç­‰)

---

### 3.2 è®¤è¯é…ç½®:TriggerAuthentication

**åœºæ™¯:**  
Redis éœ€è¦å¯†ç è®¤è¯,å¦‚ä½•å®‰å…¨é…ç½®?

```yaml
# æ–¹å¼ 1:ä½¿ç”¨ Kubernetes Secret(æ¨è)
---
apiVersion: v1
kind: Secret
metadata:
  name: redis-password
  namespace: ai-inference
type: Opaque
stringData:
  password: "MySecurePassword123"

---
apiVersion: keda.sh/v1alpha1
kind: TriggerAuthentication
metadata:
  name: redis-auth
  namespace: ai-inference
spec:
  secretTargetRef:
    - parameter: password      # â† Scaler å‚æ•°å
      name: redis-password     # â† Secret åç§°
      key: password            # â† Secret ä¸­çš„ key

---
# åœ¨ ScaledObject ä¸­å¼•ç”¨
triggers:
  - type: redis-streams
    authenticationRef:
      name: redis-auth
```

**å…¶ä»–è®¤è¯æ–¹å¼:**

| æ–¹å¼ | é€‚ç”¨åœºæ™¯ | å®‰å…¨æ€§ |
|------|----------|--------|
| **Secret** | é€šç”¨,ç®€å• | ä¸­(ä¾èµ– RBAC) |
| **Azure Workload Identity** | Azure AKS | é«˜(æ— å¯†é’¥) |
| **AWS IRSA** | AWS EKS | é«˜(IAM è§’è‰²) |
| **GCP Workload Identity** | Google GKE | é«˜(æœåŠ¡è´¦å·) |
| **Vault** | å¤šäº‘,ä¼ä¸šçº§ | é«˜(åŠ¨æ€å¯†é’¥) |

---

### 3.3 ç›‘æ§ä¸å¯è§‚æµ‹æ€§

**3.3.1 KEDA è‡ªèº«çš„å¥åº·æŒ‡æ ‡**

```yaml
# KEDA Operator æš´éœ² Prometheus æŒ‡æ ‡
apiVersion: v1
kind: Service
metadata:
  name: keda-operator-metrics
  namespace: keda
spec:
  selector:
    app: keda-operator
  ports:
    - port: 8080
      name: metrics
```

**å…³é”®æŒ‡æ ‡:**

| æŒ‡æ ‡ | å«ä¹‰ | å‘Šè­¦é˜ˆå€¼ |
|------|------|----------|
| `keda_scaler_errors_total` | Scaler æŸ¥è¯¢å¤±è´¥æ¬¡æ•° | >10/min |
| `keda_scaled_object_errors` | ScaledObject é”™è¯¯æ•° | >0 |
| `keda_metrics_adapter_scaler_metric_value` | Scaler é‡‡é›†çš„åŸå§‹æŒ‡æ ‡å€¼ | ç”¨äºéªŒè¯æ•°æ®å‡†ç¡®æ€§ |
| `keda_internal_scale_loop_latency` | æ‰©ç¼©å®¹å†³ç­–å»¶è¿Ÿ | >10s |

**Prometheus å‘Šè­¦è§„åˆ™ç¤ºä¾‹:**

```yaml
groups:
  - name: keda_alerts
    rules:
      - alert: KEDAScalerHighErrorRate
        expr: rate(keda_scaler_errors_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "KEDA Scaler {{ $labels.scaler }} é”™è¯¯ç‡è¿‡é«˜"
          description: "è¿‡å» 5 åˆ†é’Ÿé”™è¯¯ç‡ {{ $value }}/s"
      
      - alert: KEDAMetricValueStale
        expr: |
          (time() - keda_metrics_adapter_scaler_metric_value_timestamp) > 300
        labels:
          severity: critical
        annotations:
          summary: "KEDA æŒ‡æ ‡ {{ $labels.metric }} è¶…è¿‡ 5 åˆ†é’Ÿæœªæ›´æ–°"
```

---

### 3.4 å¸¸è§æ•…éšœæ’æŸ¥å†³ç­–æ ‘

```mermaid
flowchart TD
    Start["æ‰©ç¼©å®¹ä¸ç¬¦åˆé¢„æœŸ"] --> Q1{"HPA æ˜¯å¦å­˜åœ¨?"}
    Q1 -->|å¦| Fix1["æ£€æŸ¥ ScaledObject çŠ¶æ€<br/>kubectl get scaledobject"]
    Q1 -->|æ˜¯| Q2{"HPA å‰¯æœ¬æ•°æ˜¯å¦æ­£ç¡®?"}
    
    Q2 -->|å¦| Q3{"HPA èƒ½è·å– External Metric?"}
    Q3 -->|å¦| Fix2["æ£€æŸ¥ Metrics Server<br/>kubectl get apiservice"]
    Q3 -->|æ˜¯| Fix3["æ£€æŸ¥ HPA é…ç½®<br/>kubectl describe hpa"]
    
    Q2 -->|æ˜¯| Q4{"Pod æ˜¯å¦æˆåŠŸå¯åŠ¨?"}
    Q4 -->|å¦| Fix4["æ£€æŸ¥èŠ‚ç‚¹èµ„æº<br/>kubectl describe node"]
    Q4 -->|æ˜¯| Fix5["æ£€æŸ¥åº”ç”¨æ—¥å¿—<br/>ä¸šåŠ¡å±‚é—®é¢˜"]
    
    Fix1 --> End["è§£å†³"]
    Fix2 --> End
    Fix3 --> End
    Fix4 --> End
    Fix5 --> End
    
    style Start fill:#ffcdd2
    style End fill:#c8e6c9
```

**æ•…éšœæ¡ˆä¾‹ 1:æ‰©å®¹ä¸ç”Ÿæ•ˆ**

```bash
# 1. æ£€æŸ¥ ScaledObject çŠ¶æ€
kubectl get scaledobject inference-scaler -n ai-inference

# æ­£å¸¸è¾“å‡º:
# NAME                SCALETARGETKIND      SCALETARGETNAME          MIN   MAX   TRIGGERS   READY
# inference-scaler    apps/v1.Deployment   inference-deployment     2     100   1          True

# å¼‚å¸¸çŠ¶æ€:
# READY=False â† è¯´æ˜æœ‰é—®é¢˜

# 2. æŸ¥çœ‹è¯¦ç»†é”™è¯¯
kubectl describe scaledobject inference-scaler -n ai-inference

# å¸¸è§é”™è¯¯ä¿¡æ¯:
# - "unable to get external metric": Metrics Server æœªå°±ç»ª
# - "error getting scaler": äº‹ä»¶æºè¿æ¥å¤±è´¥(ç½‘ç»œ/è®¤è¯)
# - "scaled object is paused": è¢«æ‰‹åŠ¨æš‚åœäº†

# 3. æŸ¥çœ‹ KEDA Operator æ—¥å¿—
kubectl logs -n keda deploy/keda-operator --tail=100 | grep inference-scaler

# å…³é”®æ—¥å¿—:
# - "Error getting metric": Scaler æŸ¥è¯¢å¤±è´¥
# - "Successfully scaled": æ‰©ç¼©å®¹æˆåŠŸ
```

**æ•…éšœæ¡ˆä¾‹ 2:æŒ‡æ ‡é‡‡é›†å¤±è´¥**

```bash
# 1. éªŒè¯ Metrics Server å¥åº·
kubectl get apiservice v1beta1.external.metrics.k8s.io

# è¾“å‡ºåº”ä¸º Available=True
# NAME                                   SERVICE               AVAILABLE
# v1beta1.external.metrics.k8s.io        keda/keda-metrics     True

# 2. æ‰‹åŠ¨æŸ¥è¯¢ External Metric
kubectl get --raw "/apis/external.metrics.k8s.io/v1beta1/namespaces/ai-inference/redis_stream_length" | jq

# æ­£å¸¸è¾“å‡º:
# {
#   "kind": "ExternalMetricValueList",
#   "items": [{"value": "123"}]
# }

# 3. æµ‹è¯•äº‹ä»¶æºè¿é€šæ€§(ä»¥ Redis ä¸ºä¾‹)
kubectl run redis-test --rm -it --image=redis:7 -- redis-cli -h redis-cluster.middleware.svc.cluster.local PING

# åº”è¿”å› PONG
```

**æ•…éšœæ¡ˆä¾‹ 3:æ‰©ç¼©å®¹æŠ–åŠ¨**

**ç—‡çŠ¶:**  
å‰¯æœ¬æ•°é¢‘ç¹åœ¨ 10 â†” 20 ä¹‹é—´éœ‡è¡

**æ ¹å› :**  
- cooldownPeriod å¤ªçŸ­
- ä¸šåŠ¡æŒ‡æ ‡æœ¬èº«æ³¢åŠ¨å¤§
- é˜ˆå€¼è®¾ç½®ä¸åˆç†

**è§£å†³æ–¹æ¡ˆ:**

```yaml
# è°ƒæ•´ HPA behavior
advanced:
  horizontalPodAutoscalerConfig:
    behavior:
      scaleDown:
        stabilizationWindowSeconds: 600  # â† å¢åŠ åˆ° 10 åˆ†é’Ÿ
        policies:
          - type: Percent
            value: 10                     # â† ç¼©å®¹æ›´ä¿å®ˆ
            periodSeconds: 120
```

**ç±»æ¯”ç†è§£:**  
æŠ–åŠ¨å°±åƒé¤å…ç»ç†ç¥ç»è´¨åœ°ä¸€ä¼šå„¿å–Šäººæ¥ä¸€ä¼šå„¿è®©äººèµ°,è§£å†³åŠæ³•æ˜¯"åŠ äººå¿«ã€å‡äººæ…¢ã€å¤šè§‚å¯Ÿå†å†³å®š"ã€‚

---

### 3.5 ç”Ÿäº§æœ€ä½³å®è·µ

| ç»´åº¦ | å»ºè®® | åæ¨¡å¼ |
|------|------|--------|
| **å‰¯æœ¬æ•°ä¸‹é™** | minReplicaCount â‰¥ 2(é«˜å¯ç”¨) | minReplicaCount=0(é™¤éæ‰¹å¤„ç†) |
| **ç›‘æ§è¦†ç›–** | åŒæ—¶ç›‘æ§ KEDA æŒ‡æ ‡å’Œä¸šåŠ¡æŒ‡æ ‡ | åªçœ‹ Pod æ•°é‡ |
| **å›é€€ç­–ç•¥** | é…ç½® fallback é˜²æ­¢ Scaler æ•…éšœ | æ— å®¹é”™æœºåˆ¶ |
| **æƒé™æœ€å°åŒ–** | TriggerAuthentication ç”¨ä¸“å± Secret | å…±äº«é€šç”¨å‡­è¯ |
| **æ‰©ç¼©é€Ÿç‡** | æ‰©å®¹å¿«(100%/15s)ã€ç¼©å®¹æ…¢(10%/60s) | æ‰©ç¼©é€Ÿç‡ä¸€è‡´ |
| **æµ‹è¯•éªŒè¯** | å‹æµ‹éªŒè¯æ‰©å®¹é€Ÿåº¦æ»¡è¶³ SLA | ç›´æ¥ä¸Šç”Ÿäº§ |

---

### 3.6 SLI/SLO è®¾è®¡

**é’ˆå¯¹ AI æ¨ç†æœåŠ¡çš„å¯é æ€§ç›®æ ‡:**

| æŒ‡æ ‡(SLI) | ç›®æ ‡(SLO) | å®ç°æ–¹å¼ |
|-----------|-----------|----------|
| **P99 è¯·æ±‚å»¶è¿Ÿ** | <2s | é˜Ÿåˆ—ç§¯å‹ <50 æ¡æ—¶è§¦å‘æ‰©å®¹ |
| **æ‰©å®¹å“åº”æ—¶é—´** | <60s | pollingInterval=15s + å¿«é€Ÿæ‰©å®¹ç­–ç•¥ |
| **æˆæœ¬æ•ˆç‡** | å¹³å‡ CPU åˆ©ç”¨ç‡ >50% | cooldownPeriod=300s é¿å…è¿‡æ—©ç¼©å®¹ |
| **é«˜å¯ç”¨æ€§** | 99.9% å¯ç”¨æ€§ | minReplicaCount â‰¥ 2 |

**ç›‘æ§ Dashboard ç¤ºä¾‹(Grafana):**

```promql
# é˜Ÿåˆ—æ·±åº¦
keda_metrics_adapter_scaler_metric_value{metric="redis_stream_length"}

# å®é™…å‰¯æœ¬æ•° vs æœŸæœ›å‰¯æœ¬æ•°
kube_deployment_status_replicas_available{deployment="inference-deployment"}
kube_deployment_spec_replicas{deployment="inference-deployment"}

# P99 å»¶è¿Ÿ(éœ€ä¸šåŠ¡ä¾§åŸ‹ç‚¹)
histogram_quantile(0.99, rate(inference_request_duration_seconds_bucket[5m]))
```

---

### âœ… èºæ—‹ 3 éªŒæ”¶æ ‡å‡†

å®Œæˆæœ¬å±‚å,ä½ åº”è¯¥èƒ½å¤Ÿ:

- [ ] **å†™å‡ºç”Ÿäº§é…ç½®:** ç‹¬ç«‹ç¼–å†™åŒ…å«è®¤è¯ã€å›é€€ç­–ç•¥ã€è¡Œä¸ºè°ƒä¼˜çš„ ScaledObject
- [ ] **æ’æŸ¥æ•…éšœ:** ä½¿ç”¨å†³ç­–æ ‘è¯Šæ–­"æ‰©å®¹ä¸ç”Ÿæ•ˆ"é—®é¢˜,å®šä½æ˜¯ Scaler/Metrics Server/HPA å“ªå±‚æ•…éšœ
- [ ] **è®¾è®¡ç›‘æ§:** åˆ—å‡ºéœ€è¦ç›‘æ§çš„ KEDA å…³é”®æŒ‡æ ‡å’Œå‘Šè­¦é˜ˆå€¼
- [ ] **æƒè¡¡å†³ç­–:** æ ¹æ®ä¸šåŠ¡ç‰¹ç‚¹(å®æ—¶ vs æ‰¹å¤„ç†)é€‰æ‹©åˆé€‚çš„ minReplicaCount å’Œæ‰©ç¼©é€Ÿç‡
- [ ] **å®šä¹‰ SLO:** ä¸ºæ‰©ç¼©å®¹ç³»ç»Ÿè®¾è®¡å¯é‡åŒ–çš„å¯é æ€§ç›®æ ‡

---

### ğŸ”— æ€»ç»“:KEDA çš„å·¥ç¨‹åŒ–ä»·å€¼

**ä¸‰å±‚èºæ—‹å›é¡¾:**

| èºæ—‹ | æ ¸å¿ƒæ”¶è· | ç±»æ¯” |
|------|----------|------|
| ğŸŒ€ 1 æ¦‚å¿µå±‚ | KEDA æ˜¯äº‹ä»¶é©±åŠ¨çš„æ‰©ç¼©å®¹å¢å¼ºå±‚ | é¤å…ç»ç†çœ‹å°ç¥¨æœºå†³å®šåŠ äºº |
| ğŸŒ€ 2 æœºåˆ¶å±‚ | Scaler â†’ Metrics Server â†’ HPA çš„åä½œé“¾è·¯ | æ•°å°ç¥¨ â†’ ç¿»è¯‘å®˜ â†’ äººäº‹éƒ¨ |
| ğŸŒ€ 3 å®æˆ˜å±‚ | ç”Ÿäº§é…ç½®ã€æ•…éšœæ’æŸ¥ã€ç›‘æ§å‘Šè­¦ | åˆ¶å®šæ’ç­è§„åˆ™,å¤„ç†çªå‘çŠ¶å†µ |

**KEDA åœ¨ AI åœºæ™¯çš„ç‹¬ç‰¹ä»·å€¼:**

1. **æˆæœ¬ä¼˜åŒ–:** æ·±å¤œæ— æ¨ç†è¯·æ±‚æ—¶ç¼©å®¹åˆ° 0,æ¯æœˆèŠ‚çœ ~70% è®¡ç®—æˆæœ¬
2. **å¼¹æ€§å“åº”:** æ ¹æ®é˜Ÿåˆ—æ·±åº¦å®æ—¶æ‰©å®¹,P99 å»¶è¿Ÿä» 8.5s é™è‡³ 1.2s
3. **ç®€åŒ–è¿ç»´:** å£°æ˜å¼é…ç½®æ›¿ä»£æ‰‹åŠ¨æ‰©ç¼©å®¹è„šæœ¬,å‡å°‘ 90% äººå·¥ä»‹å…¥

**å‡†å¤‡å¥½å®è·µäº†å—? â†’ æŸ¥çœ‹å®Œæ•´éƒ¨ç½²ç¤ºä¾‹**

---

## æ€»ç»“ä¸å»¶ä¼¸é˜…è¯»

### æ ¸å¿ƒè¦ç‚¹é€ŸæŸ¥

**ä¸€å¥è¯æ€»ç»“:**  
KEDA è®© Kubernetes æ ¹æ®ä¸šåŠ¡æŒ‡æ ‡(é˜Ÿåˆ—æ·±åº¦ã€API è°ƒç”¨é‡...)è€Œéä»…èµ„æºæŒ‡æ ‡(CPU/å†…å­˜)è‡ªåŠ¨æ‰©ç¼©å®¹,ç‰¹åˆ«é€‚åˆäº‹ä»¶é©±åŠ¨çš„ AI æ¨ç†æœåŠ¡ã€‚

**å…³é”®æ•°å­—:**
- **60+** å¼€ç®±å³ç”¨çš„ Scaler(Redis/Kafka/SQS/Prometheus...)
- **0 â†’ N** æ”¯æŒç¼©å®¹åˆ°é›¶å’Œå¼¹æ€§æ‰©å±•
- **15s** æ¨èçš„ pollingInterval(å¹³è¡¡å®æ—¶æ€§å’Œå¼€é”€)
- **300s** æ¨èçš„ cooldownPeriod(é˜²æ­¢æ‰©ç¼©å®¹æŠ–åŠ¨)

---

### å»¶ä¼¸é˜…è¯»

1. **å®˜æ–¹æ–‡æ¡£:**  
   - KEDA Scalers å®Œæ•´åˆ—è¡¨: https://keda.sh/docs/2.19/scalers/
   - ScaledObject è§„èŒƒ: https://keda.sh/docs/2.19/reference/scaledobject-spec/

2. **è¿›é˜¶ä¸»é¢˜:**  
   - è‡ªå®šä¹‰ External Scaler å¼€å‘: https://keda.sh/docs/2.19/concepts/external-scalers/
   - ä¸ Istio é›†æˆçš„æµé‡æ„ŸçŸ¥æ‰©ç¼©å®¹: https://keda.sh/docs/2.19/integrations/istio-integration/

3. **ç›¸å…³æŠ€æœ¯å¯¹æ¯”:**  
   - KEDA vs Knative Serving: ä½•æ—¶é€‰æ‹©å“ªä¸ª?
   - HPA vs VPA vs KEDA: Kubernetes ä¸‰ç§è‡ªåŠ¨ä¼¸ç¼©å™¨çš„é€‚ç”¨åœºæ™¯

4. **AI åœºæ™¯æœ€ä½³å®è·µ:**  
   - GPU å·¥ä½œè´Ÿè½½çš„æ‰©ç¼©å®¹ç­–ç•¥(éœ€è€ƒè™‘æ¨¡å‹åŠ è½½æ—¶é—´)
   - å‘é‡æ•°æ®åº“(Milvus/Weaviate)çš„ KEDA é›†æˆæ¡ˆä¾‹

---

### å®æˆ˜æ¼”ç»ƒå»ºè®®

1. **Day 1:** åœ¨æµ‹è¯•ç¯å¢ƒéƒ¨ç½² KEDA,é…ç½®ç®€å•çš„ Redis Scaler
2. **Day 2:** ä½¿ç”¨ `kubectl` æ‰‹åŠ¨è°ƒæ•´é˜Ÿåˆ—æ·±åº¦,è§‚å¯Ÿæ‰©ç¼©å®¹è¡Œä¸º
3. **Day 3:** é…ç½® Prometheus ç›‘æ§,éªŒè¯ KEDA æŒ‡æ ‡é‡‡é›†
4. **Day 4:** æ¨¡æ‹Ÿ Scaler æ•…éšœ,æµ‹è¯• fallback æœºåˆ¶
5. **Day 5:** ç¼–å†™å‹æµ‹è„šæœ¬,éªŒè¯æ‰©å®¹é€Ÿåº¦æ˜¯å¦æ»¡è¶³ SLA

---

### ç­”ç–‘

**Q: KEDA å’Œ Kubernetes åŸç”Ÿ HPA å¯ä»¥å…±å­˜å—?**  
A: å¯ä»¥,ä½†ä¸è¦å¯¹åŒä¸€ä¸ª Deployment åŒæ—¶åˆ›å»º ScaledObject å’Œæ‰‹åŠ¨ HPA,ä¼šå†²çªã€‚KEDA ä¼šè‡ªåŠ¨åˆ›å»ºå¹¶æ‰˜ç®¡ HPAã€‚

**Q: ä¸ºä»€ä¹ˆæˆ‘çš„ ScaledObject åˆ›å»ºäº†ä½†æ²¡æœ‰æ‰©ç¼©å®¹?**  
A: æŒ‰é¡ºåºæ£€æŸ¥:  
   1. `kubectl get scaledobject` çš„ READY åˆ—æ˜¯å¦ä¸º True  
   2. äº‹ä»¶æºæ˜¯å¦å¯è¾¾(ç½‘ç»œ/è®¤è¯)  
   3. HPA æ˜¯å¦æ­£å¸¸(`kubectl get hpa`)  
   4. Metrics Server æ˜¯å¦è¿”å›æŒ‡æ ‡(`kubectl get --raw /apis/external.metrics.k8s.io/...`)

**Q: æ”¯æŒå¤šé›†ç¾¤æ‰©ç¼©å®¹å—?**  
A: KEDA æœ¬èº«æ˜¯å•é›†ç¾¤çš„,å¤šé›†ç¾¤éœ€ç»“åˆ Karmada/Open Cluster Management ç­‰æ–¹æ¡ˆã€‚

---

**ğŸ¯ ä½ å·²æŒæ¡ KEDA çš„æ ¸å¿ƒåŸç†å’Œç”Ÿäº§å®è·µ,ç°åœ¨å»ä¼˜åŒ–ä½ çš„ AI æ¨ç†æœåŠ¡å§!**
