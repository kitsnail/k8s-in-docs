# Kubernetes HPA æ·±åº¦è§£æï¼šAI æ¨ç†æœåŠ¡çš„æ™ºèƒ½æ‰©ç¼©å®¹

> **æ¡ˆä¾‹èƒŒæ™¯**ï¼šä»¥ AI å¤§æ¨¡å‹æ¨ç†æ‰©ç¼©å®¹æœåŠ¡ä¸ºåœºæ™¯  
> **è´¯ç©¿ç±»æ¯”**ï¼šè¶…å¸‚æ”¶é“¶æŸœå°çš„å¼€é—­å°ç®¡ç†  
> **æŠ€æœ¯æ ˆ**ï¼šKubernetes (Kubespray éƒ¨ç½²) + Metrics Server

---

## ğŸŒ€ èºæ—‹ 1ï¼šæ¦‚å¿µå±‚ (Why & What)

### æœ¬å±‚ç›®æ ‡

ç†è§£ HPA çš„æ ¸å¿ƒæ¦‚å¿µã€è§£å†³çš„ä¸šåŠ¡ç—›ç‚¹ï¼Œå»ºç«‹å¯¹"è‡ªåŠ¨æ‰©ç¼©å®¹"çš„ç›´è§‚è®¤çŸ¥ã€‚å¬ä¼—èƒ½å¤Ÿç”¨ä¸€å¥è¯å¤è¿° HPA æ˜¯ä»€ä¹ˆã€ä¸ºä»€ä¹ˆéœ€è¦å®ƒã€‚

---

### 1.1 ä¸šåŠ¡ç—›ç‚¹ï¼šAI æ¨ç†æœåŠ¡çš„æµé‡æ³¢åŠ¨æŒ‘æˆ˜

æƒ³è±¡ä¸€ä¸ªä¸ºä¼ä¸šå®¢æˆ·æä¾›å¤§æ¨¡å‹æ¨ç†æœåŠ¡çš„å¹³å°ï¼š

- **ç™½å¤© 9:00-18:00**ï¼šä¼ä¸šç”¨æˆ·é›†ä¸­ä½¿ç”¨ï¼Œè¯·æ±‚é‡è¾¾åˆ° **5000 QPS**
- **å¤œé—´ 22:00-06:00**ï¼šå‡ ä¹æ— è¯·æ±‚ï¼Œæµé‡é™è‡³ **50 QPS**
- **çªå‘åœºæ™¯**ï¼šè¥é”€æ´»åŠ¨æœŸé—´ï¼Œæµé‡çªå¢è‡³ **10000 QPS**

#### ç—›ç‚¹åˆ†æ

| åœºæ™¯ | å›ºå®šå‰¯æœ¬æ•°çš„é—®é¢˜ | ä¸šåŠ¡å½±å“ |
|------|----------------|----------|
| **æµé‡ä½è°·æœŸ** | å¤§é‡ Pod ç©ºé—²ï¼Œèµ„æºæµªè´¹ | æˆæœ¬æµªè´¹ 60-80% |
| **æµé‡é«˜å³°æœŸ** | Pod ä¸è¶³ï¼Œè¯·æ±‚è¶…æ—¶/å¤±è´¥ | ç”¨æˆ·ä½“éªŒå·®ï¼Œæ½œåœ¨æµå¤± |
| **çªå‘æµé‡** | æ‰‹åŠ¨æ‰©å®¹å“åº”æ…¢ï¼ˆ5-10 åˆ†é’Ÿï¼‰ | é”™å¤±ä¸šåŠ¡æœºä¼š |

---

### 1.2 è¶…å¸‚æ”¶é“¶æŸœå°ç±»æ¯”

æŠŠ **AI æ¨ç†æœåŠ¡çš„ Pod** ç±»æ¯”ä¸º **è¶…å¸‚çš„æ”¶é“¶æŸœå°**ï¼š

#### åœºæ™¯å¯¹ç…§è¡¨

| è¶…å¸‚åœºæ™¯ | Kubernetes åœºæ™¯ |
|---------|----------------|
| é¡¾å®¢æ’é˜Ÿç»“è´¦ | ç”¨æˆ·è¯·æ±‚æ¨ç†æœåŠ¡ |
| æ”¶é“¶å‘˜ï¼ˆæŸœå°ï¼‰ | Pod å‰¯æœ¬ |
| æ’é˜Ÿæ—¶é•¿ | è¯·æ±‚å“åº”å»¶è¿Ÿ |
| åº—é•¿è°ƒåº¦å¼€é—­å° | HPA æ§åˆ¶å™¨ |
| æŸœå°æ•°é‡ä¸Šä¸‹é™ | minReplicas / maxReplicas |

#### æ™ºèƒ½å¼€é—­å°ç­–ç•¥

```
ğŸ“Š è¶…å¸‚åº—é•¿çš„å†³ç­–é€»è¾‘ï¼š
   - æ¯ä¸ªæŸœå°å¹³å‡æ’é˜Ÿ > 5 äºº â†’ å¼€æ–°æŸœå°
   - æ‰€æœ‰æŸœå°å¹³å‡æ’é˜Ÿ < 2 äºº â†’ å…³é—­ç©ºé—²æŸœå°
   - æœ€å°‘ä¿ç•™ 3 ä¸ªæŸœå°ï¼ˆåº”å¯¹çªå‘æƒ…å†µï¼‰
   - æœ€å¤šå¼€ 10 ä¸ªæŸœå°ï¼ˆç‰©ç†ç©ºé—´é™åˆ¶ï¼‰
```

è¿™æ­£æ˜¯ HPA çš„å·¥ä½œåŸç†ï¼

---

### 1.3 HPA æ ¸å¿ƒæ¦‚å¿µ

#### å®šä¹‰

**Horizontal Pod Autoscaler (HPA)** æ˜¯ Kubernetes çš„è‡ªåŠ¨æ‰©ç¼©å®¹æœºåˆ¶ï¼Œé€šè¿‡ç›‘æ§ Pod çš„èµ„æºä½¿ç”¨ç‡ï¼ˆCPU/å†…å­˜ï¼‰æˆ–è‡ªå®šä¹‰æŒ‡æ ‡ï¼ŒåŠ¨æ€è°ƒæ•´ Deployment/StatefulSet çš„å‰¯æœ¬æ•°ã€‚

#### æ ¸å¿ƒç‰¹ç‚¹

1. **æ°´å¹³æ‰©å±•**ï¼šé€šè¿‡å¢åŠ /å‡å°‘ Pod æ•°é‡æ¥è°ƒæ•´å®¹é‡ï¼ˆvs å‚ç›´æ‰©å±•ï¼šè°ƒæ•´å•ä¸ª Pod çš„èµ„æºï¼‰
2. **æŒ‡æ ‡é©±åŠ¨**ï¼šåŸºäºå®æ—¶è§‚æµ‹å€¼ï¼ˆå¦‚ CPU ä½¿ç”¨ç‡ï¼‰è‡ªåŠ¨å†³ç­–
3. **åŠ¨æ€å¹³è¡¡**ï¼šåœ¨æœåŠ¡è´¨é‡å’Œèµ„æºæˆæœ¬ä¹‹é—´å¯»æ‰¾æœ€ä¼˜ç‚¹

#### å·¥ä½œæµç¨‹æ¦‚è§ˆ

```mermaid
flowchart LR
    A[ç”¨æˆ·è¯·æ±‚å¢åŠ ] --> B[Pod CPU ä½¿ç”¨ç‡ä¸Šå‡]
    B --> C{HPA æ£€æµ‹<br/>å®é™…å€¼ vs ç›®æ ‡å€¼}
    C -->|è¶…è¿‡ç›®æ ‡| D[è®¡ç®—ç†æƒ³å‰¯æœ¬æ•°]
    D --> E[åˆ›å»ºæ–° Pod]
    E --> F[è´Ÿè½½å‡è¡¡åˆ†é…æµé‡]
    F --> G[CPU ä½¿ç”¨ç‡é™è‡³ç›®æ ‡èŒƒå›´]
    
    style C fill:#fff3e0
    style E fill:#e8f5e9
```

---

### 1.4 HPA åœ¨ AI æ¨ç†åœºæ™¯çš„ä»·å€¼

| ä»·å€¼ç»´åº¦ | å…·ä½“ä½“ç° | é‡åŒ–æŒ‡æ ‡ |
|---------|---------|---------|
| **æˆæœ¬ä¼˜åŒ–** | ä½è°·æœŸè‡ªåŠ¨ç¼©å®¹ï¼Œé‡Šæ”¾èµ„æº | èŠ‚çœ 40-60% äº‘è®¡ç®—æˆæœ¬ |
| **æ€§èƒ½ä¿éšœ** | é«˜å³°æœŸè‡ªåŠ¨æ‰©å®¹ï¼Œé¿å…æœåŠ¡é™çº§ | P99 å»¶è¿Ÿç¨³å®šåœ¨ <200ms |
| **è¿ç»´æ•ˆç‡** | æ— éœ€äººå·¥å¹²é¢„ï¼Œ24/7 è‡ªåŠ¨å“åº” | å‡å°‘ 90% æ‰©å®¹æ“ä½œå·¥å• |
| **ä¸šåŠ¡æ•æ·** | å¿«é€Ÿå“åº”çªå‘æµé‡ï¼ˆç§’çº§æ‰©å®¹ï¼‰ | æµé‡çªå¢æ—¶ 30 ç§’å†…å®Œæˆæ‰©å®¹ |

---

### âœ… èºæ—‹ 1 éªŒæ”¶æ ‡å‡†

å¬ä¼—èƒ½å¤Ÿï¼š
1. ç”¨ **è¶…å¸‚æ”¶é“¶æŸœå°** ç±»æ¯”è§£é‡Š HPA çš„å·¥ä½œåŸç†
2. åˆ—ä¸¾ **AI æ¨ç†æœåŠ¡ä½¿ç”¨ HPA çš„ 3 ä¸ªæ ¸å¿ƒä»·å€¼**
3. åŒºåˆ† **æ°´å¹³æ‰©å±•ï¼ˆHPAï¼‰** å’Œ **å‚ç›´æ‰©å±•ï¼ˆVPAï¼‰** çš„é€‚ç”¨åœºæ™¯

---

### ğŸ”— è¡”æ¥ä¸‹ä¸€å±‚

æˆ‘ä»¬å·²ç»ç†è§£äº† HPA çš„ **What** å’Œ **Why**ï¼Œä½†è¿˜æœ‰å…³é”®é—®é¢˜å¾…è§£ç­”ï¼š

- HPA å¦‚ä½•**ç²¾ç¡®è®¡ç®—**éœ€è¦å¤šå°‘ä¸ª Podï¼Ÿ
- æŒ‡æ ‡æ•°æ®ä»å“ªé‡Œæ¥ï¼ŸMetrics Server æ˜¯ä»€ä¹ˆï¼Ÿ
- æ‰©ç¼©å®¹çš„å†³ç­–ç®—æ³•æ˜¯ä»€ä¹ˆï¼Ÿä¼šä¸ä¼šé¢‘ç¹æŠ–åŠ¨ï¼Ÿ

ä¸‹ä¸€å±‚å°†æ·±å…¥ HPA çš„**åº•å±‚æœºåˆ¶**ï¼Œæ­ç¤ºè¿™äº›é—®é¢˜çš„ç­”æ¡ˆã€‚

---

## ğŸŒ€ èºæ—‹ 2ï¼šæœºåˆ¶å±‚ (How - åŸç†)

### æœ¬å±‚ç›®æ ‡

æ·±å…¥ç†è§£ HPA çš„åº•å±‚å·¥ä½œæœºåˆ¶ï¼ŒåŒ…æ‹¬æŒ‡æ ‡é‡‡é›†ã€è®¡ç®—å…¬å¼ã€æ§åˆ¶å¾ªç¯ã€ç¨³å®šæ€§ä¿éšœç­‰æ ¸å¿ƒæŠ€æœ¯ç»†èŠ‚ã€‚å¬ä¼—èƒ½å¤Ÿç”»å‡º HPA çš„å®Œæ•´å·¥ä½œæµç¨‹å›¾ï¼Œç†è§£ä¸ºä»€ä¹ˆéœ€è¦ Metrics Serverã€‚

---

### ğŸ“Œ è®¤çŸ¥é™å‹ (Decompression)

åœ¨è¿›å…¥å¤æ‚çš„æŠ€æœ¯ç»†èŠ‚å‰ï¼Œè®©æˆ‘ä»¬å›åˆ°è¶…å¸‚ç±»æ¯”ï¼š

```
ğŸª è¶…å¸‚åº—é•¿å¦‚ä½•å†³å®šå¼€å‡ ä¸ªæŸœå°ï¼Ÿ

ç¬¬ä¸€æ­¥ï¼šè§‚å¯Ÿç°çŠ¶
   â†’ åº—å‘˜æŠ¥å‘Šï¼š10 ä¸ªæŸœå°ï¼Œæ¯ä¸ªæŸœå°å¹³å‡æ’é˜Ÿ 6 äºº

ç¬¬äºŒæ­¥ï¼šè®¡ç®—ç†æƒ³çŠ¶æ€
   â†’ ç›®æ ‡ï¼šæ¯ä¸ªæŸœå°å¹³å‡ 3 äºº
   â†’ å½“å‰æ€»æ’é˜Ÿäººæ•°ï¼š10 Ã— 6 = 60 äºº
   â†’ ç†æƒ³æŸœå°æ•°ï¼š60 Ã· 3 = 20 ä¸ª

ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œè°ƒæ•´
   â†’ å¼€å¯ 10 ä¸ªæ–°æŸœå°ï¼ˆä½†ä¸èƒ½è¶…è¿‡ç‰©ç†ä¸Šé™ï¼‰
   â†’ ç­‰å¾… 5 åˆ†é’Ÿè§‚å¯Ÿæ•ˆæœï¼Œé¿å…é¢‘ç¹å¼€å…³å°

ç¬¬å››æ­¥ï¼šæŒç»­ç›‘æ§
   â†’ æ¯ 15 ç§’æ£€æŸ¥ä¸€æ¬¡æ’é˜Ÿæƒ…å†µ
   â†’ æ ¹æ®æ–°æ•°æ®é‡æ–°è®¡ç®—
```

è¿™ä¸ªç®€å•çš„é€»è¾‘ï¼Œå°±æ˜¯ HPA ç®—æ³•çš„æœ¬è´¨ï¼

---

### 2.1 HPA æ¶æ„å…¨æ™¯

#### æ ¸å¿ƒç»„ä»¶å…³ç³»å›¾

```mermaid
flowchart TB
    subgraph k8s["Kubernetes é›†ç¾¤"]
        subgraph cp["Control Plane"]
            HPA[HPA Controller<br/>æ§åˆ¶å™¨]
            APIServer[API Server<br/>API æœåŠ¡å™¨]
        end
        
        subgraph worker["Worker Nodes"]
            MS[Metrics Server<br/>æŒ‡æ ‡æœåŠ¡å™¨]
            Kubelet[Kubelet<br/>èŠ‚ç‚¹ä»£ç†]
            Pod1[Pod 1<br/>æ¨ç†æœåŠ¡]
            Pod2[Pod 2<br/>æ¨ç†æœåŠ¡]
            Pod3[Pod N<br/>æ¨ç†æœåŠ¡]
        end
    end
    
    User[ç”¨æˆ·/SRE] -->|1. åˆ›å»º HPA é…ç½®| APIServer
    Kubelet -->|2. é‡‡é›†å®¹å™¨æŒ‡æ ‡| MS
    HPA -->|3. æ¯ 15s æŸ¥è¯¢æŒ‡æ ‡| MS
    HPA -->|4. è®¡ç®—æœŸæœ›å‰¯æœ¬æ•°| HPA
    HPA -->|5. æ›´æ–° Deployment| APIServer
    APIServer -->|6. è°ƒåº¦ Pod| Pod1
    APIServer -->|6. è°ƒåº¦ Pod| Pod2
    APIServer -->|6. è°ƒåº¦ Pod| Pod3
    
    style HPA fill:#e1f5fe
    style MS fill:#fff3e0
    style APIServer fill:#f3e5f5
```

#### ç»„ä»¶èŒè´£è¡¨

| ç»„ä»¶ | ç±»æ¯”è§’è‰² | æ ¸å¿ƒèŒè´£ |
|------|---------|---------|
| **HPA Controller** | è¶…å¸‚åº—é•¿ | å†³ç­–ä¸­æ¢ï¼Œè®¡ç®—ç†æƒ³å‰¯æœ¬æ•°å¹¶æ‰§è¡Œè°ƒæ•´ |
| **Metrics Server** | åº—å‘˜ç»Ÿè®¡å‘˜ | é‡‡é›†å„ Pod çš„å®æ—¶èµ„æºä½¿ç”¨æƒ…å†µ |
| **Kubelet** | æ”¶é“¶å‘˜ | è¿è¡Œåœ¨æ¯ä¸ªèŠ‚ç‚¹ï¼Œæš´éœ²å®¹å™¨æŒ‡æ ‡ç»™ Metrics Server |
| **API Server** | æ€»éƒ¨è°ƒåº¦ç³»ç»Ÿ | æ¥æ”¶ HPA æŒ‡ä»¤ï¼Œåè°ƒ Pod åˆ›å»º/åˆ é™¤ |

---

### 2.2 HPA è®¡ç®—å…¬å¼è¯¦è§£

#### æ ¸å¿ƒå…¬å¼

HPA ä½¿ç”¨ä»¥ä¸‹å…¬å¼è®¡ç®—æœŸæœ›å‰¯æœ¬æ•°ï¼š

```
æœŸæœ›å‰¯æœ¬æ•° = ceil(å½“å‰å‰¯æœ¬æ•° Ã— (å½“å‰æŒ‡æ ‡å€¼ / ç›®æ ‡æŒ‡æ ‡å€¼))
```

#### è¶…å¸‚ç±»æ¯”è®¡ç®—å®ä¾‹

**åœºæ™¯**ï¼šAI æ¨ç†æœåŠ¡å½“å‰é…ç½®
- **å½“å‰å‰¯æœ¬æ•°**ï¼š5 ä¸ª Podï¼ˆ5 ä¸ªæ”¶é“¶å°ï¼‰
- **ç›®æ ‡ CPU ä½¿ç”¨ç‡**ï¼š50%ï¼ˆæ¯å°å¹³å‡æœåŠ¡ 3 äººï¼‰
- **å®é™… CPU ä½¿ç”¨ç‡**ï¼š80%ï¼ˆæ¯å°å¹³å‡æœåŠ¡ 5 äººï¼‰

**è®¡ç®—è¿‡ç¨‹**ï¼š

```
æ­¥éª¤ 1ï¼šè®¡ç®—å¹³å‡æŒ‡æ ‡å€¼
   å½“å‰æ€» CPU ä½¿ç”¨ï¼š5 ä¸ª Pod Ã— 80% = 400%
   
æ­¥éª¤ 2ï¼šè®¡ç®—ç†æƒ³å‰¯æœ¬æ•°
   æœŸæœ›å‰¯æœ¬æ•° = 400% Ã· 50% = 8 ä¸ª Pod
   
æ­¥éª¤ 3ï¼šå‘ä¸Šå–æ•´
   ceil(8) = 8 ä¸ª Pod
   
ç»“æœï¼šHPA å°†æ‰©å®¹åˆ° 8 ä¸ª Pod
```

#### å®é™… Kubernetes è®¡ç®—ç¤ºä¾‹

å‡è®¾ AI æ¨ç†æœåŠ¡ Deployment é…ç½®ï¼š

```yaml
resources:
  requests:
    cpu: 1000m  # æ¯ä¸ª Pod è¯·æ±‚ 1 æ ¸ CPU
```

**å½“å‰çŠ¶æ€**ï¼š
- 3 ä¸ª Pod è¿è¡Œ
- Pod 1: 800m CPU (80%)
- Pod 2: 850m CPU (85%)
- Pod 3: 750m CPU (75%)

**HPA ç›®æ ‡**ï¼šCPU ä½¿ç”¨ç‡ 50%

**HPA è®¡ç®—**ï¼š

```
å¹³å‡ CPU ä½¿ç”¨ç‡ = (80% + 85% + 75%) / 3 = 80%

æœŸæœ›å‰¯æœ¬æ•° = ceil(3 Ã— (80% / 50%))
           = ceil(3 Ã— 1.6)
           = ceil(4.8)
           = 5 ä¸ª Pod
```

**æ‰©å®¹åé¢„æœŸ**ï¼š
- æ€» CPU éœ€æ±‚ä¸å˜ï¼š2400m
- 5 ä¸ª Pod å‡æ‘Šï¼š2400m / 5 = 480m â‰ˆ 48%
- **è¾¾åˆ°ç›®æ ‡ï¼**

---

### 2.3 HPA æ§åˆ¶å¾ªç¯ï¼ˆControl Loopï¼‰

#### æ—¶åºæµç¨‹å›¾

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·/SRE
    participant HPA as HPA Controller
    participant Metrics as Metrics Server
    participant API as API Server
    participant Deploy as Deployment
    participant Pods as Pods

    User->>API: åˆ›å»º HPA å¯¹è±¡<br/>(target: 50% CPU)
    
    loop æ¯ 15 ç§’
        HPA->>Metrics: æŸ¥è¯¢ Pod æŒ‡æ ‡
        Metrics->>HPA: è¿”å›å½“å‰ CPU: 80%
        
        HPA->>HPA: è®¡ç®—æœŸæœ›å‰¯æœ¬æ•°<br/>(3 â†’ 5)
        
        alt éœ€è¦æ‰©ç¼©å®¹
            HPA->>API: æ›´æ–° Deployment.replicas=5
            API->>Deploy: åº”ç”¨å˜æ›´
            Deploy->>Pods: åˆ›å»º 2 ä¸ªæ–° Pod
            Pods-->>Metrics: æ–° Pod å¼€å§‹æš´éœ²æŒ‡æ ‡
        else å‰¯æœ¬æ•°å·²è¾¾æ ‡
            HPA->>HPA: æ— æ“ä½œï¼Œç»§ç»­ç›‘æ§
        end
    end
```

#### æ§åˆ¶å¾ªç¯å…³é”®å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¶…å¸‚ç±»æ¯” | è°ƒä¼˜å»ºè®® |
|------|-------|---------|---------|
| **æ£€æŸ¥é—´éš”** | 15 ç§’ | åº—é•¿æ¯ 15 ç§’å·¡è§†ä¸€æ¬¡ | æ¨ç†æœåŠ¡å»ºè®®ä¿æŒé»˜è®¤ |
| **æ‰©å®¹å†·å´æ—¶é—´** | 3 åˆ†é’Ÿ | å¼€å°åç­‰ 3 åˆ†é’Ÿè§‚å¯Ÿæ•ˆæœ | æµé‡æ³¢åŠ¨å¤§æ—¶å¯ç¼©çŸ­è‡³ 1 åˆ†é’Ÿ |
| **ç¼©å®¹å†·å´æ—¶é—´** | 5 åˆ†é’Ÿ | å…³å°å‰ç­‰ 5 åˆ†é’Ÿç¡®è®¤ä½å³° | é¿å…é¢‘ç¹ç¼©å®¹ï¼Œå»ºè®® 5-10 åˆ†é’Ÿ |
| **å®¹å¿åº¦** | 10% | å®é™…å€¼åœ¨ç›®æ ‡ Â±10% å†…ä¸è°ƒæ•´ | é¿å…å¾®å°æ³¢åŠ¨è§¦å‘æ‰©ç¼©å®¹ |

---

### 2.4 Metrics Server æ·±å…¥è§£æ

#### ä¸ºä»€ä¹ˆéœ€è¦ Metrics Serverï¼Ÿ

Kubernetes åŸç”Ÿåªæä¾› **èµ„æºè°ƒåº¦** èƒ½åŠ›ï¼Œä¸æä¾› **æŒ‡æ ‡é‡‡é›†** èƒ½åŠ›ã€‚Metrics Server æ˜¯æ¡¥æ¢ç»„ä»¶ï¼Œè´Ÿè´£ï¼š

1. **ä» Kubelet æŠ“å–æŒ‡æ ‡**ï¼ˆé€šè¿‡ Summary APIï¼‰
2. **èšåˆè®¡ç®—å¹³å‡å€¼**ï¼ˆè·¨æ‰€æœ‰ Podï¼‰
3. **æš´éœ² Metrics API**ï¼ˆä¾› HPA æŸ¥è¯¢ï¼‰

#### Metrics Server å·¥ä½œæµç¨‹

```mermaid
flowchart LR
    subgraph node1["Node 1"]
        K1[Kubelet]
        P1[Pod A]
        P2[Pod B]
    end
    
    subgraph node2["Node 2"]
        K2[Kubelet]
        P3[Pod C]
    end
    
    MS[Metrics Server]
    HPA[HPA Controller]
    
    P1 -->|cAdvisor é‡‡é›†| K1
    P2 -->|cAdvisor é‡‡é›†| K1
    P3 -->|cAdvisor é‡‡é›†| K2
    
    K1 -->|Summary API| MS
    K2 -->|Summary API| MS
    
    MS -->|èšåˆè®¡ç®—| MS
    MS -->|Metrics API| HPA
    
    style MS fill:#fff3e0
```

#### Metrics Server å…³é”®ç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ | AI æ¨ç†åœºæ™¯å½±å“ |
|------|------|----------------|
| **å†…å­˜å­˜å‚¨** | ä¸æŒä¹…åŒ–å†å²æ•°æ®ï¼Œä»…ä¿ç•™æœ€è¿‘ 1-2 åˆ†é’Ÿ | é€‚åˆå®æ—¶æ‰©ç¼©å®¹ï¼Œä¸é€‚åˆé•¿æœŸè¶‹åŠ¿åˆ†æ |
| **é‡‡é›†é—´éš”** | é»˜è®¤ 60 ç§’ | å†³å®š HPA çš„æ•°æ®æ–°é²œåº¦ |
| **å»¶è¿Ÿ** | é€šå¸¸ 1-2 ç§’ | å¯¹æ¨ç†æœåŠ¡å“åº”é€Ÿåº¦å½±å“å° |
| **èµ„æºå ç”¨** | è½»é‡çº§ï¼ˆ~40MB å†…å­˜ï¼‰ | é€‚åˆç”Ÿäº§ç¯å¢ƒ |

> **æ³¨æ„**ï¼šå¦‚éœ€å†å²è¶‹åŠ¿åˆ†æï¼Œåº”ä½¿ç”¨ Prometheus + Grafanaï¼Œä½† HPA ä»ä¾èµ– Metrics Serverã€‚

---

### 2.5 ç¨³å®šæ€§æœºåˆ¶ï¼šé˜²æ­¢é¢‘ç¹æŠ–åŠ¨

#### é—®é¢˜åœºæ™¯ï¼šæŠ–åŠ¨çš„å™©æ¢¦

æƒ³è±¡è¶…å¸‚åº—é•¿ç–¯ç‹‚å¼€é—­å°çš„åœºæ™¯ï¼š

```
10:00  è§‚å¯Ÿåˆ°æ’é˜Ÿäººå¤š â†’ å¼€ 5 ä¸ªæ–°å°
10:01  æ–°å°åˆšå¼€ï¼Œæ’é˜Ÿå‡å°‘ â†’ å…³ 3 ä¸ªå°
10:02  æ’é˜Ÿåˆå¢åŠ  â†’ å†å¼€ 4 ä¸ªå°
10:03  ...å¾ªç¯å¾€å¤
```

ç»“æœï¼š
- âŒ æ”¶é“¶å‘˜ç–²äºåº”å¯¹
- âŒ é¡¾å®¢ä½“éªŒæå·®
- âŒ æµªè´¹å¤§é‡è°ƒåº¦æˆæœ¬

#### HPA çš„ 4 é‡é˜²æŠ–æœºåˆ¶

##### 1. å®¹å¿åº¦ï¼ˆToleranceï¼‰

```yaml
# HPA é»˜è®¤å®¹å¿åº¦ï¼š10%
# åªæœ‰å½“å®é™…å€¼è¶…å‡ºç›®æ ‡ Â±10% æ—¶æ‰è§¦å‘è°ƒæ•´

ç›®æ ‡ CPU: 50%
è§¦å‘æ‰©å®¹ï¼š> 55%  (50% Ã— 1.1)
è§¦å‘ç¼©å®¹ï¼š< 45%  (50% Ã— 0.9)
```

**è¶…å¸‚ç±»æ¯”**ï¼šæ¯å°ç›®æ ‡ 3 äººæ’é˜Ÿï¼Œåªæœ‰åœ¨ >3.3 äººæˆ– <2.7 äººæ—¶æ‰è°ƒæ•´ã€‚

##### 2. å†·å´æ—¶é—´ï¼ˆCooldownï¼‰

```yaml
# æ‰©å®¹åå†·å´ 3 åˆ†é’Ÿ
--horizontal-pod-autoscaler-upscale-delay=3m

# ç¼©å®¹åå†·å´ 5 åˆ†é’Ÿ
--horizontal-pod-autoscaler-downscale-delay=5m
```

**åŸç†**ï¼šæ–° Pod å¯åŠ¨éœ€è¦æ—¶é—´ï¼ˆæ‹‰é•œåƒã€åˆå§‹åŒ–ï¼‰ï¼Œå†·å´æœŸç­‰å¾…ç¨³å®šåå†åˆ¤æ–­ã€‚

##### 3. ç¨³å®šçª—å£ï¼ˆStabilization Windowï¼‰

Kubernetes 1.18+ å¼•å…¥ï¼Œä½¿ç”¨å†å²æ•°æ®è€Œéå•æ¬¡æµ‹é‡å€¼ï¼š

```yaml
behavior:
  scaleDown:
    stabilizationWindowSeconds: 300  # 5 åˆ†é’Ÿ
    # é€‰æ‹©è¿‡å» 5 åˆ†é’Ÿå†…çš„æœ€é«˜æ¨èå€¼è¿›è¡Œç¼©å®¹
```

**æ•ˆæœ**ï¼šé¿å…çŸ­æš‚çš„æµé‡ä¸‹é™å¯¼è‡´è¿‡åº¦ç¼©å®¹ã€‚

##### 4. æ‰©ç¼©å®¹é€Ÿç‡é™åˆ¶

```yaml
behavior:
  scaleUp:
    policies:
    - type: Percent
      value: 100        # æ¯æ¬¡æœ€å¤šæ‰©å®¹ 100%ï¼ˆç¿»å€ï¼‰
      periodSeconds: 60 # æ¯åˆ†é’Ÿ
    - type: Pods
      value: 4          # æ¯æ¬¡æœ€å¤šå¢åŠ  4 ä¸ª Pod
      periodSeconds: 60
    selectPolicy: Max   # å–ä¸¤è€…ä¸­çš„è¾ƒå¤§å€¼
  
  scaleDown:
    policies:
    - type: Percent
      value: 50         # æ¯æ¬¡æœ€å¤šç¼©å®¹ 50%
      periodSeconds: 60
```

**è¶…å¸‚ç±»æ¯”**ï¼šå³ä½¿éœ€è¦ 20 ä¸ªå°ï¼Œä¹Ÿä¸èƒ½ä¸€æ¬¡æ€§å…¨å¼€ï¼Œåˆ†æ‰¹å¼€å¯é¿å…æ··ä¹±ã€‚

---

### 2.6 è‡ªå®šä¹‰æŒ‡æ ‡æ‰©å®¹ï¼ˆé«˜çº§ç‰¹æ€§ï¼‰

#### ä¸ºä»€ä¹ˆ CPU/å†…å­˜ä¸å¤Ÿç”¨ï¼Ÿ

AI æ¨ç†æœåŠ¡çš„çœŸå®ç“¶é¢ˆå¯èƒ½æ˜¯ï¼š
- **GPU åˆ©ç”¨ç‡**ï¼ˆå¤§æ¨¡å‹æ¨ç†ï¼‰
- **è¯·æ±‚é˜Ÿåˆ—é•¿åº¦**ï¼ˆä¸šåŠ¡æŒ‡æ ‡ï¼‰
- **æ¨ç†å»¶è¿Ÿ P99**ï¼ˆSLA æŒ‡æ ‡ï¼‰
- **å¹¶å‘è¿æ¥æ•°**ï¼ˆè´Ÿè½½å‡è¡¡å™¨æŒ‡æ ‡ï¼‰

#### è‡ªå®šä¹‰æŒ‡æ ‡æ¶æ„

```mermaid
flowchart TB
    App[æ¨ç†æœåŠ¡ Pod]
    Prom[Prometheus]
    Adapter[Prometheus Adapter]
    HPA[HPA Controller]
    
    App -->|æš´éœ²è‡ªå®šä¹‰æŒ‡æ ‡<br/>gpu_utilization| Prom
    Prom -->|å­˜å‚¨æ—¶åºæ•°æ®| Prom
    Adapter -->|æŸ¥è¯¢ PromQL| Prom
    Adapter -->|è½¬æ¢ä¸º Metrics API| Adapter
    HPA -->|æŸ¥è¯¢ custom.metrics.k8s.io| Adapter
    
    style Prom fill:#e8f5e9
    style Adapter fill:#fff3e0
```

#### è‡ªå®šä¹‰æŒ‡æ ‡ HPA ç¤ºä¾‹

åŸºäº GPU åˆ©ç”¨ç‡æ‰©å®¹ï¼š

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: llm-inference-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: llm-inference
  minReplicas: 2
  maxReplicas: 20
  metrics:
  - type: Pods
    pods:
      metric:
        name: gpu_utilization
      target:
        type: AverageValue
        averageValue: "70"  # ç›®æ ‡ GPU åˆ©ç”¨ç‡ 70%
```

**è¶…å¸‚ç±»æ¯”**ï¼šä¸ä»…çœ‹æ’é˜Ÿäººæ•°ï¼Œè¿˜è¦çœ‹æ”¶é“¶é€Ÿåº¦ï¼ˆGPU æ•ˆç‡ï¼‰ï¼

---

### âœ… èºæ—‹ 2 éªŒæ”¶æ ‡å‡†

å¬ä¼—èƒ½å¤Ÿï¼š
1. **ç”»å‡º HPA æ¶æ„å›¾**ï¼Œæ ‡æ³¨ HPA Controllerã€Metrics Serverã€Kubelet çš„èŒè´£
2. **æ‰‹ç®—å‰¯æœ¬æ•°**ï¼šç»™å®šå½“å‰å‰¯æœ¬æ•° 3ã€å®é™… CPU 80%ã€ç›®æ ‡ 50%ï¼Œè®¡ç®—å‡ºæœŸæœ›å‰¯æœ¬æ•° 5
3. **è§£é‡Šé˜²æŠ–æœºåˆ¶**ï¼šè¯´æ˜å®¹å¿åº¦ã€å†·å´æ—¶é—´ã€ç¨³å®šçª—å£çš„ä½œç”¨
4. **ç†è§£ Metrics Server**ï¼šè¯´æ˜ä¸ºä»€ä¹ˆ HPA ä¾èµ–å®ƒï¼Œä»¥åŠæ•°æ®æµå‘

---

### ğŸ”— è¡”æ¥ä¸‹ä¸€å±‚

ç°åœ¨æˆ‘ä»¬ç†è§£äº† HPA çš„ **åº•å±‚åŸç†**ï¼Œä½†åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼š

- å¦‚ä½•ç¼–å†™æ­£ç¡®çš„ HPA YAML é…ç½®ï¼Ÿ
- é‡åˆ°"æ‰©å®¹ä¸ç”Ÿæ•ˆ"ã€"é¢‘ç¹æŠ–åŠ¨"æ€ä¹ˆæ’æŸ¥ï¼Ÿ
- å¦‚ä½•ç›‘æ§ HPA çš„å¥åº·çŠ¶æ€ï¼Ÿ
- æœ‰å“ªäº›ç”Ÿäº§ç¯å¢ƒçš„æœ€ä½³å®è·µå’Œåæ¨¡å¼ï¼Ÿ

ä¸‹ä¸€å±‚å°†å¸¦ä½ èµ°è¿› **å®æˆ˜è¿ç»´**ï¼Œä» 0 åˆ° 1 éƒ¨ç½²ç”Ÿäº§çº§ HPAã€‚

---

## ğŸŒ€ èºæ—‹ 3ï¼šå®æˆ˜å±‚ (How - è¿ç»´)

### æœ¬å±‚ç›®æ ‡

æŒæ¡åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²å’Œè¿ç»´ HPA çš„å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬é…ç½®ç¼–å†™ã€æ•…éšœæ’æŸ¥ã€ç›‘æ§å‘Šè­¦ã€æœ€ä½³å®è·µã€‚å¬ä¼—èƒ½å¤Ÿç‹¬ç«‹æ’æŸ¥å¸¸è§é—®é¢˜ï¼Œå¹¶å»ºç«‹ç”Ÿäº§çº§çš„ HPA ç›‘æ§ä½“ç³»ã€‚

---

### 3.1 å‰ç½®å‡†å¤‡ï¼šéƒ¨ç½² Metrics Server

#### ç¯å¢ƒè¦æ±‚

```bash
# 1. Kubernetes ç‰ˆæœ¬è¦æ±‚
kubectl version --short
# è¦æ±‚ï¼šServer Version >= v1.19

# 2. æ£€æŸ¥é›†ç¾¤æ˜¯å¦å·²å®‰è£… Metrics Server
kubectl get deployment metrics-server -n kube-system

# å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™éœ€è¦å®‰è£…
```

#### å®‰è£… Metrics Serverï¼ˆæ ‡å‡† Kubernetesï¼‰

```bash
# æ–¹æ³• 1ï¼šä½¿ç”¨å®˜æ–¹ YAML
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# æ–¹æ³• 2ï¼šä½¿ç”¨ Helmï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰
helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/
helm upgrade --install metrics-server metrics-server/metrics-server \
  --namespace kube-system \
  --set args={--kubelet-insecure-tls}  # ä»…æµ‹è¯•ç¯å¢ƒä½¿ç”¨
```

#### éªŒè¯å®‰è£…

```bash
# ç­‰å¾… Pod å°±ç»ª
kubectl wait --for=condition=ready pod \
  -l k8s-app=metrics-server \
  -n kube-system \
  --timeout=300s

# éªŒè¯ Metrics API
kubectl top nodes
kubectl top pods -n default

# è¾“å‡ºç¤ºä¾‹ï¼š
# NAME           CPU(cores)   MEMORY(bytes)
# llm-pod-1      850m         2048Mi
# llm-pod-2      920m         2100Mi
```

---

### 3.2 å®æˆ˜é…ç½®ï¼šAI æ¨ç†æœåŠ¡ HPA

#### åœºæ™¯è®¾å®š

æŸ AI å…¬å¸çš„å¤§æ¨¡å‹æ¨ç†æœåŠ¡ï¼š
- **åŸºç¡€é•œåƒ**ï¼š`llm-inference:v1.0`ï¼ˆåŒ…å« GPT-J-6B æ¨¡å‹ï¼‰
- **èµ„æºéœ€æ±‚**ï¼šæ¯ä¸ª Pod éœ€è¦ 2 æ ¸ CPUã€4GB å†…å­˜
- **ä¸šåŠ¡ç›®æ ‡**ï¼š
  - å¹³æ—¶ä¿æŒ 3 ä¸ªå‰¯æœ¬ï¼ˆæˆæœ¬æ§åˆ¶ï¼‰
  - é«˜å³°æœŸæœ€å¤š 10 ä¸ªå‰¯æœ¬ï¼ˆå®¹é‡ä¸Šé™ï¼‰
  - CPU ä½¿ç”¨ç‡ç»´æŒåœ¨ 60%ï¼ˆæ€§èƒ½ä¸æˆæœ¬å¹³è¡¡ç‚¹ï¼‰

#### æ­¥éª¤ 1ï¼šåˆ›å»º Deployment

```yaml
# llm-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-inference
  labels:
    app: llm-inference
spec:
  replicas: 3  # åˆå§‹å‰¯æœ¬æ•°ï¼ˆå°†è¢« HPA æ¥ç®¡ï¼‰
  selector:
    matchLabels:
      app: llm-inference
  template:
    metadata:
      labels:
        app: llm-inference
    spec:
      containers:
      - name: inference
        image: llm-inference:v1.0
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 2000m      # ğŸ”‘ å…³é”®ï¼šå¿…é¡»è®¾ç½® requests
            memory: 4Gi
          limits:
            cpu: 2000m      # é™åˆ¶ CPU é˜²æ­¢å¹²æ‰°å…¶ä»– Pod
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 5
```

**âš ï¸ å…³é”®æ³¨æ„äº‹é¡¹**ï¼š
- `resources.requests` **å¿…é¡»è®¾ç½®**ï¼ŒHPA åŸºäº requests è®¡ç®—ä½¿ç”¨ç‡
- `requests` åº”æ¥è¿‘å®é™…ä½¿ç”¨é‡ï¼Œé¿å…è¿‡é«˜ï¼ˆæµªè´¹èµ„æºï¼‰æˆ–è¿‡ä½ï¼ˆé¢‘ç¹æ‰©å®¹ï¼‰

```bash
kubectl apply -f llm-deployment.yaml
```

#### æ­¥éª¤ 2ï¼šåˆ›å»º Service

```yaml
# llm-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: llm-inference
spec:
  selector:
    app: llm-inference
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  type: LoadBalancer  # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ LoadBalancer æˆ– Ingress
```

```bash
kubectl apply -f llm-service.yaml
```

#### æ­¥éª¤ 3ï¼šåˆ›å»º HPAï¼ˆåŸºç¡€ç‰ˆï¼‰

```yaml
# llm-hpa-basic.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: llm-inference-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: llm-inference
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60  # ç›®æ ‡ CPU ä½¿ç”¨ç‡ 60%
```

```bash
kubectl apply -f llm-hpa-basic.yaml
```

#### æ­¥éª¤ 4ï¼šåˆ›å»º HPAï¼ˆç”Ÿäº§çº§ï¼‰

ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®ï¼ŒåŒ…å«é˜²æŠ–å’Œé€Ÿç‡é™åˆ¶ï¼š

```yaml
# llm-hpa-production.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: llm-inference-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: llm-inference
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80  # å†…å­˜ä½¿ç”¨ç‡ 80%
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60      # æ‰©å®¹ç¨³å®šçª—å£ 1 åˆ†é’Ÿ
      policies:
      - type: Percent
        value: 100                        # æ¯æ¬¡æœ€å¤šç¿»å€
        periodSeconds: 60
      - type: Pods
        value: 3                          # æ¯æ¬¡æœ€å¤šå¢åŠ  3 ä¸ª Pod
        periodSeconds: 60
      selectPolicy: Max                   # å–è¾ƒæ¿€è¿›çš„ç­–ç•¥
    scaleDown:
      stabilizationWindowSeconds: 300     # ç¼©å®¹ç¨³å®šçª—å£ 5 åˆ†é’Ÿ
      policies:
      - type: Percent
        value: 50                         # æ¯æ¬¡æœ€å¤šç¼©å‡ 50%
        periodSeconds: 60
      - type: Pods
        value: 2                          # æ¯æ¬¡æœ€å¤šå‡å°‘ 2 ä¸ª Pod
        periodSeconds: 60
      selectPolicy: Min                   # å–è¾ƒä¿å®ˆçš„ç­–ç•¥
```

**é…ç½®è§£è¯»ï¼ˆè¶…å¸‚ç±»æ¯”ï¼‰**ï¼š
- `stabilizationWindowSeconds: 60`ï¼šå¼€å°å‰è§‚å¯Ÿ 1 åˆ†é’Ÿï¼Œç¡®è®¤ç¡®å®éœ€è¦
- `scaleUp.value: 100`ï¼šé«˜å³°æœŸå¯ä»¥å¿«é€Ÿç¿»å€å¼€å°
- `scaleDown.stabilizationWindowSeconds: 300`ï¼šå…³å°å‰ç­‰ 5 åˆ†é’Ÿï¼Œé¿å…è¯¯åˆ¤
- `scaleDown.value: 50`ï¼šç¼©å®¹ä¿å®ˆï¼Œæ¯æ¬¡æœ€å¤šå…³ä¸€åŠ

```bash
kubectl apply -f llm-hpa-production.yaml
```

---

### 3.3 éªŒè¯ä¸æµ‹è¯•

#### æŸ¥çœ‹ HPA çŠ¶æ€

```bash
# æŸ¥çœ‹ HPA å¯¹è±¡
kubectl get hpa llm-inference-hpa

# è¾“å‡ºç¤ºä¾‹ï¼š
# NAME                 REFERENCE                   TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
# llm-inference-hpa    Deployment/llm-inference    45%/60%, 55%/80%   3         10        3          5m

# æŸ¥çœ‹è¯¦ç»†äº‹ä»¶
kubectl describe hpa llm-inference-hpa
```

#### å‹åŠ›æµ‹è¯•ï¼šæ¨¡æ‹Ÿæµé‡é«˜å³°

ä½¿ç”¨ `hey` å·¥å…·æ¨¡æ‹Ÿå¹¶å‘è¯·æ±‚ï¼š

```bash
# å®‰è£… heyï¼ˆHTTP è´Ÿè½½æµ‹è¯•å·¥å…·ï¼‰
go install github.com/rakyll/hey@latest

# è·å– Service å¤–éƒ¨ IP
export LLM_SERVICE_IP=$(kubectl get svc llm-inference -o jsonpath='{.status.loadBalancer.ingress[0].ip}')

# å‘èµ·å‹åŠ›æµ‹è¯•ï¼š200 å¹¶å‘ï¼ŒæŒç»­ 5 åˆ†é’Ÿ
hey -z 5m -c 200 http://${LLM_SERVICE_IP}/v1/inference \
  -m POST \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Explain quantum computing"}'
```

#### è§‚å¯Ÿæ‰©å®¹è¿‡ç¨‹

åœ¨å¦ä¸€ä¸ªç»ˆç«¯å®æ—¶ç›‘æ§ï¼š

```bash
# å®æ—¶æŸ¥çœ‹ HPA çŠ¶æ€ï¼ˆæ¯ 2 ç§’åˆ·æ–°ï¼‰
watch -n 2 kubectl get hpa llm-inference-hpa

# å®æ—¶æŸ¥çœ‹ Pod æ•°é‡
watch -n 2 kubectl get pods -l app=llm-inference

# æŸ¥çœ‹ HPA äº‹ä»¶æµ
kubectl get events --watch --field-selector involvedObject.name=llm-inference-hpa
```

**é¢„æœŸè¡Œä¸º**ï¼š
1. **T+0s**ï¼šå‹æµ‹å¼€å§‹ï¼ŒCPU ä½¿ç”¨ç‡å¿«é€Ÿä¸Šå‡
2. **T+30s**ï¼šHPA æ£€æµ‹åˆ° CPU 80%ï¼Œè®¡ç®—æœŸæœ›å‰¯æœ¬æ•°ä¸º 5
3. **T+60s**ï¼šæ–° Pod åˆ›å»ºå¹¶è¿›å…¥ Running çŠ¶æ€
4. **T+90s**ï¼šæ–° Pod é€šè¿‡ readinessProbeï¼Œå¼€å§‹æ¥æ”¶æµé‡
5. **T+120s**ï¼šCPU ä½¿ç”¨ç‡é™è‡³ 62%ï¼Œæ¥è¿‘ç›®æ ‡å€¼

---

### 3.4 æ•…éšœæ’æŸ¥å†³ç­–æ ‘

```mermaid
flowchart TD
    Start{HPA æ˜¯å¦ç”Ÿæ•ˆï¼Ÿ}
    
    Start -->|å¦| Check1{HPA å¯¹è±¡å­˜åœ¨ï¼Ÿ}
    Check1 -->|å¦| Fix1[åˆ›å»º HPA å¯¹è±¡]
    Check1 -->|æ˜¯| Check2{Metrics Server<br/>è¿è¡Œæ­£å¸¸ï¼Ÿ}
    
    Check2 -->|å¦| Fix2[ä¿®å¤ Metrics Server:<br/>kubectl get pods -n kube-system]
    Check2 -->|æ˜¯| Check3{Pod è®¾ç½®äº†<br/>resources.requestsï¼Ÿ}
    
    Check3 -->|å¦| Fix3[æ·»åŠ  requests é…ç½®<br/>å¹¶é‡å¯ Deployment]
    Check3 -->|æ˜¯| Check4{kubectl top pods<br/>èƒ½çœ‹åˆ°æ•°æ®ï¼Ÿ}
    
    Check4 -->|å¦| Fix4[æ£€æŸ¥ Kubelet ä¸<br/>Metrics Server è¿é€šæ€§]
    Check4 -->|æ˜¯| Check5{å½“å‰æŒ‡æ ‡æ˜¯å¦<br/>è¶…å‡ºç›®æ ‡Â±10%ï¼Ÿ}
    
    Check5 -->|å¦| Fix5[æŒ‡æ ‡åœ¨å®¹å¿èŒƒå›´å†…<br/>ç­‰å¾…è§¦å‘æ¡ä»¶]
    Check5 -->|æ˜¯| Check6{æ˜¯å¦åœ¨å†·å´æœŸï¼Ÿ}
    
    Check6 -->|æ˜¯| Fix6[ç­‰å¾…å†·å´æœŸç»“æŸ<br/>æ‰©å®¹:3min ç¼©å®¹:5min]
    Check6 -->|å¦| Check7{æ˜¯å¦è¾¾åˆ°<br/>maxReplicasï¼Ÿ}
    
    Check7 -->|æ˜¯| Fix7[æé«˜ maxReplicas<br/>æˆ–å¢åŠ èŠ‚ç‚¹å®¹é‡]
    Check7 -->|å¦| Fix8[æ£€æŸ¥äº‹ä»¶æ—¥å¿—:<br/>kubectl describe hpa]
    
    Start -->|æ˜¯ï¼Œä½†æŠ–åŠ¨| Flap{é¢‘ç¹æ‰©ç¼©å®¹ï¼Ÿ}
    Flap --> FixFlap1[è°ƒæ•´ stabilizationWindow<br/>å»¶é•¿è‡³ 5-10 åˆ†é’Ÿ]
    Flap --> FixFlap2[é™ä½æ‰©ç¼©å®¹é€Ÿç‡<br/>policies.value]
    
    style Fix1 fill:#e8f5e9
    style Fix2 fill:#e8f5e9
    style Fix3 fill:#e8f5e9
    style Fix4 fill:#e8f5e9
    style Fix5 fill:#fff3e0
    style Fix6 fill:#fff3e0
    style Fix7 fill:#ffebee
    style Fix8 fill:#e1f5fe
```

#### å¸¸è§é—®é¢˜ Quick Fix

| ç—‡çŠ¶ | è¶…å¸‚ç±»æ¯” | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|---------|------|---------|
| **HPA æ˜¾ç¤º `<unknown>`** | åº—é•¿çœ‹ä¸åˆ°æ’é˜Ÿäººæ•° | Metrics Server æœªå®‰è£…/æ•…éšœ | `kubectl get pods -n kube-system \| grep metrics-server` |
| **æ‰©å®¹åˆ° maxReplicas ååœæ­¢** | å·²å¼€åˆ°ä¸Šé™æŸœå°ï¼Œä»ä¸å¤Ÿ | èŠ‚ç‚¹èµ„æºä¸è¶³ï¼ŒPod Pending | æ·»åŠ èŠ‚ç‚¹æˆ–å¯ç”¨ Cluster Autoscaler |
| **ç¼©å®¹åç«‹å³æ‰©å®¹** | å…³å°ååˆæ’é˜Ÿï¼Œåå¤å¼€å…³ | ç¨³å®šçª—å£å¤ªçŸ­ | å¢åŠ  `stabilizationWindowSeconds` è‡³ 300s |
| **CPU ä½ä½†ä¸ç¼©å®¹** | æŸœå°ç©ºé—²ä½†ä¸å…³å° | åœ¨ 5 åˆ†é’Ÿç¼©å®¹å†·å´æœŸ | ç­‰å¾…æˆ–è°ƒæ•´ `downscale-delay` |
| **æŒ‡æ ‡å§‹ç»ˆ 0%** | æ”¶é“¶å‘˜æœªä¸ŠæŠ¥æ’é˜Ÿæ•°æ® | Pod æœªè®¾ç½® `resources.requests` | æ·»åŠ  requests å¹¶é‡å»º Pod |

---

### 3.5 ç›‘æ§ä¸å‘Šè­¦

#### å…³é”® SLIï¼ˆæœåŠ¡æ°´å¹³æŒ‡æ ‡ï¼‰

| æŒ‡æ ‡ | PromQL æŸ¥è¯¢ | å‘Šè­¦é˜ˆå€¼ | ä¸šåŠ¡å½±å“ |
|------|------------|---------|---------|
| **HPA å½“å‰å‰¯æœ¬æ•°** | `kube_horizontalpodautoscaler_status_current_replicas` | - | è§‚å¯Ÿæ‰©ç¼©å®¹å†å² |
| **æœŸæœ›å‰¯æœ¬æ•°** | `kube_horizontalpodautoscaler_status_desired_replicas` | - | è¯„ä¼°æ‰©å®¹éœ€æ±‚ |
| **è·ç¦» maxReplicas çš„ä½™é‡** | `(max - current) / max` | < 20% | å®¹é‡å³å°†è€—å°½ |
| **æ‰©ç¼©å®¹é¢‘ç‡** | `rate(kube_horizontalpodautoscaler_status_desired_replicas[5m])` | > 0.5/min | å¯èƒ½å­˜åœ¨æŠ–åŠ¨ |
| **æŒ‡æ ‡è·å–å¤±è´¥æ¬¡æ•°** | `kube_horizontalpodautoscaler_status_condition{condition="ScalingActive",status="false"}` | > 3 | Metrics Server å¼‚å¸¸ |

#### Prometheus å‘Šè­¦è§„åˆ™ç¤ºä¾‹

```yaml
# hpa-alerts.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: hpa-alerts
spec:
  groups:
  - name: hpa
    interval: 30s
    rules:
    # å‘Šè­¦ 1ï¼šHPA æ¥è¿‘å®¹é‡ä¸Šé™
    - alert: HPANearMaxCapacity
      expr: |
        (kube_horizontalpodautoscaler_status_current_replicas 
         / kube_horizontalpodautoscaler_spec_max_replicas) > 0.9
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "HPA {{ $labels.horizontalpodautoscaler }} æ¥è¿‘å®¹é‡ä¸Šé™"
        description: "å½“å‰å‰¯æœ¬æ•° {{ $value | humanizePercentage }}ï¼Œå»ºè®®æé«˜ maxReplicas"
    
    # å‘Šè­¦ 2ï¼šHPA æ— æ³•è·å–æŒ‡æ ‡
    - alert: HPAMetricsUnavailable
      expr: |
        kube_horizontalpodautoscaler_status_condition{condition="ScalingActive",status="false"} == 1
      for: 10m
      labels:
        severity: critical
      annotations:
        summary: "HPA {{ $labels.horizontalpodautoscaler }} æ— æ³•è·å–æŒ‡æ ‡"
        description: "æ£€æŸ¥ Metrics Server å’Œ Pod resources.requests é…ç½®"
    
    # å‘Šè­¦ 3ï¼šé¢‘ç¹æ‰©ç¼©å®¹ï¼ˆæŠ–åŠ¨ï¼‰
    - alert: HPAFlapping
      expr: |
        rate(kube_horizontalpodautoscaler_status_desired_replicas[10m]) > 0.5
      for: 15m
      labels:
        severity: warning
      annotations:
        summary: "HPA {{ $labels.horizontalpodautoscaler }} é¢‘ç¹æ‰©ç¼©å®¹"
        description: "è¿‡å» 10 åˆ†é’Ÿæ‰©ç¼©å®¹ {{ $value }} æ¬¡/åˆ†é’Ÿï¼Œå»ºè®®è°ƒæ•´ stabilizationWindow"
```

#### Grafana ç›‘æ§é¢æ¿

æ¨èå¯¼å…¥ç¤¾åŒºé¢æ¿ï¼š[Kubernetes HPA Dashboard (ID: 12125)](https://grafana.com/grafana/dashboards/12125)

å…³é”®é¢æ¿åŒ…æ‹¬ï¼š
- **å®æ—¶å‰¯æœ¬æ•°è¶‹åŠ¿å›¾**ï¼ˆæŠ˜çº¿å›¾ï¼‰
- **CPU/å†…å­˜ä½¿ç”¨ç‡ vs ç›®æ ‡å€¼**ï¼ˆåŒè½´å›¾ï¼‰
- **æ‰©ç¼©å®¹äº‹ä»¶æ—¶é—´çº¿**ï¼ˆæ³¨é‡Šå›¾ï¼‰
- **HPA å»¶è¿Ÿåˆ†å¸ƒ**ï¼ˆçƒ­åŠ›å›¾ï¼‰

---

### 3.6 ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

#### âœ… æ¨èåšæ³•

| å®è·µ | è¶…å¸‚ç±»æ¯” | ç†ç”± |
|------|---------|------|
| **è®¾ç½®åˆç†çš„ minReplicas** | è‡³å°‘ä¿ç•™ 2-3 ä¸ªæŸœå° | é¿å…å†·å¯åŠ¨å»¶è¿Ÿï¼Œä¿éšœåŸºç¡€æœåŠ¡ |
| **maxReplicas ç•™ 20% ä½™é‡** | é¢„ç•™ç´§æ€¥å¼€å°ç©ºé—´ | åº”å¯¹è¶…é¢„æœŸæµé‡ |
| **åŒæ—¶ç›‘æ§ CPU å’Œå†…å­˜** | æ—¢çœ‹æ’é˜Ÿäººæ•°ï¼Œä¹Ÿçœ‹å¤„ç†é€Ÿåº¦ | å…¨é¢è¯„ä¼°è´Ÿè½½ |
| **é…ç½® PodDisruptionBudget** | ä¿è¯è‡³å°‘ 70% æŸœå°è¥ä¸š | é˜²æ­¢ç¼©å®¹æ—¶æœåŠ¡ä¸å¯ç”¨ |
| **ä½¿ç”¨è‡ªå®šä¹‰æŒ‡æ ‡** | æ ¹æ®ä¸šåŠ¡ KPI å†³ç­– | CPU ä¸èƒ½å®Œå…¨åæ˜ æœåŠ¡è´¨é‡ |
| **å¯ç”¨ Cluster Autoscaler** | è‡ªåŠ¨æ‰©å±•è¶…å¸‚é¢ç§¯ | HPA éœ€è¦é…åˆèŠ‚ç‚¹è‡ªåŠ¨æ‰©å®¹ |

#### âŒ åæ¨¡å¼ï¼ˆAnti-Patternsï¼‰

| åæ¨¡å¼ | è¶…å¸‚ç±»æ¯” | å±å®³ | æ­£ç¡®åšæ³• |
|--------|---------|------|---------|
| **minReplicas = 1** | åªä¿ç•™ 1 ä¸ªæŸœå° | å•ç‚¹æ•…éšœï¼Œæ— é«˜å¯ç”¨ | è‡³å°‘è®¾ä¸º 2-3 |
| **ä¸è®¾ç½® resources.requests** | ä¸çŸ¥é“æ¯ä¸ªæŸœå°èƒ½æœåŠ¡å¤šå°‘äºº | HPA æ— æ³•è®¡ç®—ï¼ŒåŠŸèƒ½å¤±æ•ˆ | å¿…é¡»è®¾ç½® requests |
| **åŒæ—¶ä½¿ç”¨ HPA å’Œ VPA** | æ—¢è°ƒæ•´æŸœå°æ•°é‡ï¼Œåˆè°ƒæ•´æ¯ä¸ªæŸœå°å¤§å° | å†²çªå¯¼è‡´ä¸å¯é¢„æµ‹è¡Œä¸º | åªé€‰å…¶ä¸€ |
| **æ‰‹åŠ¨ä¿®æ”¹ Deployment.replicas** | åº—é•¿å’Œæ€»éƒ¨åŒæ—¶è°ƒåº¦æŸœå° | HPA é…ç½®è¢«è¦†ç›– | è®© HPA å…¨æƒç®¡ç†å‰¯æœ¬æ•° |
| **è¿‡çŸ­çš„ç¨³å®šçª—å£** | çœ‹åˆ°æ’é˜Ÿç«‹å³å¼€å° | é¢‘ç¹æŠ–åŠ¨ï¼Œæµªè´¹èµ„æº | æ‰©å®¹ â‰¥60sï¼Œç¼©å®¹ â‰¥300s |

#### é…ç½®æ¨èå€¼ï¼ˆAI æ¨ç†åœºæ™¯ï¼‰

```yaml
# æ¨èé…ç½®æ¨¡æ¿
minReplicas: 3                    # åŸºç¡€å®¹é‡ï¼šä¿éšœå¯ç”¨æ€§
maxReplicas: 20                   # å³°å€¼å®¹é‡ï¼šæŒ‰å†å²æœ€é«˜ QPS Ã— 1.5 è®¡ç®—
metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        averageUtilization: 60    # ç•™ 40% ä½™é‡åº”å¯¹çªå‘
  - type: Resource
    resource:
      name: memory
      target:
        averageUtilization: 75    # å†…å­˜é€šå¸¸æ›´ç¨³å®š
behavior:
  scaleUp:
    stabilizationWindowSeconds: 60    # 1 åˆ†é’Ÿï¼šå¿«é€Ÿå“åº”
    policies:
    - type: Percent
      value: 100                      # æœ€æ¿€è¿›ï¼šç¿»å€æ‰©å®¹
  scaleDown:
    stabilizationWindowSeconds: 300   # 5 åˆ†é’Ÿï¼šä¿å®ˆç¼©å®¹
    policies:
    - type: Pods
      value: 2                        # æ¯æ¬¡æœ€å¤šå‡ 2 ä¸ª
```

---

### 3.7 è¿›é˜¶è¯é¢˜ï¼šå¤šæŒ‡æ ‡æƒè¡¡

#### åœºæ™¯ï¼šCPU ä½ä½†å»¶è¿Ÿé«˜

```yaml
# é—®é¢˜ï¼šæ¨ç†æœåŠ¡ CPU ä»… 40%ï¼Œä½† P99 å»¶è¿Ÿè¾¾åˆ° 2 ç§’ï¼ˆSLA è¦æ±‚ <500msï¼‰
# åŸå› ï¼šæ¨¡å‹æ¨ç†æ˜¯ I/O å¯†é›†å‹ï¼ˆè¯»å– GPU å†…å­˜ï¼‰ï¼ŒCPU ä¸æ˜¯ç“¶é¢ˆ

# è§£å†³æ–¹æ¡ˆï¼šåŸºäºè‡ªå®šä¹‰å»¶è¿ŸæŒ‡æ ‡æ‰©å®¹
metrics:
- type: Pods
  pods:
    metric:
      name: http_request_duration_p99
    target:
      type: AverageValue
      averageValue: "500"  # ç›®æ ‡ P99 å»¶è¿Ÿ 500ms
```

#### åœºæ™¯ï¼šæ··åˆæƒé‡ç­–ç•¥

```yaml
# åŒæ—¶è€ƒè™‘ CPUã€å†…å­˜ã€è‡ªå®šä¹‰æŒ‡æ ‡
# HPA ä¼šåˆ†åˆ«è®¡ç®—æ¯ä¸ªæŒ‡æ ‡çš„æœŸæœ›å‰¯æœ¬æ•°ï¼Œå–æœ€å¤§å€¼

metrics:
- type: Resource
  resource:
    name: cpu
    target:
      averageUtilization: 70
- type: Resource
  resource:
    name: memory
    target:
      averageUtilization: 80
- type: Pods
  pods:
    metric:
      name: inference_queue_length
    target:
      type: AverageValue
      averageValue: "10"  # æ¯ä¸ª Pod å¹³å‡é˜Ÿåˆ—é•¿åº¦ 10

# è®¡ç®—é€»è¾‘ï¼š
# CPU å»ºè®® 5 ä¸ªå‰¯æœ¬
# å†…å­˜å»ºè®® 4 ä¸ªå‰¯æœ¬
# é˜Ÿåˆ—é•¿åº¦å»ºè®® 8 ä¸ªå‰¯æœ¬
# æœ€ç»ˆï¼šmax(5, 4, 8) = 8 ä¸ªå‰¯æœ¬
```

---

### âœ… èºæ—‹ 3 éªŒæ”¶æ ‡å‡†

å¬ä¼—èƒ½å¤Ÿï¼š
1. **ç‹¬ç«‹éƒ¨ç½² HPA**ï¼šä» Metrics Server å®‰è£…åˆ° HPA é…ç½®ï¼Œå®Œæ•´æ­å»ºç”Ÿäº§ç¯å¢ƒ
2. **æ•…éšœæ’æŸ¥**ï¼šé‡åˆ°"æ‰©å®¹ä¸ç”Ÿæ•ˆ"æ—¶ï¼ŒæŒ‰å†³ç­–æ ‘é€æ­¥å®šä½é—®é¢˜
3. **é…ç½®ç›‘æ§**ï¼šè®¾ç½® Prometheus å‘Šè­¦è§„åˆ™ï¼Œç›‘æ§ HPA å¥åº·çŠ¶æ€
4. **è°ƒä¼˜å‚æ•°**ï¼šæ ¹æ®ä¸šåŠ¡ç‰¹ç‚¹è°ƒæ•´ç¨³å®šçª—å£ã€æ‰©ç¼©å®¹é€Ÿç‡
5. **é¿å…åæ¨¡å¼**ï¼šè¯†åˆ«å¹¶çº æ­£å¸¸è§çš„ HPA é…ç½®é”™è¯¯

---

## æ€»ç»“ä¸å±•æœ›

### æ ¸å¿ƒå›é¡¾ï¼šè¶…å¸‚æ”¶é“¶å°çš„æ™ºæ…§

é€šè¿‡æœ¬æ¬¡æŠ€æœ¯åˆ†äº«ï¼Œæˆ‘ä»¬ç”¨ **è¶…å¸‚æ”¶é“¶æŸœå°** ç±»æ¯”å®Œæ•´å­¦ä¹ äº† Kubernetes HPAï¼š

1. **èºæ—‹ 1ï¼ˆæ¦‚å¿µå±‚ï¼‰**ï¼šç†è§£ **ä¸ºä»€ä¹ˆ** éœ€è¦è‡ªåŠ¨æ‰©ç¼©å®¹ï¼ŒHPA **æ˜¯ä»€ä¹ˆ**
2. **èºæ—‹ 2ï¼ˆæœºåˆ¶å±‚ï¼‰**ï¼šæŒæ¡ HPA **å¦‚ä½•å·¥ä½œ**ï¼Œè®¡ç®—å…¬å¼ã€é˜²æŠ–æœºåˆ¶ã€Metrics Server åŸç†
3. **èºæ—‹ 3ï¼ˆå®æˆ˜å±‚ï¼‰**ï¼šå­¦ä¼š **ç”Ÿäº§éƒ¨ç½²**ï¼Œä»é…ç½®åˆ°ç›‘æ§åˆ°æ•…éšœæ’æŸ¥

### å…³é”®å…¬å¼ï¼ˆé“­è®°äºå¿ƒï¼‰

```
æœŸæœ›å‰¯æœ¬æ•° = ceil(å½“å‰å‰¯æœ¬æ•° Ã— (å½“å‰æŒ‡æ ‡å€¼ / ç›®æ ‡æŒ‡æ ‡å€¼))
```

å°±åƒè¶…å¸‚åº—é•¿è®¡ç®—ï¼š
```
éœ€è¦çš„æŸœå°æ•° = å½“å‰æŸœå°æ•° Ã— (å®é™…æ’é˜Ÿäººæ•° / ç›®æ ‡æ’é˜Ÿäººæ•°)
```

### ä¸‹ä¸€æ­¥å­¦ä¹ æ–¹å‘

1. **é›†ç¾¤è‡ªåŠ¨æ‰©å®¹ï¼ˆCluster Autoscalerï¼‰**ï¼šHPA çš„æœ€ä½³æ­æ¡£ï¼Œè‡ªåŠ¨æ·»åŠ èŠ‚ç‚¹
2. **å‚ç›´æ‰©å®¹ï¼ˆVPAï¼‰**ï¼šè°ƒæ•´å•ä¸ª Pod çš„èµ„æºé…é¢
3. **KEDAï¼ˆKubernetes Event-Driven Autoscalingï¼‰**ï¼šåŸºäºäº‹ä»¶é©±åŠ¨ï¼ˆæ¶ˆæ¯é˜Ÿåˆ—ã€HTTP æµé‡ï¼‰æ‰©ç¼©å®¹
4. **å®šåˆ¶æŒ‡æ ‡æ”¶é›†**ï¼šä½¿ç”¨ Prometheus Adapter æ¥å…¥ä¸šåŠ¡æŒ‡æ ‡

### ç”Ÿäº§ç¯å¢ƒ Checklist

- [ ] Metrics Server å·²å®‰è£…å¹¶è¿è¡Œæ­£å¸¸
- [ ] æ‰€æœ‰ Pod é…ç½®äº† `resources.requests`
- [ ] HPA è®¾ç½®äº†åˆç†çš„ `minReplicas`ï¼ˆâ‰¥2ï¼‰å’Œ `maxReplicas`
- [ ] é…ç½®äº†é˜²æŠ–æœºåˆ¶ï¼ˆ`stabilizationWindow` â‰¥ 60sï¼‰
- [ ] å¯ç”¨äº† Prometheus ç›‘æ§å’Œå‘Šè­¦
- [ ] é›†æˆäº† Cluster Autoscalerï¼ˆåº”å¯¹èŠ‚ç‚¹å®¹é‡ä¸è¶³ï¼‰
- [ ] å®šæœŸå›é¡¾ HPA æ—¥å¿—ï¼Œä¼˜åŒ–ç›®æ ‡å€¼å’Œç­–ç•¥

---

> **æœ€åçš„è¶…å¸‚æ™ºæ…§**ï¼š  
> å¥½çš„åº—é•¿ä¸æ˜¯å¼€å°æœ€å¤šçš„ï¼Œè€Œæ˜¯ç”¨æœ€å°‘çš„æŸœå°ï¼Œè®©æ¯ä¸ªé¡¾å®¢éƒ½ä¸ç”¨æ’é•¿é˜Ÿã€‚  
> å¥½çš„ HPA ä¸æ˜¯å‰¯æœ¬æ•°æœ€å¤šçš„ï¼Œè€Œæ˜¯ç”¨æœ€ä¼˜çš„èµ„æºï¼Œè®©æ¯ä¸ªè¯·æ±‚éƒ½å¾—åˆ°åŠæ—¶å“åº”ã€‚

**Happy Autoscaling!** ğŸš€

---

## å‚è€ƒèµ„æ–™

1. [Kubernetes å®˜æ–¹æ–‡æ¡£ - Horizontal Pod Autoscaling](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
2. [Google Cloud - HorizontalPodAutoscaler æ¦‚å¿µ](https://docs.cloud.google.com/kubernetes-engine/docs/concepts/horizontalpodautoscaler)
3. [Cast.AI - Kubernetes HPA å®Œå…¨æŒ‡å—](https://cast.ai/blog/what-is-kubernetes-hpa-and-how-can-it-help-you-save-on-the-cloud/)
4. [Spacelift - HPA æœ€ä½³å®è·µ](https://spacelift.io/blog/kubernetes-hpa-horizontal-pod-autoscaler)
5. [Kubernetes Walkthrough - HPA å®æˆ˜](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/)
