# Gateway API Inference Extension æ·±åº¦è§£æ

> **ä¸€å¥è¯æ€»ç»“**ï¼šInference Gateway å°±åƒç±³å…¶æ—é¤å…çš„èµ„æ·±é¢†ç­ï¼Œæ ¹æ®å¨æˆ¿å®æ—¶çŠ¶æ€ï¼ˆé˜Ÿåˆ—ã€ç¼“å­˜ã€é€‚é…å™¨ï¼‰æ™ºèƒ½åˆ†é…è®¢å•ï¼Œè€Œä¸æ˜¯éšæœºå®‰æ’åº§ä½ã€‚

---

## ğŸŒ€ èºæ—‹ 1ï¼šæ¦‚å¿µå±‚ï¼ˆWhy/Whatï¼‰

### æœ¬å±‚ç›®æ ‡
å»ºç«‹è®¤çŸ¥é”šç‚¹ï¼Œç†è§£ä¸ºä»€ä¹ˆ LLM æ¨ç†éœ€è¦ä¸“é—¨çš„è´Ÿè½½å‡è¡¡ï¼Œä»¥åŠ Gateway API Inference Extension çš„æ ¸å¿ƒå®šä½ã€‚

---

### 1.1 é—®é¢˜æœ¬è´¨ï¼šLLM æ¨ç† vs ä¼ ç»Ÿ Web æœåŠ¡

#### ä¼ ç»Ÿ Web æœåŠ¡çš„ç‰¹å¾

```
è¯·æ±‚ â†’ å¤„ç† â†’ å“åº”
 â”œâ”€ å¤„ç†æ—¶é—´ç¨³å®šï¼ˆé€šå¸¸ < 100msï¼‰
 â”œâ”€ çŠ¶æ€æ— å…³ï¼ˆStatelessï¼‰
 â””â”€ èµ„æºæ¶ˆè€—å‡åŒ€
```

ä¼ ç»Ÿè´Ÿè½½å‡è¡¡ï¼ˆRound-Robinã€Least Connectionsï¼‰å·¥ä½œå¾—å¾ˆå¥½ï¼Œå› ä¸ºï¼š
- æ¯ä¸ªè¯·æ±‚çš„ CPU/å†…å­˜æ¶ˆè€—å¤§è‡´ç›¸åŒ
- å“åº”æ—¶é—´å¯é¢„æµ‹
- æ— çŠ¶æ€æ„å‘³ç€ä»»æ„ Pod éƒ½èƒ½å¤„ç†ä»»æ„è¯·æ±‚

#### LLM æ¨ç†çš„ç‰¹å¾

```
è¯·æ±‚ï¼ˆPromptï¼‰â†’ é¢„å¡«å……ï¼ˆPrefillï¼‰â†’ è§£ç ï¼ˆDecodeï¼‰â†’ å“åº”
     â”œâ”€ è¾“å…¥é•¿åº¦å·®å¼‚å·¨å¤§ï¼ˆ10 tokens vs 10000 tokensï¼‰
     â”œâ”€ è¾“å‡ºé•¿åº¦ä¸ç¡®å®šï¼ˆ100 tokens vs 4000 tokensï¼‰
     â”œâ”€ æ˜¾å­˜æ¶ˆè€—ä¸åºåˆ—é•¿åº¦æ­£ç›¸å…³
     â”œâ”€ Prefix Cache å¯å¤ç”¨å‰ç¼€ï¼Œæå¤§åŠ é€Ÿ
     â””â”€ KV Cache å æ»¡åéœ€è¦é€å‡ºæˆ–æ‹’ç»è¯·æ±‚
```

**å…³é”®å·®å¼‚**ï¼š

| ç»´åº¦ | ä¼ ç»Ÿ Web | LLM æ¨ç† |
|------|---------|---------|
| **è¯·æ±‚å¤§å°** | å›ºå®šï¼ˆKB çº§ï¼‰ | é«˜åº¦å¯å˜ï¼ˆprompt 1K-100K tokensï¼‰ |
| **å“åº”æ—¶é—´** | ç¨³å®šï¼ˆP99/P50 æ¥è¿‘ï¼‰ | é•¿å°¾ä¸¥é‡ï¼ˆP99 å¯èƒ½æ˜¯ P50 çš„ 10 å€ï¼‰ |
| **èµ„æºæ¶ˆè€—** | å‡åŒ€ | ä¸è¾“å…¥/è¾“å‡ºé•¿åº¦å¼ºç›¸å…³ |
| **çŠ¶æ€å½±å“** | æ— çŠ¶æ€ | Prefix/KV Cache å‘½ä¸­ä¸å¦å·®å¼‚å·¨å¤§ |
| **æ’é˜Ÿæ¨¡å‹** | ç®€å• FIFO | ä¼˜å…ˆçº§ã€æŠ¢å ã€Adapter äº²å’Œæ€§ |

#### ä¸­å›½æœ¬åœŸåœºæ™¯ï¼šåŒ 11 AI å®¢æœ

**åœºæ™¯æè¿°**ï¼š
- æŸç”µå•†å¹³å°çš„ AI å®¢æœç³»ç»Ÿä½¿ç”¨è‡ªæ‰˜ç®¡ LLMï¼ˆQwen-72Bï¼‰
- åŒ 11 æœŸé—´æµé‡æ¿€å¢ 50 å€
- è¯·æ±‚ç±»å‹æ··åˆï¼š
  - **ç´§æ€¥**ï¼šè®¢å•é—®é¢˜ï¼ˆéœ€ç§’çº§å“åº”ï¼‰
  - **æ™®é€š**ï¼šå•†å“å’¨è¯¢ï¼ˆå¯å®¹å¿ 5s å»¶è¿Ÿï¼‰
  - **æ‰¹å¤„ç†**ï¼šå†å²è®¢å•æ€»ç»“ï¼ˆå¯å®¹å¿ 30sï¼‰

**ä¼ ç»Ÿ Round-Robin çš„é—®é¢˜**ï¼š
```
æ—¶é—´çº¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶

Pod-1: [å¤§å•â˜…]        [å¤§å•â˜…]        [å¤§å•â˜…]
Pod-2: [å°å•] [å°å•] [å°å•] [å°å•] [å°å•] [å°å•]
Pod-3: [ä¸­å•]  [ä¸­å•]  [ä¸­å•]  [ä¸­å•]

ç»“æœï¼š
- Pod-1 æ»¡è½½ï¼Œåç»­è¯·æ±‚æ’é˜Ÿ 10s+
- Pod-2/3 ç©ºé—²ï¼Œä½†æ–°è¯·æ±‚ä»æŒ‰è½®è¯¢å‘å¾€ Pod-1
- ç´§æ€¥è®¢å•è¢«æ™®é€šè®¢å•é˜»å¡
- GPU åˆ©ç”¨ç‡ï¼šåä¹‰ä¸Š 100%ï¼Œå®é™…ä¸Šå¤§é‡æ—¶é—´èŠ±åœ¨æ’é˜Ÿ
```

**éœ€è¦çš„æ™ºèƒ½è°ƒåº¦**ï¼š
```
æ—¶é—´çº¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶

Pod-1ï¼ˆQueue=5ï¼‰: [å¤§å•] 
Pod-2ï¼ˆQueue=0ï¼‰: [ç´§æ€¥å•â˜…] [å°å•] [å°å•] [å°å•] [ä¸­å•]
Pod-3ï¼ˆQueue=2ï¼‰: [ä¸­å•] [å¤§å•]

å†³ç­–ï¼š
- ç´§æ€¥å• â†’ Pod-2ï¼ˆæœ€çŸ­é˜Ÿåˆ—ï¼‰
- å¤§å• â†’ Pod-3ï¼ˆKV Cache æœ‰ç©ºé—´ï¼‰
- å°å• â†’ Pod-2ï¼ˆè´Ÿè½½æœ€è½»ï¼‰
- æ‰¹å¤„ç†ä»»åŠ¡ â†’ å»¶è¿Ÿå®¹å¿åº¦é«˜ï¼Œå¯ç­‰ä½å³°æœŸ

ç»“æœï¼šP99 å»¶è¿Ÿé™ä½ 60%ï¼ŒGPU åˆ©ç”¨ç‡æå‡ 40%
```

---

### 1.2 æ¶æ„å…¨æ™¯ï¼šä» Gateway åˆ° Model Server

```mermaid
flowchart LR
    Client([Client]) -->|HTTP/HTTPS| Gateway[Gateway<br/>Envoy/Istio/KGateway]
    Gateway -->|ext-proc| EPP[Endpoint Picker<br/>æ™ºèƒ½è°ƒåº¦å™¨]
    EPP -->|Watch| APIServer[Kubernetes API Server]
    APIServer -->|Pod/Metrics| Pool[InferencePool<br/>vLLM Pods]
    EPP -->|Select Endpoint| Gateway
    Gateway -->|Route| Pod1[Pod 1]
    Gateway -->|Route| Pod2[Pod 2]
    Gateway -->|Route| Pod3[Pod N]
    
    subgraph "æ§åˆ¶é¢"
        APIServer
        EPP
    end
    
    subgraph "æ•°æ®é¢"
        Gateway
        Pod1
        Pod2
        Pod3
    end
    
    style EPP fill:#e1f5fe
    style Gateway fill:#fff3e0
    style Pool fill:#e8f5e9
```

#### æ ¸å¿ƒç»„ä»¶èŒè´£

| ç»„ä»¶ | ç±»æ¯”è§’è‰² | æ ¸å¿ƒèŒè´£ |
|------|---------|---------|
| **Gateway** | é¤å…å‰å° | TLS ç»ˆæ­¢ã€è®¤è¯ã€é™æµã€è·¯ç”±è§„åˆ™åŒ¹é… |
| **EPP (Endpoint Picker)** | èµ„æ·±é¢†ç­ (MaÃ®tre d') | æ ¹æ®å®æ—¶æŒ‡æ ‡é€‰æ‹©æœ€ä¼˜ Pod |
| **InferencePool** | é¤å…åº§ä½åŒº | å®šä¹‰å“ªäº› Pod å±äºåŒä¸€æœåŠ¡æ±  |
| **InferenceObjective** | VIP å¡/ä¼˜å…ˆçº§æ ‡ç­¾ | å®šä¹‰è¯·æ±‚çš„ä¼˜å…ˆçº§å’Œç›®æ ‡ SLA |
| **BBR (Body Based Router)** | é¢„è®¢ç³»ç»Ÿ | ä»è¯·æ±‚ä½“è§£æ model åç§°ï¼Œå®ç°å¤šæ¨¡å‹è·¯ç”± |
| **Model Server (vLLM)** | å¨æˆ¿å·¥ä½ | å®é™…æ‰§è¡Œæ¨ç†ï¼Œæš´éœ² Queue/KV/Prefix æŒ‡æ ‡ |

---

### 1.3 å…³é”®æ¦‚å¿µè¯¦è§£

#### InferencePoolï¼šæ¨ç†æœåŠ¡çš„"åº§ä½åŒº"

```yaml
apiVersion: inference.networking.k8s.io/v1
kind: InferencePool
metadata:
  name: qwen-72b-pool
spec:
  selector:
    matchLabels:
      model: qwen-72b-instruct
  port: 8000
  extensionRef:
    name: epp-qwen-72b
```

**ç±»æ¯”**ï¼šInferencePool å°±åƒé¤å…é‡Œçš„"å¤§åŒ…å¢åŒº"â€”â€”æŒ‡å®šäº†å“ªäº›æ¡Œå­ï¼ˆPodsï¼‰å±äºè¿™ä¸ªåŒºåŸŸï¼Œä»¥åŠåŒºåŸŸçš„ä¸“å±æœåŠ¡å‘˜ï¼ˆEPPï¼‰ã€‚

**ä¸ä¼ ç»Ÿ Service çš„åŒºåˆ«**ï¼š
- Serviceï¼šå•çº¯çš„ L4 è´Ÿè½½å‡è¡¡ï¼Œéšæœºåˆ†é…
- InferencePoolï¼šL7 æ„ŸçŸ¥ï¼Œæ”¯æŒè‡ªå®šä¹‰è°ƒåº¦é€»è¾‘

#### InferenceObjectiveï¼šè¯·æ±‚çš„"èº«ä»½æ ‡ç­¾"

```yaml
apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: InferenceObjective
metadata:
  name: critical-chat
spec:
  priority: 100  # è¶Šé«˜è¶Šä¼˜å…ˆ
  poolRef:
    name: qwen-72b-pool
```

**ç±»æ¯”**ï¼šå°±åƒé¤å…çš„ VIP å®¢äºº vs æ™®é€šå®¢äºº
- VIPï¼ˆPriority=100ï¼‰ï¼šå¿…é¡»ç«‹å³å…¥åº§ï¼Œå¯æŠ¢å æ™®é€šå®¢äººèµ„æº
- æ™®é€šï¼ˆPriority=0ï¼‰ï¼šæ­£å¸¸æ’é˜Ÿ
- æ‰¹å¤„ç†ï¼ˆPriority=-50ï¼‰ï¼šå¯å»¶è¿Ÿï¼Œç³»ç»Ÿæ»¡è½½æ—¶ç¬¬ä¸€ä¸ªè¢«ä¸¢å¼ƒ

**åŒ 11 åœºæ™¯æ˜ å°„**ï¼š
| ä¸šåŠ¡åœºæ™¯ | Priority | è¯´æ˜ |
|---------|---------|------|
| è®¢å•å¼‚å¸¸å¤„ç† | 100 | Criticalï¼Œç§’çº§å“åº” |
| å®æ—¶å®¢æœå¯¹è¯ | 50 | é«˜ä¼˜å…ˆçº§ï¼Œå®¹å¿ 2s |
| å•†å“å’¨è¯¢ | 0 | é»˜è®¤ä¼˜å…ˆçº§ |
| å†å²è®¢å•åˆ†æ | -50 | Sheddableï¼Œå¯å»¶è¿Ÿ/ä¸¢å¼ƒ |

---

### 1.4 æ ¸å¿ƒèƒ½åŠ›ä¸€è§ˆ

```mermaid
flowchart TD
    A[Gateway API Inference Extension] --> B[æ¨¡å‹æ„ŸçŸ¥è·¯ç”±]
    A --> C[æ™ºèƒ½è´Ÿè½½å‡è¡¡]
    A --> D[ä¼˜å…ˆçº§ä¸å®¹é‡]
    A --> E[å¯è§‚æµ‹æ€§]
    A --> F[æ‰©å±•æ€§]
    
    B --> B1[å¤šæ¨¡å‹æœåŠ¡]
    B --> B2[LoRA é€‚é…å™¨äº²å’Œ]
    B --> B3[Prefix Cache è·¯ç”±]
    
    C --> C1[Queue Depth æ„ŸçŸ¥]
    C --> C1[KV Cache æ„ŸçŸ¥]
    C --> C1[å»¶è¿Ÿé¢„æµ‹]
    
    D --> D1[ä¼˜å…ˆçº§é˜Ÿåˆ—]
    D --> D2[å®¹é‡é˜ˆå€¼ä¿æŠ¤]
    D --> D3[ä¼˜é›…é™çº§]
    
    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#fff3e0
    style D fill:#fff3e0
```

---

### âœ… èºæ—‹ 1 éªŒæ”¶æ ‡å‡†

**ä½ èƒ½åšåˆ°**ï¼š
1. ä¸€å¥è¯å¤è¿° Inference Gateway çš„æ ¸å¿ƒä»·å€¼
2. è§£é‡Šä¸ºä»€ä¹ˆä¼ ç»Ÿ Round-Robin ä¸é€‚åˆ LLM æ¨ç†
3. æè¿°ä» Gateway â†’ EPP â†’ InferencePool â†’ Pod çš„è¯·æ±‚è·¯å¾„
4. ä¸ºåŒ 11 AI å®¢æœåœºæ™¯è®¾è®¡åˆç†çš„ Priority åˆ†çº§

**ç±»æ¯”å¼ºåŒ–**ï¼š
> Inference Gateway å°±åƒç±³å…¶æ—ä¸‰æ˜Ÿé¤å…çš„**èµ„æ·±é¢†ç­ï¼ˆMaÃ®tre d'ï¼‰**ï¼š
> - ä¸åƒæ–°æ‰‹è¿å®¾å‘˜éšæœºå®‰æ’åº§ä½
> - ä»–æ·±è°™æ¯ä¸ªå¨æˆ¿å·¥ä½çš„å®æ—¶çŠ¶æ€
> - çŸ¥é“å“ªä¸ªå¨å¸ˆæ‰‹å¤´å•å¤šã€å“ªä¸ªåˆšåšè¿‡åŒæ ·çš„èœã€å“ªä¸ªå·¥ä½è¿˜æœ‰å¤‡é¤ç©ºé—´
> - VIP å®¢äººæ¥äº†ç«‹å³å®‰æ’ï¼Œæ™®é€šå®¢äººå¯ç¨ç­‰ï¼Œå¤–å–å¤§å•å¯å»¶å

---

### ğŸ”— ä¸‹ä¸€æ­¥æŒ‡å¼•

**è¿›å…¥èºæ—‹ 2 ä¹‹å‰**ï¼šå…ˆé€šè¿‡"è®¤çŸ¥é™å‹"ç¯èŠ‚ï¼Œå°†ç®—æ³•æŠ½è±¡ä¸ºå¸¸è¯†é€»è¾‘ã€‚

**è¡”æ¥é—®é¢˜**ï¼šEPP åˆ°åº•æ˜¯å¦‚ä½•"çœ‹"åˆ°æ¯ä¸ª Pod çš„çŠ¶æ€çš„ï¼Ÿå®ƒç”¨ä»€ä¹ˆç®—æ³•å†³å®šæŠŠè¯·æ±‚å‘ç»™å“ªä¸ª Podï¼Ÿ

---

## ğŸ’¨ è®¤çŸ¥é™å‹ï¼ˆDecompressionï¼‰

### ä¸ºä»€ä¹ˆéœ€è¦é™å‹ï¼Ÿ

å³å°†è¿›å…¥çš„èºæ—‹ 2 ä¼šæ¶‰åŠä»¥ä¸‹æ¦‚å¿µï¼š
- Queue Depthã€KV Cache Utilizationã€Prefix Cache å‘½ä¸­ç‡
- å¤šç»´åº¦è¯„åˆ†ç®—æ³•ã€æƒé‡è®¡ç®—
- Saturation Detectionã€ä¼˜é›…é™çº§

**å¬èµ·æ¥å¾ˆå¤æ‚ï¼Ÿ** å…¶å®åº•å±‚é€»è¾‘éå¸¸ç®€å•â€”â€”å°±åƒé¤å…é¢†ç­çœ‹ä»ªè¡¨ç›˜åšå†³ç­–ã€‚

---

### 2.1 é™å‹ï¼šEPP å°±æ˜¯"çœ‹ä»ªè¡¨ç›˜æ‰“åˆ†"

æƒ³è±¡ä½ æ˜¯ç±³å…¶æ—é¤å…çš„é¢†ç­ï¼Œé¢å‰æœ‰ä¸€ä¸ª**å®æ—¶ä»ªè¡¨ç›˜**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å¨æˆ¿å·¥ä½çŠ¶æ€ä»ªè¡¨ç›˜                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   å·¥ä½   â”‚  å¾…åšå•   â”‚  å¤‡é¤å°   â”‚  åˆšåšè¿‡   â”‚    ç»¼åˆè¯„åˆ†     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Pod-1    â”‚   â–ˆâ–ˆâ–ˆâ–ˆ   â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â”‚  å®«ä¿é¸¡ä¸ â”‚     65 åˆ†      â”‚
â”‚          â”‚  (4å•)   â”‚  (80%æ»¡) â”‚           â”‚                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Pod-2    â”‚   â–ˆ      â”‚   â–ˆâ–ˆ     â”‚  çº¢çƒ§è‚‰   â”‚     92 åˆ†      â”‚
â”‚          â”‚  (1å•)   â”‚  (20%æ»¡) â”‚   âœ“åŒ¹é…   â”‚      â˜…         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Pod-3    â”‚   â–ˆâ–ˆ     â”‚   â–ˆâ–ˆâ–ˆ    â”‚  ç³–é†‹æ’éª¨ â”‚     78 åˆ†      â”‚
â”‚          â”‚  (2å•)   â”‚  (40%æ»¡) â”‚           â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ–°è®¢å•ï¼šçº¢çƒ§è‚‰
å†³ç­–ï¼šå‘ç»™ Pod-2ï¼ˆåˆšåšè¿‡ã€å¤‡é¤å°ç©ºã€å¾…åšå•å°‘ï¼‰
```

**å¯¹åº”å…³ç³»**ï¼š

| é¤å…ä»ªè¡¨ç›˜ | EPP æŒ‡æ ‡ | å«ä¹‰ |
|-----------|---------|------|
| å¾…åšå•æ•°é‡ | **Queue Depth** | Pod çš„ç­‰å¾…é˜Ÿåˆ—é•¿åº¦ |
| å¤‡é¤å°å ç”¨ | **KV Cache Utilization** | GPU æ˜¾å­˜å ç”¨ç‡ |
| åˆšåšè¿‡ä»€ä¹ˆèœ | **Prefix Cache** | æœ€è¿‘å¤„ç†çš„ prompt å‰ç¼€ |
| å¨å¸ˆä¸“é•¿ | **LoRA Adapter** | ç‰¹å®šæ¨¡å‹é€‚é…å™¨ |

**è¯„åˆ†é€»è¾‘**ï¼ˆå¸¸è¯†ç‰ˆï¼‰ï¼š
```
æ€»åˆ† = (100 - å¾…åšå•æ•°Ã—10) Ã— æƒé‡
     + (100 - å¤‡é¤å°å ç”¨%) Ã— æƒé‡
     + (æ˜¯å¦åˆšåšè¿‡åŒæ ·èœ ? 100 : 0) Ã— æƒé‡
```

---

### 2.2 é™å‹ï¼šä¸‰ä¸ªæ ¸å¿ƒæŒ‡æ ‡çš„æœ¬è´¨

#### æŒ‡æ ‡ 1ï¼šQueue Depthï¼ˆé˜Ÿåˆ—æ·±åº¦ï¼‰

**å¸¸è¯†ç†è§£**ï¼šå¨å¸ˆæ‰‹ä¸Šæœ‰å¤šå°‘å•åœ¨ç­‰

```
Queue Depth = 0: å¨å¸ˆ idleï¼Œç«‹å³å¯ä»¥æ¥æ–°å• â˜…â˜…â˜…
Queue Depth = 2: å¨å¸ˆå¿™ç¢Œï¼Œä½†è¿˜èƒ½æ¥       â˜…â˜…â˜†
Queue Depth = 5: å¨å¸ˆçˆ†æ»¡ï¼Œæ–°å•è¦æ’é•¿é˜Ÿ   â˜…â˜†â˜†
```

**æŠ€æœ¯å«ä¹‰**ï¼š
- vLLM çš„ `num_requests_waiting` æŒ‡æ ‡
- åæ˜  Pod çš„å¹¶å‘å¤„ç†èƒ½åŠ›ä½™é‡
- é˜ˆå€¼é»˜è®¤ï¼šè¶…è¿‡ 5 è®¤ä¸ºé¥±å’Œ

#### æŒ‡æ ‡ 2ï¼šKV Cache Utilizationï¼ˆKV ç¼“å­˜åˆ©ç”¨ç‡ï¼‰

**å¸¸è¯†ç†è§£**ï¼šå¤‡é¤å°è¿˜æœ‰å¤šå°‘ç©ºé—´

```
KV Cache åˆ©ç”¨ç‡ = 30%: ç©ºé—´å……è£•ï¼Œå¤§å•ä¹Ÿèƒ½æ¥ â˜…â˜…â˜…
KV Cache åˆ©ç”¨ç‡ = 70%: ç©ºé—´ç´§å¼ ï¼Œåªèƒ½æ¥å°å• â˜…â˜…â˜†
KV Cache åˆ©ç”¨ç‡ = 90%: å‡ ä¹æ»¡äº†ï¼Œæ–°å•å¯èƒ½è¢«æ‹’ â˜…â˜†â˜†
```

**æŠ€æœ¯å«ä¹‰**ï¼š
- LLM çš„ Attention æœºåˆ¶éœ€è¦å­˜å‚¨ Key/Value å‘é‡
- å ç”¨æ˜¾å­˜ï¼Œä¸åºåˆ—é•¿åº¦æˆæ­£æ¯”
- é˜ˆå€¼é»˜è®¤ï¼šè¶…è¿‡ 80% è®¤ä¸ºé«˜é£é™©

#### æŒ‡æ ‡ 3ï¼šPrefix Cacheï¼ˆå‰ç¼€ç¼“å­˜ï¼‰

**å¸¸è¯†ç†è§£**ï¼šåŒæ ·çš„èœåˆšåšè¿‡ï¼Œç›´æ¥å¤ç”¨

```
Prompt: "è¯·ç”¨é²è¿…çš„é£æ ¼å†™ä¸€ç¯‡æ–‡ç« ï¼Œä¸»é¢˜æ˜¯..."

Pod-1: ç¼“å­˜å‘½ä¸­ "è¯·ç”¨é²è¿…çš„é£æ ¼å†™" â†’ åªéœ€ç»­å†™åé¢ï¼Œé€Ÿåº¦æå‡ 3 å€ â˜…â˜…â˜…
Pod-2: ç¼“å­˜æœªå‘½ä¸­ â†’ éœ€è¦å®Œæ•´é‡æ–°è®¡ç®—ï¼Œé€Ÿåº¦æ­£å¸¸
Pod-3: ç¼“å­˜æœªå‘½ä¸­ â†’ éœ€è¦å®Œæ•´é‡æ–°è®¡ç®—ï¼Œé€Ÿåº¦æ­£å¸¸

å†³ç­–ï¼šå‘ç»™ Pod-1
```

**æŠ€æœ¯å«ä¹‰**ï¼š
- vLLM çš„è‡ªåŠ¨ Prefix Caching åŠŸèƒ½
- ç›¸åŒå‰ç¼€çš„ prompt å¯ä»¥å¤ç”¨è®¡ç®—ç»“æœ
- å¯¹ RAGã€ç³»ç»Ÿæç¤ºè¯ç­‰åœºæ™¯æ•ˆæœæä½³

---

### 2.3 é™å‹ï¼šSaturation Detection å°±æ˜¯"æŒ‚å…æˆ˜ç‰Œ"

**å¸¸è¯†ç†è§£**ï¼šå½“é¤å…çˆ†æ»¡æ—¶ï¼Œé¢†ç­åœ¨é—¨å£æŒ‚"å…æˆ˜ç‰Œ"

```
é¤å…çŠ¶æ€æ£€æŸ¥ï¼š
â”œâ”€ å¹³å‡å¾…åšå• > 5ï¼Ÿ æ˜¯ â†’ è¿›å…¥é¥±å’ŒçŠ¶æ€
â”œâ”€ å¤‡é¤å°å ç”¨ > 80%ï¼Ÿ æ˜¯ â†’ è¿›å…¥é¥±å’ŒçŠ¶æ€
â””â”€ ä»»ä¸€æ¡ä»¶æ»¡è¶³ â†’ æŒ‚å…æˆ˜ç‰Œ

å…æˆ˜ç‰Œæ•ˆæœï¼š
â”œâ”€ VIP å®¢äººï¼šä»å¯è¿›å…¥ï¼ˆä¼˜å…ˆæ¥å¾…ï¼‰
â”œâ”€ æ™®é€šå®¢äººï¼šæ’é˜Ÿç­‰å¾…
â””â”€ å¤–å–å¤§å•ï¼šç›´æ¥æ‹’ç»ï¼ˆè¿”å› 429ï¼‰
```

**æŠ€æœ¯å«ä¹‰**ï¼š
- EPP çš„ SaturationDetector ç»„ä»¶
- å¤šç»´åº¦é˜ˆå€¼åˆ¤æ–­ç³»ç»Ÿæ•´ä½“è´Ÿè½½
- é¥±å’Œæ—¶æ ¹æ® Priority å†³å®šæ˜¯å¦ä¸¢å¼ƒè¯·æ±‚

---

### 2.4 é™å‹ï¼šå¤šæ¨¡å‹è·¯ç”±å°±æ˜¯"æŒ‰èœç³»åˆ†é…"

**å¸¸è¯†ç†è§£**ï¼šå·èœå¨å¸ˆä¸åšç²¤èœï¼Œé™¤éä»–å­¦è¿‡

```
è¯·æ±‚ï¼š" model: qwen-coder " â†’ å‘ç»™æœ‰ coder é€‚é…å™¨çš„ Pod
è¯·æ±‚ï¼š" model: llama3-70b " â†’ å‘ç»™åŠ è½½äº† llama3 çš„ Pod
è¯·æ±‚ï¼š" model: qwen-72b-lora-medicine " â†’ å‘ç»™æœ‰ medicine LoRA çš„ Pod
```

**æŠ€æœ¯å«ä¹‰**ï¼š
- BBR (Body Based Router) è§£æè¯·æ±‚ä½“ä¸­çš„ model å­—æ®µ
- æ ¹æ® Pod åŠ è½½çš„æ¨¡å‹/é€‚é…å™¨è¿›è¡ŒåŒ¹é…
- æ”¯æŒåŸºç¡€æ¨¡å‹ + LoRA é€‚é…å™¨çš„çµæ´»ç»„åˆ

---

### âœ… è®¤çŸ¥é™å‹éªŒæ”¶æ ‡å‡†

**ä½ èƒ½åšåˆ°**ï¼š
1. ç”¨é¤å…é¢†ç­çš„è§†è§’è§£é‡Š Queue Depthã€KV Cacheã€Prefix Cache
2. ç†è§£ä¸ºä»€ä¹ˆ"åŒæ ·çš„èœåˆšåšè¿‡"èƒ½åŠ é€Ÿï¼ˆPrefix Cacheï¼‰
3. ç†è§£"å…æˆ˜ç‰Œ"æœºåˆ¶ï¼ˆSaturation Detectionï¼‰
4. ä¸éœ€è¦è®°å¿†å…¬å¼ï¼Œåªéœ€è¦ç†è§£"æ‰“åˆ†é€»è¾‘"

**é™å‹å®Œæˆæ ‡å¿—**ï¼š
> ğŸ’¡ "åŸæ¥ EPP å°±æ˜¯ç»™æ¯ä¸ª Pod æ‰“åˆ†ï¼Œé€‰åˆ†æ•°æœ€é«˜çš„é‚£ä¸ªã€‚è¯„åˆ†æ ‡å‡†å°±æ˜¯'è°æœ€é—²ã€è°ç©ºé—´å¤šã€è°åˆšåšè¿‡ç±»ä¼¼çš„'ã€‚"

---

### ğŸ”— ä¸‹ä¸€æ­¥æŒ‡å¼•

ç°åœ¨ä½ å·²ç»ç†è§£äº†**å¸¸è¯†é€»è¾‘**ï¼Œå‡†å¤‡å¥½è¿›å…¥**æŠ€æœ¯ç»†èŠ‚**äº†å—ï¼Ÿ

èºæ—‹ 2 å°†æ·±å…¥è®²è§£ï¼š
- EPP å¦‚ä½•é‡‡é›†è¿™äº›æŒ‡æ ‡
- å…·ä½“çš„è¯„åˆ†ç®—æ³•å’Œæƒé‡é…ç½®
- Request Flow çš„å®Œæ•´æ—¶åº
- Prefix Cache çš„åŒ¹é…æœºåˆ¶

---

## ğŸŒ€ èºæ—‹ 2ï¼šæœºåˆ¶å±‚ï¼ˆHow-åŸç†ï¼‰

### æœ¬å±‚ç›®æ ‡
æ­ç¤ºåº•å±‚æœºåˆ¶ï¼Œç†è§£ EPP å¦‚ä½•é‡‡é›†æŒ‡æ ‡ã€è®¡ç®—è¯„åˆ†ã€åšå‡ºè·¯ç”±å†³ç­–ã€‚

---

### 2.1 æ¶æ„æ·±åº¦ï¼šEPP å†…éƒ¨ç»„ä»¶

```mermaid
flowchart TB
    subgraph "EPP (Endpoint Picker)"
        A[Metrics Receiver] --> B[Metrics Store]
        C[Pod Watcher] --> B
        D[Scorer Plugins] --> E[Scheduler]
        B --> D
        E --> F[Decision Engine]
    end
    
    G[Model Server Pods] -->|Prometheus Metrics| A
    H[K8s API Server] -->|Pod Events| C
    F -->|Selected Endpoint| I[Gateway]
    
    style A fill:#e1f5fe
    style B fill:#fff3e0
    style E fill:#e8f5e9
    style F fill:#f3e5f5
```

#### ç»„ä»¶èŒè´£

| ç»„ä»¶ | èŒè´£ | ç±»æ¯” |
|------|------|------|
| **Metrics Receiver** | æ¥æ”¶æ¨¡å‹æœåŠ¡å™¨çš„ Prometheus æŒ‡æ ‡ | å·¥ä½ä¼ å‘¼æœº |
| **Pod Watcher** | Watch K8s APIï¼Œè·Ÿè¸ª Pod ç”Ÿå‘½å‘¨æœŸ | äººå‘˜è€ƒå‹¤ç³»ç»Ÿ |
| **Metrics Store** | ç¼“å­˜æœ€æ–°æŒ‡æ ‡ï¼Œæä¾›æŸ¥è¯¢ | å®æ—¶ä»ªè¡¨ç›˜ |
| **Scorer Plugins** | å¤šç»´åº¦è¯„åˆ†ï¼ˆQueue/KV/Prefixï¼‰| æ‰“åˆ†è¯„å§” |
| **Scheduler** | ç»¼åˆè¯„åˆ†ï¼Œé€‰æ‹©æœ€ä¼˜ Pod | é¢†ç­å†³ç­– |
| **Decision Engine** | ç”Ÿæˆè·¯ç”±æŒ‡ä»¤è¿”å›ç»™ Gateway | æ´¾å·ç³»ç»Ÿ |

---

### 2.2 æŒ‡æ ‡é‡‡é›†æœºåˆ¶

#### æŒ‡æ ‡æ¥æºï¼švLLM çš„ `/metrics` ç«¯ç‚¹

```yaml
# vLLM æš´éœ²çš„å…³é”®æŒ‡æ ‡
vllm:num_requests_running          # æ­£åœ¨å¤„ç†çš„è¯·æ±‚æ•°
vllm:num_requests_waiting          # é˜Ÿåˆ—ä¸­ç­‰å¾…çš„è¯·æ±‚æ•°ï¼ˆQueue Depthï¼‰
vllm:gpu_cache_usage_perc          # GPU KV Cache åˆ©ç”¨ç‡
vllm:cpu_cache_usage_perc          # CPU KV Cache åˆ©ç”¨ç‡
vllm:prompt_tokens                 # è¾“å…¥ token æ•°
vllm:generation_tokens             # è¾“å‡º token æ•°
```

**é‡‡é›†é¢‘ç‡**ï¼šé»˜è®¤æ¯ 50ms æ‹‰å–ä¸€æ¬¡ï¼ˆå¯é…ç½®ï¼‰

#### EPP çš„æŒ‡æ ‡èšåˆ

```python
# ä¼ªä»£ç ï¼šæŒ‡æ ‡èšåˆé€»è¾‘
class MetricsAggregator:
    def __init__(self):
        self.pod_metrics = {}  # Pod åç§° -> æœ€æ–°æŒ‡æ ‡
        self.metrics_ttl = 200  # 200ms è¶…æ—¶è§†ä¸ºè¿‡æœŸ
    
    def update_metrics(self, pod_name, metrics):
        """æ›´æ–°æŒ‡å®š Pod çš„æŒ‡æ ‡"""
        self.pod_metrics[pod_name] = {
            'timestamp': time.now(),
            'queue_depth': metrics['num_requests_waiting'],
            'kv_cache_util': metrics['gpu_cache_usage_perc'],
            'running_reqs': metrics['num_requests_running'],
        }
    
    def get_valid_pods(self):
        """è¿”å›æŒ‡æ ‡æœªè¿‡æœŸçš„ Pod åˆ—è¡¨"""
        valid = []
        for pod, data in self.pod_metrics.items():
            if time.now() - data['timestamp'] < self.metrics_ttl:
                valid.append(pod)
        return valid
```

---

### 2.3 å¤šç»´åº¦è¯„åˆ†ç®—æ³•

#### æ ¸å¿ƒæ¦‚å¿µï¼šPlugin-Based Scoring

EPP é‡‡ç”¨**æ’ä»¶åŒ–è¯„åˆ†æœºåˆ¶**ï¼Œæ¯ä¸ª Scorer è´Ÿè´£ä¸€ä¸ªç»´åº¦ï¼Œæœ€ç»ˆåŠ æƒæ±‚å’Œã€‚

```mermaid
flowchart LR
    Request([Incoming Request]) --> A[Queue Scorer]
    Request --> B[KV Cache Scorer]
    Request --> C[Prefix Cache Scorer]
    Request --> D[Latency Predictor]
    
    A -->|Score_A Ã— Weight_A| E[Weighted Sum]
    B -->|Score_B Ã— Weight_B| E
    C -->|Score_C Ã— Weight_C| E
    D -->|Score_D Ã— Weight_D| E
    
    E --> F[Total Score]
    F --> G[Select Max Score Pod]
    
    style E fill:#e1f5fe
    style G fill:#e8f5e9
```

#### Scorer 1ï¼šQueue Scorer

**é€»è¾‘**ï¼šQueue è¶ŠçŸ­è¶Šå¥½

```python
def queue_score(queue_depth, max_queue=10):
    """
    queue_depth: å½“å‰é˜Ÿåˆ—æ·±åº¦
    max_queue: æœ€å¤§å¯æ¥å—é˜Ÿåˆ—æ·±åº¦ï¼ˆé»˜è®¤ 10ï¼‰
    """
    if queue_depth >= max_queue:
        return 0  # æ»¡è½½ï¼Œä¸å¾—åˆ†
    
    # çº¿æ€§é€’å‡ï¼šqueue=0 å¾— 100 åˆ†ï¼Œqueue=9 å¾— 10 åˆ†
    return 100 * (1 - queue_depth / max_queue)
```

**ç¤ºä¾‹**ï¼š
| Queue Depth | Score | è¯´æ˜ |
|-------------|-------|------|
| 0 | 100 | ç©ºé—²ï¼Œæœ€ä¼˜ |
| 2 | 80 | è½»åº¦è´Ÿè½½ |
| 5 | 50 | ä¸­åº¦è´Ÿè½½ |
| 9 | 10 | æ¥è¿‘é¥±å’Œ |
| 10 | 0 | æ»¡è½½ï¼Œä¸å¯ç”¨ |

#### Scorer 2ï¼šKV Cache Utilization Scorer

**é€»è¾‘**ï¼šKV Cache åˆ©ç”¨ç‡è¶Šä½è¶Šå¥½

```python
def kv_cache_score(utilization, threshold=0.8):
    """
    utilization: KV Cache åˆ©ç”¨ç‡ (0.0 - 1.0)
    threshold: é¥±å’Œé˜ˆå€¼ï¼ˆé»˜è®¤ 0.8ï¼‰
    """
    if utilization >= threshold:
        return 0  # è¶…è¿‡é˜ˆå€¼ï¼Œä¸å¾—åˆ†
    
    # çº¿æ€§é€’å‡ï¼šutil=0% å¾— 100 åˆ†ï¼Œutil=79% å¾— 21 åˆ†
    return 100 * (1 - utilization / threshold)
```

**ç¤ºä¾‹**ï¼š
| Utilization | Score | è¯´æ˜ |
|-------------|-------|------|
| 0% | 100 | æ˜¾å­˜å……è£• |
| 40% | 50 | ä¸­ç­‰å ç”¨ |
| 79% | 1 | æ¥è¿‘é˜ˆå€¼ |
| 80% | 0 | é¥±å’Œ |

#### Scorer 3ï¼šPrefix Cache Scorer

**é€»è¾‘**ï¼šPrefix åŒ¹é…åº¦è¶Šé«˜è¶Šå¥½

```python
def prefix_cache_score(request_prompt, pod_cache):
    """
    request_prompt: è¯·æ±‚ä¸­çš„ prompt
    pod_cache: Pod çš„ Prefix Cache å†…å®¹ï¼ˆLRU ç¼“å­˜æœ€è¿‘ N ä¸ª prefixï¼‰
    """
    max_score = 0
    
    for cached_prefix in pod_cache:
        # è®¡ç®—æœ€é•¿å…¬å…±å‰ç¼€é•¿åº¦
        match_len = longest_common_prefix(request_prompt, cached_prefix)
        
        # åŒ¹é…é•¿åº¦å æ€»é•¿åº¦çš„æ¯”ä¾‹
        match_ratio = match_len / len(request_prompt)
        
        # åŒ¹é…è¶Šå¤šå¾—åˆ†è¶Šé«˜
        score = 100 * match_ratio
        max_score = max(max_score, score)
    
    return max_score
```

**ç¤ºä¾‹**ï¼š
```
è¯·æ±‚ Prompt: "è¯·ç”¨é²è¿…çš„é£æ ¼å†™ä¸€ç¯‡æ–‡ç« ï¼Œä¸»é¢˜æ˜¯äººå·¥æ™ºèƒ½"

Pod-1 Cache: "è¯·ç”¨é²è¿…çš„é£æ ¼å†™" â†’ åŒ¹é… 10 tokens â†’ Score = 40
Pod-2 Cache: "è¯·ç”¨æç™½çš„é£æ ¼å†™" â†’ åŒ¹é… 0 tokens â†’ Score = 0
Pod-3 Cache: "è¯·ç”¨é²è¿…çš„é£æ ¼å†™ä¸€ç¯‡æ–‡ç« " â†’ åŒ¹é… 13 tokens â†’ Score = 52

å†³ç­–ï¼šé€‰æ‹© Pod-3ï¼ˆåŒ¹é…åº¦æœ€é«˜ï¼‰
```

**Prefix Cache åŒ¹é…ç²’åº¦**ï¼š
- åŸºäº **block** åŒ¹é…ï¼Œè€Œéå­—ç¬¦
- é»˜è®¤ block_size = 16 tokens
- åŒ¹é… 1 ä¸ª block = 16 tokens çš„å¤ç”¨

#### ç»¼åˆè¯„åˆ†è®¡ç®—

```python
def calculate_total_score(pod, request, weights):
    """
    ç»¼åˆè¯„åˆ† = Î£ (å•é¡¹è¯„åˆ† Ã— æƒé‡)
    """
    scores = {
        'queue': queue_score(pod.queue_depth),
        'kv_cache': kv_cache_score(pod.kv_cache_util),
        'prefix': prefix_cache_score(request.prompt, pod.cache),
    }
    
    total = 0
    for metric, score in scores.items():
        total += score * weights[metric]
    
    return total

# é»˜è®¤æƒé‡é…ç½®
DEFAULT_WEIGHTS = {
    'queue': 2.0,
    'kv_cache': 2.0,
    'prefix': 3.0,
}

# ç¤ºä¾‹è®¡ç®—
Pod-A: queue=100, kv=80, prefix=40
       â†’ 100Ã—2 + 80Ã—2 + 40Ã—3 = 200 + 160 + 120 = 480

Pod-B: queue=60, kv=90, prefix=100
       â†’ 60Ã—2 + 90Ã—2 + 100Ã—3 = 120 + 180 + 300 = 600

# Pod-B å¾—åˆ†æ›´é«˜ï¼Œä¼˜å…ˆé€‰æ‹©
```

---

### 2.4 Request Flow æ—¶åºè¯¦è§£

```mermaid
sequenceDiagram
    participant Client
    participant Gateway
    participant EPP
    participant Pod1 as Pod 1
    participant Pod2 as Pod 2

    Note over Pod1,Pod2: æŒç»­ä¸ŠæŠ¥æŒ‡æ ‡
    Pod1->>EPP: POST /metrics (queue=2, kv=0.3)
    Pod2->>EPP: POST /metrics (queue=5, kv=0.8)

    Client->>Gateway: POST /v1/completions
    Note right of Client: Body: {model: "qwen", prompt: "..."}
    
    Gateway->>EPP: ext-proc: RequestHeaders
    
    EPP->>EPP: æŸ¥è¯¢å„ Pod æœ€æ–°æŒ‡æ ‡
    EPP->>EPP: Queue Scorer è¯„åˆ†
    EPP->>EPP: KV Cache Scorer è¯„åˆ†
    EPP->>EPP: Prefix Cache Scorer è¯„åˆ†
    EPP->>EPP: åŠ æƒæ±‚å’Œï¼Œé€‰æ‹©æœ€é«˜åˆ† Pod
    
    EPP->>Gateway: ext-proc: Response (selected: Pod1)
    
    Gateway->>Pod1: è½¬å‘è¯·æ±‚
    Pod1->>Gateway: è¿”å›å“åº”
    Gateway->>Client: è¿”å›ç»“æœ
```

**æ—¶åºè¯´æ˜**ï¼š
1. **æŒ‡æ ‡ä¸ŠæŠ¥ï¼ˆå¼‚æ­¥ï¼‰**ï¼šPod æŒç»­å‘ EPP æ¨é€æŒ‡æ ‡
2. **è¯·æ±‚åˆ°è¾¾**ï¼šClient å‘é€è¯·æ±‚åˆ° Gateway
3. **Extension Processing**ï¼šGateway é€šè¿‡ Envoy ext-proc è°ƒç”¨ EPP
4. **è·¯ç”±å†³ç­–**ï¼šEPP æŸ¥è¯¢æŒ‡æ ‡ã€è®¡ç®—è¯„åˆ†ã€é€‰æ‹© Pod
5. **è¯·æ±‚è½¬å‘**ï¼šGateway å°†è¯·æ±‚è·¯ç”±åˆ°é€‰ä¸­çš„ Pod

**å…³é”®å»¶è¿Ÿ**ï¼š
- EPP å†³ç­–å»¶è¿Ÿï¼šé€šå¸¸ < 1ms
- æŒ‡æ ‡æ–°é²œåº¦ï¼šé»˜è®¤ 200ms TTL

---

### 2.5 Saturation Detection æœºåˆ¶

#### é¥±å’Œåˆ¤å®šé€»è¾‘

```python
class SaturationDetector:
    def __init__(self):
        self.queue_threshold = 5        # é˜Ÿåˆ—æ·±åº¦é˜ˆå€¼
        self.kv_threshold = 0.8         # KV Cache é˜ˆå€¼
        self.metrics_staleness = 200    # æŒ‡æ ‡è¿‡æœŸæ—¶é—´ï¼ˆmsï¼‰
    
    def is_saturated(self, pod_metrics):
        """åˆ¤å®šå•ä¸ª Pod æ˜¯å¦é¥±å’Œ"""
        # æ£€æŸ¥æŒ‡æ ‡æ–°é²œåº¦
        if self.is_stale(pod_metrics):
            return True  # è¿‡æœŸè§†ä¸ºé¥±å’Œï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        
        # æ£€æŸ¥é˜Ÿåˆ—æ·±åº¦
        if pod_metrics.queue_depth >= self.queue_threshold:
            return True
        
        # æ£€æŸ¥ KV Cache
        if pod_metrics.kv_cache_util >= self.kv_threshold:
            return True
        
        return False
    
    def is_pool_saturated(self, pool_metrics):
        """åˆ¤å®šæ•´ä¸ª Pool æ˜¯å¦é¥±å’Œ"""
        # å¦‚æœæ‰€æœ‰ Pod éƒ½é¥±å’Œï¼Œåˆ™ Pool é¥±å’Œ
        all_saturated = all(
            self.is_saturated(pod) for pod in pool_metrics
        )
        return all_saturated
```

#### é¥±å’Œæ—¶çš„è¯·æ±‚å¤„ç†

```mermaid
flowchart TD
    A[Request Arrives] --> B{Pool Saturated?}
    B -->|No| C[æ­£å¸¸è·¯ç”±]
    B -->|Yes| D{Request Priority?}
    
    D -->|Critical<br/>>= 0| E[å…è®¸æ’é˜Ÿ]
    D -->|Sheddable<br/>< 0| F[è¿”å› 429]
    
    E --> G[ç­‰å¾…å¯ç”¨ Pod]
    F --> H[å®¢æˆ·ç«¯é‡è¯•/é™çº§]
    
    style B fill:#fff3e0
    style F fill:#ffebee
```

**é˜ˆå€¼é…ç½®ç¤ºä¾‹**ï¼š
```yaml
# EPP é…ç½®æ–‡ä»¶
saturationDetector:
  queueDepthThreshold: 5          # é˜Ÿåˆ—æ·±åº¦é˜ˆå€¼
  kvCacheUtilThreshold: 0.8       # KV Cache é˜ˆå€¼
  metricsStalenessThreshold: 200  # æŒ‡æ ‡è¿‡æœŸæ—¶é—´ï¼ˆmsï¼‰
```

---

### 2.6 Prefix Cache æ·±åº¦è§£æ

#### Block-Based Matching

Prefix Cache ä¸æ˜¯å­—ç¬¦çº§åŒ¹é…ï¼Œè€Œæ˜¯ **Block çº§åŒ¹é…**ï¼ˆé»˜è®¤ 16 tokens/blockï¼‰ã€‚

```
Prompt: "è¯·ç”¨é²è¿…çš„é£æ ¼å†™ä¸€ç¯‡æ–‡ç« "
Tokenized: [è¯·, ç”¨, é², è¿…, çš„, é£, æ ¼, å†™, ä¸€, ç¯‡, æ–‡, ç« ]

Block åˆ’åˆ†ï¼ˆblock_size=4ï¼‰:
Block 0: [è¯·, ç”¨, é², è¿…]
Block 1: [çš„, é£, æ ¼, å†™]
Block 2: [ä¸€, ç¯‡, æ–‡, ç« ]

åŒ¹é…ç­–ç•¥ï¼š
- åŒ¹é… 1 ä¸ª block = å¤ç”¨ 4 tokens çš„ KV Cache
- åŒ¹é… 3 ä¸ª blocks = å¤ç”¨ 12 tokensï¼Œåªéœ€è®¡ç®—å‰©ä½™éƒ¨åˆ†
```

#### LRU ç¼“å­˜ç­–ç•¥

æ¯ä¸ª Pod ç»´æŠ¤ä¸€ä¸ª LRU (Least Recently Used) Cacheï¼š

```python
class PrefixCache:
    def __init__(self, capacity=31250):  # é»˜è®¤å®¹é‡
        self.capacity = capacity  # æœ€å¤šç¼“å­˜å¤šå°‘ blocks
        self.cache = OrderedDict()  # LRU ç»“æ„
    
    def get(self, prefix_hash):
        if prefix_hash in self.cache:
            # ç§»åŠ¨åˆ°é˜Ÿå°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
            self.cache.move_to_end(prefix_hash)
            return self.cache[prefix_hash]
        return None
    
    def put(self, prefix_hash, blocks):
        if prefix_hash in self.cache:
            self.cache.move_to_end(prefix_hash)
        else:
            if len(self.cache) >= self.capacity:
                # æ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„
                self.cache.popitem(last=False)
            self.cache[prefix_hash] = blocks
```

**é…ç½®å‚æ•°**ï¼š
```yaml
prefix-cache-scorer:
  parameters:
    blockSize: 16                  # æ¯ä¸ª block çš„ token æ•°
    maxPrefixBlocksToMatch: 512    # æœ€å¤§åŒ¹é… block æ•°
    lruCapacityPerServer: 31250    # æ¯ä¸ª Pod çš„ LRU å®¹é‡
```

---

### âœ… èºæ—‹ 2 éªŒæ”¶æ ‡å‡†

**ä½ èƒ½åšåˆ°**ï¼š
1. è§£é‡Š EPP çš„ 4 ä¸ªæ ¸å¿ƒç»„ä»¶åŠå…¶èŒè´£
2. æ‰‹åŠ¨è®¡ç®—ä¸€ä¸ªè¯·æ±‚çš„ Queue/KV/Prefix è¯„åˆ†
3. ç”»å‡º Request Flow çš„å®Œæ•´æ—¶åºå›¾
4. é…ç½® Saturation Detection çš„é˜ˆå€¼
5. è§£é‡Š Block-Based Prefix Matching çš„åŸç†

**æ ¸å¿ƒå…¬å¼è®°å¿†**ï¼š
```
æ€»è¯„åˆ† = QueueScore Ã— 2 + KVCacheScore Ã— 2 + PrefixScore Ã— 3
é¥±å’Œåˆ¤å®š = queue â‰¥ 5 OR kv_cache â‰¥ 0.8 OR metrics_stale
```

---

### ğŸ”— ä¸‹ä¸€æ­¥æŒ‡å¼•

ç†è®ºå·²æŒæ¡ï¼Œå¦‚ä½•è½åœ°ï¼Ÿ

èºæ—‹ 3 å°†å¸¦ä½ è¿›å…¥å®æˆ˜ï¼š
- å®Œæ•´çš„éƒ¨ç½² YAML å’Œ Helm Chart é…ç½®
- ç”Ÿäº§ç¯å¢ƒè°ƒä¼˜å‚æ•°
- å…¸å‹æ•…éšœçš„æ’éšœè·¯å¾„
- SLI/SLO è®¾è®¡å’Œæˆæœ¬æƒè¡¡

---

## ğŸŒ€ èºæ—‹ 3ï¼šå®æˆ˜å±‚ï¼ˆHow-è¿ç»´ï¼‰

### æœ¬å±‚ç›®æ ‡
å…·å¤‡å®æ“èƒ½åŠ›ï¼Œèƒ½ç‹¬ç«‹éƒ¨ç½²ã€è°ƒä¼˜ã€ç›‘æ§ï¼Œå¹¶èƒ½å¤„ç†å…¸å‹æ•…éšœã€‚

---

### 3.1 ç”Ÿäº§éƒ¨ç½²å®æˆ˜

#### éƒ¨ç½²æ¶æ„ï¼ˆåŒ 11 åœºæ™¯ç¤ºä¾‹ï¼‰

```mermaid
flowchart TB
    subgraph "æµé‡å…¥å£å±‚"
        LB[External LB]
        LB --> GW1[Gateway Pod 1]
        LB --> GW2[Gateway Pod 2]
    end
    
    subgraph "æ§åˆ¶å±‚"
        EPP1[EPP Pod 1]
        EPP2[EPP Pod 2]
    end
    
    subgraph "æ¨ç†å±‚ï¼ˆGPU Nodesï¼‰"
        subgraph "Pool: qwen-72b"
            P1[Pod 1<br/>A100]
            P2[Pod 2<br/>A100]
            P3[Pod 3<br/>A100]
        end
    end
    
    GW1 --> EPP1
    GW2 --> EPP2
    EPP1 --> P1
    EPP1 --> P2
    EPP1 --> P3
    EPP2 --> P1
    EPP2 --> P2
    EPP2 --> P3
    
    style LB fill:#e1f5fe
    style EPP1 fill:#fff3e0
    style P1 fill:#e8f5e9
```

#### å®Œæ•´éƒ¨ç½²æ¸…å•

**Step 1ï¼šéƒ¨ç½²æ¨¡å‹æœåŠ¡å™¨ï¼ˆvLLMï¼‰**

```yaml
# vllm-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-qwen-72b
  labels:
    app: vllm-qwen-72b
    model: qwen-72b-instruct
spec:
  replicas: 3
  selector:
    matchLabels:
      app: vllm-qwen-72b
  template:
    metadata:
      labels:
        app: vllm-qwen-72b
        model: qwen-72b-instruct
    spec:
      nodeSelector:
        nvidia.com/gpu.product: NVIDIA-A100
      containers:
      - name: vllm
        image: vllm/vllm-openai:v0.5.0
        args:
        - --model
        - Qwen/Qwen2-72B-Instruct
        - --tensor-parallel-size
        - "4"  # 4 GPU per Pod
        - --enable-prefix-caching
        - --max-model-len
        - "32768"
        ports:
        - containerPort: 8000
          name: http
        resources:
          limits:
            nvidia.com/gpu: "4"
            memory: "256Gi"
            cpu: "32"
        env:
        - name: VLLM_LOGGING_LEVEL
          value: "INFO"
```

**Step 2ï¼šéƒ¨ç½² InferencePool**

```yaml
# inferencepool.yaml
apiVersion: inference.networking.k8s.io/v1
kind: InferencePool
metadata:
  name: qwen-72b-pool
spec:
  selector:
    matchLabels:
      model: qwen-72b-instruct
  port: 8000
  extensionRef:
    name: epp-qwen-72b
```

**Step 3ï¼šéƒ¨ç½² EPPï¼ˆHelmï¼‰**

```bash
# æ·»åŠ  Helm ä»“åº“
helm repo add inference-extension \
  oci://registry.k8s.io/gateway-api-inference-extension/charts

# éƒ¨ç½² InferencePool + EPP
helm install qwen-72b-pool \
  --set inferencePool.modelServers.matchLabels.app=vllm-qwen-72b \
  --set inferencePool.modelServerType=vllm \
  --set provider.name=istio \
  inference-extension/inferencepool
```

**Step 4ï¼šé…ç½® Gateway å’Œ HTTPRoute**

```yaml
# gateway.yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: inference-gateway
spec:
  gatewayClassName: istio
  listeners:
  - name: http
    protocol: HTTP
    port: 80
---
# httproute.yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: qwen-72b-route
spec:
  parentRefs:
  - name: inference-gateway
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /v1/chat/completions
    backendRefs:
    - group: inference.networking.x-k8s.io
      kind: InferencePool
      name: qwen-72b-pool
```

**Step 5ï¼šé…ç½® InferenceObjectiveï¼ˆä¼˜å…ˆçº§ï¼‰**

```yaml
# critical-objective.yaml
apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: InferenceObjective
metadata:
  name: critical-chat
spec:
  priority: 100
  poolRef:
    name: qwen-72b-pool
---
# batch-objective.yaml
apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: InferenceObjective
metadata:
  name: batch-processing
spec:
  priority: -50  # å¯ä¸¢å¼ƒ
  poolRef:
    name: qwen-72b-pool
```

---

### 3.2 ç”Ÿäº§ç¯å¢ƒè°ƒä¼˜å‚æ•°

#### å…³é”®é…ç½®é¡¹

```yaml
# epp-config.yaml
apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: EndpointPickerConfig
plugins:
- type: queue-scorer
- type: kv-cache-utilization-scorer
- type: prefix-cache-scorer
  parameters:
    blockSize: 16
    maxPrefixBlocksToMatch: 512
    lruCapacityPerServer: 31250
- type: predicted-latency-scorer
  parameters:
    samplingMean: 1000.0

schedulingProfiles:
- name: default
  plugins:
  - pluginRef: queue-scorer
    weight: 2
  - pluginRef: kv-cache-utilization-scorer
    weight: 2
  - pluginRef: prefix-cache-scorer
    weight: 3

saturationDetector:
  queueDepthThreshold: 5
  kvCacheUtilThreshold: 0.8
  metricsStalenessThreshold: 200
```

#### è°ƒä¼˜å»ºè®®

| åœºæ™¯ | Queue Threshold | KV Threshold | Prefix Weight | è¯´æ˜ |
|------|----------------|--------------|---------------|------|
| **å»¶è¿Ÿæ•æ„Ÿ** | 3 | 0.7 | 4 | æ›´æ¿€è¿›åœ°é¿å¼€äº†è´Ÿè½½é«˜çš„ Pod |
| **ååä¼˜å…ˆ** | 8 | 0.9 | 2 | å®¹å¿æ›´é«˜è´Ÿè½½ï¼Œè¿½æ±‚å¹¶å‘ |
| **Prefix Cache å¯†é›†** | 5 | 0.8 | 5 | RAG åœºæ™¯ï¼Œæœ€å¤§åŒ–ç¼“å­˜å‘½ä¸­ |
| **GPU å—é™** | 5 | 0.6 | 3 | ä¸¥æ ¼é™åˆ¶ KV Cache ä½¿ç”¨ |

---

### 3.3 å¯è§‚æµ‹æ€§ä½“ç³»

#### å…³é”®æŒ‡æ ‡ï¼ˆSLIï¼‰

```yaml
# Prometheus ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: inference-gateway-metrics
spec:
  selector:
    matchLabels:
      app: inference-gateway
  endpoints:
  - port: metrics
    interval: 15s
```

**æ ¸å¿ƒç›‘æ§æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡å | ç±»å‹ | è¯´æ˜ | å‘Šè­¦é˜ˆå€¼ |
|--------|------|------|---------|
| `inference_request_duration_seconds` | Histogram | è¯·æ±‚å»¶è¿Ÿ | P99 > 5s |
| `inference_requests_total` | Counter | è¯·æ±‚æ•° | - |
| `inference_queue_depth` | Gauge | é˜Ÿåˆ—æ·±åº¦ | > 8 |
| `inference_kv_cache_utilization` | Gauge | KV Cache ä½¿ç”¨ç‡ | > 0.85 |
| `inference_prefix_cache_hit_ratio` | Gauge | Prefix Cache å‘½ä¸­ç‡ | < 0.3 |
| `inference_shedded_requests_total` | Counter | ä¸¢å¼ƒè¯·æ±‚æ•° | > 100/min |

#### SLO è®¾è®¡å»ºè®®

```yaml
# SLO å®šä¹‰
apiVersion: n/a
kind: SLODefinition
spec:
  objectives:
  - name: latency
    displayName: "TTFT P99 Latency"
    target: 0.95  # 95% çš„è¯·æ±‚ TTFT < 500ms
    threshold: 500ms
    
  - name: availability
    displayName: "Service Availability"
    target: 0.999  # 99.9% å¯ç”¨æ€§
    
  - name: throughput
    displayName: "QPS"
    target: 1000  # å• Pool 1000 QPS
    
  - name: gpu_utilization
    displayName: "GPU Utilization"
    target: 0.80  # ç›®æ ‡ 80% åˆ©ç”¨ç‡
    min: 0.60     # ä½äº 60% è¯´æ˜èµ„æºæµªè´¹
    max: 0.95     # é«˜äº 95% å¯èƒ½è¿‡è½½
```

#### Dashboard å…³é”®é¢æ¿

```mermaid
flowchart TB
    subgraph "Inference Gateway Dashboard"
        A[è¯·æ±‚é‡/QPS]
        B[å»¶è¿Ÿåˆ†å¸ƒ P50/P95/P99]
        C[Queue Depth çƒ­åŠ›å›¾]
        D[KV Cache åˆ©ç”¨ç‡]
        E[Prefix Cache å‘½ä¸­ç‡]
        F[Pod å¥åº·çŠ¶æ€]
        G[Shedded Requests ç‡]
    end
    
    style A fill:#e1f5fe
    style B fill:#fff3e0
    style G fill:#ffebee
```

---

### 3.4 å…¸å‹æ•…éšœä¸æ’éšœ

#### æ•…éšœå†³ç­–æ ‘

```mermaid
flowchart TD
    A[ç”¨æˆ·åé¦ˆé—®é¢˜] --> B{é”™è¯¯ç±»å‹?}
    
    B -->|429| C[System Saturated]
    B -->|503| D[No Healthy Upstream]
    B -->|502| E[Upstream Connection Error]
    B -->|å»¶è¿Ÿé«˜| F[Performance Issue]
    B -->|è·¯ç”±ä¸å‡| G[Unexpected Routing]
    
    C --> H{Priority?}
    H -->|Critical| I[æ‰©å®¹ Pod]
    H -->|Sheddable| J[é¢„æœŸè¡Œä¸º]
    
    D --> K{Pod çŠ¶æ€?}
    K -->|CrashLoop| L[æ£€æŸ¥ EPP æ—¥å¿—]
    K -->|Running| M[æ£€æŸ¥å¥åº·æ£€æŸ¥é…ç½®]
    
    E --> N{Port é…ç½®?}
    N -->|ä¸åŒ¹é…| O[ä¿®æ­£ InferencePool port]
    N -->|åŒ¹é…| P[æ£€æŸ¥ç½‘ç»œç­–ç•¥]
    
    F --> Q{TTFT é«˜?}
    Q -->|æ˜¯| R[æ£€æŸ¥ Prefix Cache é…ç½®]
    Q -->|å¦| S[æ£€æŸ¥ Batch Size]
    
    G --> T{Metrics æ­£å¸¸?}
    T -->|å¦| U[æ£€æŸ¥ Scorer Weights]
    T -->|æ˜¯| V[æ£€æŸ¥ Pod æ ‡ç­¾]
    
    style C fill:#ffebee
    style D fill:#ffebee
    style F fill:#fff3e0
```

#### æ•…éšœ 1ï¼š429 Too Many Requests

**ç—‡çŠ¶**ï¼šå®¢æˆ·ç«¯æ”¶åˆ° `429 system saturated, sheddable request dropped`

**æ ¹å› åˆ†æ**ï¼š
```bash
# æ£€æŸ¥ Pod é˜Ÿåˆ—æ·±åº¦
kubectl top pods -l model=qwen-72b-instruct

# æ£€æŸ¥ EPP æ—¥å¿—
kubectl logs -l app=epp-qwen-72b | grep "saturated"
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. **ä¸´æ—¶**ï¼šå¢åŠ  Pod å‰¯æœ¬æ•°
   ```bash
   kubectl scale deployment vllm-qwen-72b --replicas=5
   ```
2. **é•¿æœŸ**ï¼šä¼˜åŒ– Threshold é…ç½®
   ```yaml
   saturationDetector:
     queueDepthThreshold: 8  # æ”¾å®½é˜ˆå€¼
   ```
3. **æ¶æ„**ï¼šæ¥å…¥è‡ªåŠ¨æ‰©ç¼©å®¹ï¼ˆHPA/KEDAï¼‰

#### æ•…éšœ 2ï¼š503 No Healthy Upstream

**ç—‡çŠ¶**ï¼šGateway è¿”å› `503 no healthy upstream`

**æ’æŸ¥æ­¥éª¤**ï¼š
```bash
# 1. æ£€æŸ¥ Pod çŠ¶æ€
kubectl get pods -l model=qwen-72b-instruct

# 2. æ£€æŸ¥ Pod æ—¥å¿—
kubectl logs <pod-name>

# 3. æ£€æŸ¥ InferencePool çŠ¶æ€
kubectl get inferencepool qwen-72b-pool -o yaml

# 4. éªŒè¯ç«¯å£é…ç½®
kubectl get pod <pod-name> -o jsonpath='{.spec.containers[0].ports}'
```

**å¸¸è§åŸå› **ï¼š
- Pod æœª readyï¼ˆ readiness probe å¤±è´¥ï¼‰
- InferencePool é…ç½®çš„ port ä¸ Pod å®é™…ç«¯å£ä¸åŒ¹é…
- Pod æ ‡ç­¾ä¸ InferencePool selector ä¸åŒ¹é…

#### æ•…éšœ 3ï¼šTTFT å»¶è¿ŸæŠ–åŠ¨

**ç—‡çŠ¶**ï¼šTime To First Token å¶å°”é£™å‡åˆ°æ•°ç§’

**æ ¹å› åˆ†æ**ï¼š
```bash
# æ£€æŸ¥ Prefix Cache å‘½ä¸­ç‡
kubectl logs -l app=epp-qwen-72b | grep "prefix_cache"

# å¯¹æ¯”é…ç½®
kubectl get configmap epp-config -o yaml
```

**å¸¸è§åŸå› **ï¼š
- Prefix Cache å‚æ•°ä¸ vLLM å®é™…é…ç½®ä¸åŒ¹é…
- `blockSize`ã€`lruCapacityPerServer` é…ç½®é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
```yaml
# ç¡®ä¿ EPP é…ç½®ä¸ vLLM å®é™…å‚æ•°ä¸€è‡´
prefix-cache-scorer:
  parameters:
    blockSize: 16  # å¿…é¡»ä¸ vLLM çš„ block_size ä¸€è‡´
    lruCapacityPerServer: 31250  # æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´
```

#### æ•…éšœ 4ï¼šEPP CrashLoop

**ç—‡çŠ¶**ï¼šEPP Pod åå¤é‡å¯

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
kubectl logs -l app=epp-qwen-72b --previous

# å¸¸è§é”™è¯¯ 1: RBAC æƒé™ä¸è¶³
# "failed to list InferencePool: ... is forbidden"
kubectl auth can-i list inferencepool \
  --as=system:serviceaccount:default:epp-sa

# å¸¸è§é”™è¯¯ 2: Pool ä¸å­˜åœ¨
# "Pool is not initialized, skipping refreshing metrics"
kubectl get inferencepool
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```yaml
# RBAC é…ç½®
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: epp-role
rules:
- apiGroups: ["inference.networking.x-k8s.io"]
  resources: ["inferencepools", "inferenceobjectives"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
```

---

### 3.5 æˆæœ¬ä¸æ€§èƒ½æƒè¡¡

#### GPU å…±äº«ç­–ç•¥

```mermaid
flowchart LR
    A[GPU åˆ†é…ç­–ç•¥] --> B[ç‹¬äº«æ¨¡å¼]
    A --> C[å…±äº«æ¨¡å¼]
    A --> D[è™šæ‹ŸåŒ–æ¨¡å¼]
    
    B --> B1[1 Pod = 1 GPU]
    B --> B2[æœ€é«˜æ€§èƒ½]
    B --> B3[æˆæœ¬æœ€é«˜]
    
    C --> C1[å¤š Pod å…±äº« GPU]
    C --> C2[ä¸­ç­‰æ€§èƒ½]
    C --> C3[æˆæœ¬ä¸­ç­‰]
    
    D --> D1[MIG/vGPU]
    D --> D2[éš”ç¦»æ€§å¥½]
    D --> D3[é…ç½®å¤æ‚]
    
    style B fill:#e8f5e9
    style C fill:#fff3e0
    style D fill:#e1f5fe
```

**å»ºè®®**ï¼š
- **ç”Ÿäº§ç¯å¢ƒ**ï¼šç‹¬äº«æ¨¡å¼ï¼ˆé¿å… noisy neighborï¼‰
- **å¼€å‘/æµ‹è¯•**ï¼šå…±äº«æ¨¡å¼ï¼ˆæé«˜åˆ©ç”¨ç‡ï¼‰
- **å¤šç§Ÿæˆ·**ï¼šMIGï¼ˆA100/H100ï¼‰

#### æˆæœ¬ä¼˜åŒ– checklist

| ç­–ç•¥ | æ•ˆæœ | å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ |
|------|------|--------|---------|
| **Prefix Cache ä¼˜åŒ–** | å»¶è¿Ÿé™ä½ 30-50% | ä½ | RAGã€ç³»ç»Ÿæç¤ºè¯å›ºå®š |
| **Batch Size è°ƒä¼˜** | ååæå‡ 20-40% | ä¸­ | é«˜å¹¶å‘åœºæ™¯ |
| **Spot Instance** | æˆæœ¬é™ä½ 60-70% | é«˜ | æ‰¹å¤„ç†ä»»åŠ¡ |
| **è‡ªåŠ¨æ‰©ç¼©å®¹** | èŠ‚çœç©ºé—²æˆæœ¬ | ä¸­ | æµé‡æ³¢åŠ¨å¤§ |
| **LoRA çƒ­åŠ è½½** | å¤šæ¨¡å‹å…±äº« GPU | é«˜ | å¤šé€‚é…å™¨åœºæ™¯ |

#### Spot Instance + Priority ç»„åˆç­–ç•¥

```yaml
# æ‰¹å¤„ç†ä»»åŠ¡ä½¿ç”¨ Spot Instance
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-batch
spec:
  template:
    spec:
      nodeSelector:
        node-type: spot
      tolerations:
      - key: "spot"
        operator: "Equal"
        value: "true"
        effect: "NoSchedule"
---
# æ‰¹å¤„ç†ä»»åŠ¡è®¾ç½®ä½ Priority
apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: InferenceObjective
metadata:
  name: batch-spot
spec:
  priority: -100  # æœ€ä½ä¼˜å…ˆçº§ï¼Œå¯éšæ„ä¸¢å¼ƒ
```

---

### 3.6 åæ¨¡å¼è­¦ç¤º

#### âŒ åæ¨¡å¼ 1ï¼šæ‰€æœ‰è¯·æ±‚è®¾ä¸º Critical Priority

**é—®é¢˜**ï¼š
```yaml
# é”™è¯¯é…ç½®
spec:
  priority: 100  # æ‰€æœ‰è¯·æ±‚éƒ½æ˜¯ Critical
```

**åæœ**ï¼š
- ç³»ç»Ÿæ— æ³•é™çº§ï¼Œé¥±å’Œæ—¶æ‰€æœ‰è¯·æ±‚æ’é˜Ÿ
- çœŸæ­£çš„ Critical è¯·æ±‚è¢«æ™®é€šè¯·æ±‚é˜»å¡

**æ­£ç¡®åšæ³•**ï¼š
```yaml
# åˆç†åˆ†çº§
- Criticalï¼ˆpriority=100ï¼‰: è®¢å•å¼‚å¸¸ã€æ”¯ä»˜é—®é¢˜
- Highï¼ˆpriority=50ï¼‰: å®æ—¶å®¢æœ
- Normalï¼ˆpriority=0ï¼‰: å•†å“å’¨è¯¢
- Batchï¼ˆpriority=-50ï¼‰: æ•°æ®åˆ†æ
```

#### âŒ åæ¨¡å¼ 2ï¼šå¿½ç•¥ Metrics Staleness

**é—®é¢˜**ï¼š
```yaml
saturationDetector:
  metricsStalenessThreshold: 5000  # 5 ç§’ï¼Œå¤ªé•¿ï¼
```

**åæœ**ï¼š
- åŸºäº 5 ç§’å‰çš„æ—§æ•°æ®åšå†³ç­–
- Pod å·²ç»æ»¡è½½ï¼ŒEPP ä»è®¤ä¸ºç©ºé—²

**æ­£ç¡®åšæ³•**ï¼š
```yaml
saturationDetector:
  metricsStalenessThreshold: 200  # 200msï¼Œä¸é‡‡é›†é¢‘ç‡åŒ¹é…
```

#### âŒ åæ¨¡å¼ 3ï¼šç›²ç›®è¿½æ±‚ Prefix Cache å‘½ä¸­ç‡

**é—®é¢˜**ï¼š
```yaml
prefix-cache-scorer:
  weight: 10  # æƒé‡è¿‡é«˜
```

**åæœ**ï¼š
- æ‰€æœ‰è¯·æ±‚éƒ½è·¯ç”±åˆ°æœ‰ç¼“å­˜çš„ Pod
- è¯¥ Pod é˜Ÿåˆ—å †ç§¯ï¼Œå…¶ä»– Pod ç©ºé—²
- æ•´ä½“å»¶è¿Ÿåè€Œä¸Šå‡

**æ­£ç¡®åšæ³•**ï¼š
```yaml
prefix-cache-scorer:
  weight: 3  # å¹³è¡¡æƒé‡
queue-scorer:
  weight: 2  # åŒæ—¶è€ƒè™‘é˜Ÿåˆ—æ·±åº¦
```

---

### âœ… èºæ—‹ 3 éªŒæ”¶æ ‡å‡†

**ä½ èƒ½åšåˆ°**ï¼š
1. ç‹¬ç«‹å®Œæˆä» vLLM â†’ InferencePool â†’ Gateway çš„å…¨é“¾è·¯éƒ¨ç½²
2. æ ¹æ®ä¸šåŠ¡åœºæ™¯è°ƒæ•´ Scorer Weights å’Œ Thresholds
3. é…ç½® Prometheus ç›‘æ§å’Œ Grafana Dashboard
4. ç‹¬ç«‹æ’æŸ¥ 429/503/å»¶è¿ŸæŠ–åŠ¨ç­‰å…¸å‹æ•…éšœ
5. è®¾è®¡åˆç†çš„ SLO å’Œæˆæœ¬ä¼˜åŒ–ç­–ç•¥
6. é¿å…å¸¸è§çš„åæ¨¡å¼é…ç½®

---

### ğŸ”— æ€»ç»“ä¸è¿›é˜¶

**æ ¸å¿ƒè¦ç‚¹å›é¡¾**ï¼š
1. **æ¦‚å¿µå±‚**ï¼šInference Gateway = æ™ºèƒ½é¢†ç­ï¼Œæ ¹æ®å®æ—¶æŒ‡æ ‡åšè·¯ç”±å†³ç­–
2. **æœºåˆ¶å±‚**ï¼šå¤šç»´åº¦è¯„åˆ†ç®—æ³•ï¼ˆQueue + KV + Prefixï¼‰ï¼ŒSaturation Detection ä¿æŠ¤
3. **å®æˆ˜å±‚**ï¼šéƒ¨ç½²ã€è°ƒä¼˜ã€ç›‘æ§ã€æ’éšœã€æˆæœ¬æƒè¡¡

**è¿›é˜¶æ–¹å‘**ï¼š
- **è‡ªå®šä¹‰ Scorer**ï¼šå®ç°ä¸šåŠ¡ç‰¹å®šçš„è¯„åˆ†é€»è¾‘
- **å¤šæ¨¡å‹è·¯ç”±**ï¼šç»“åˆ BBR å®ç° model-aware routing
- **è‡ªåŠ¨æ‰©ç¼©å®¹**ï¼šåŸºäºè‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆQueue Depthï¼‰çš„ HPA
- **å¤šé›†ç¾¤è”é‚¦**ï¼šè·¨é›†ç¾¤ InferencePool è·¯ç”±

---

## ğŸ“š å‚è€ƒèµ„æ–™

1. [Gateway API Inference Extension å®˜æ–¹æ–‡æ¡£](https://gateway-api-inference-extension.sigs.k8s.io/)
2. [Kubernetes SIG-Network](https://github.com/kubernetes/community/tree/master/sig-network)
3. [WG-Serving](https://github.com/kubernetes/community/tree/master/wg-serving)
4. [vLLM Prefix Caching](https://docs.vllm.ai/en/stable/design/v1/prefix_caching.html)
5. [Envoy External Processing](https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/ext_proc_filter)

---

## âœ… è´¨é‡æ£€æŸ¥æ¸…å•

- [x] ä¸‰å±‚èºæ—‹ç»“æ„å®Œæ•´
- [x] ä½¿ç”¨å•ä¸€ç±»æ¯”è´¯ç©¿å…¨ç¯‡ï¼ˆç±³å…¶æ—é¤å…é¢†ä½ç³»ç»Ÿï¼‰
- [x] æ¡ˆä¾‹æ¥è‡ªä¸­å›½æœ¬åœŸåœºæ™¯ï¼ˆåŒ 11ã€AI å¤§ä¿ƒï¼‰
- [x] æ‰€æœ‰æ¶æ„å›¾ä½¿ç”¨ Mermaid
- [x] åŒ…å« SLI/SLO å»ºè®®
- [x] åŒ…å«æ’éšœç¤ºä¾‹
- [x] åŒ…å«åæ¨¡å¼
- [x] æœ‰å…·ä½“çš„æƒè¡¡åˆ†æ
