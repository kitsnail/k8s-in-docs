# LMCache ç»„ä»¶ï¼šKV Cache ä¼˜åŒ–æŠ€æœ¯

**ç›®æ ‡å—ä¼—**ï¼šä¸€çº¿å·¥ç¨‹å¸ˆ & æ¶æ„å¸ˆ  
**æ ¸å¿ƒä»·å€¼**ï¼šCacheGen å‹ç¼©ã€CacheBlend èåˆã€Layerwise ä¼ è¾“çš„æƒè¡¡ä¸é…ç½®  
**è´¯ç©¿ç±»æ¯”**ï¼šå›¾ä¹¦é¦†çš„ç¼©å¾®èƒ¶ç‰‡ã€ç›®å½•åˆå¹¶ã€åˆ†å±‚å€Ÿé˜…

---

## ğŸŒ€ èºæ—‹ 1ï¼šæ¦‚å¿µé—­ç¯ â€” æ˜¯ä»€ä¹ˆ & ä¸ºä»€ä¹ˆ

### 1.1 åœºæ™¯ç—›ç‚¹ï¼šKV Cache çš„ä¸‰å¤§ç“¶é¢ˆ

åœ¨ LLM æ¨ç†æœåŠ¡ä¸­ï¼ŒKV Cache é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š

| ç“¶é¢ˆ | é—®é¢˜æè¿° | å½±å“ | å…¸å‹åœºæ™¯ |
|------|----------|------|----------|
| **å­˜å‚¨æˆæœ¬** | KV Cache ä½“ç§¯å·¨å¤§ï¼ˆLlama-3.1-8Bï¼Œ8K ä¸Šä¸‹æ–‡ â‰ˆ 2GBï¼‰ | æ˜¾å­˜å¿«é€Ÿè€—å°½ | é•¿æ–‡æ¡£ RAG |
| **ä¼ è¾“å¸¦å®½** | è·¨èŠ‚ç‚¹å…±äº« KV Cache æ—¶ç½‘ç»œæˆä¸ºç“¶é¢ˆ | TTFT é£™å‡ | å¤šå®ä¾‹éƒ¨ç½² |
| **å¤ç”¨å±€é™** | åªèƒ½å¤ç”¨å‰ç¼€ï¼ˆPrefixï¼‰ï¼Œä¸­é—´å†…å®¹æµªè´¹ | Cache Hit ç‡ä½ | å¯¹è¯å†å²å¤ç”¨ |

**çœŸå®æ¡ˆä¾‹**ï¼šæŸçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿï¼š
- åœºæ™¯ï¼š1000 ç¯‡æ–‡æ¡£ï¼Œæ¯ç¯‡ 4K tokens
- é—®é¢˜ï¼šKV Cache å ç”¨ 2TB å­˜å‚¨ï¼Œæˆæœ¬çˆ†ç‚¸
- ç”¨æˆ·æŸ¥è¯¢ï¼š"è¿™ç¯‡æ–‡ç« çš„ç¬¬3æ®µè®²äº†ä»€ä¹ˆ"
- **ç—›ç‚¹**ï¼šä¼ ç»Ÿ Prefix Cache æ— æ³•å¤ç”¨"ç¬¬3æ®µ"è¿™éƒ¨åˆ† KVï¼ˆéå‰ç¼€ï¼‰

### 1.2 ç±»æ¯”ç†è§£ï¼šå›¾ä¹¦é¦†çš„ä¸‰å¤§ä¼˜åŒ–æŠ€æœ¯

| ä¼˜åŒ–æŠ€æœ¯ | å›¾ä¹¦é¦†ç±»æ¯” | æ ¸å¿ƒé—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|----------|------------|----------|----------|
| **CacheGen å‹ç¼©** | ç¼©å¾®èƒ¶ç‰‡ | è—ä¹¦å¤ªå¤šå åœ°æ–¹ | æŠŠä¹¦ç¼©å¾®æ‹æ‘„ï¼ŒèŠ‚çœ 70% ç©ºé—´ |
| **CacheBlend èåˆ** | ç›®å½•åˆå¹¶ | åªèƒ½æŒ‰ä¹¦åæ‰¾ä¹¦ | æŒ‰ç« èŠ‚ç´¢å¼•ï¼Œä»»æ„æ®µè½éƒ½èƒ½å¤ç”¨ |
| **Layerwise ä¼ è¾“** | åˆ†å±‚å€Ÿé˜… | ç­‰æ•´æœ¬ä¹¦ç¼–ç›®å®Œæ‰èƒ½å€Ÿ | ç¼–ç›®ä¸€ç« å€Ÿä¸€ç« ï¼Œè¾¹ç¼–è¾¹å€Ÿ |

#### ç±»æ¯”è¯¦è§£

**CacheGen - ç¼©å¾®èƒ¶ç‰‡**ï¼š
```
ä¼ ç»Ÿæ–¹å¼ï¼šæ¯æœ¬ä¹¦å ä¸€ä¸ªä¹¦æ¶ä½ç½®ï¼ˆåŸå§‹ KV Cacheï¼Œ2GBï¼‰
ç¼©å¾®èƒ¶ç‰‡ï¼šæŠŠä¹¦æ‹ç…§ç¼©å°ä¿å­˜ï¼ˆå‹ç¼©å KV Cacheï¼Œ400MBï¼‰
è¿˜åŸé˜…è¯»ï¼šç”¨é˜…è¯»å™¨æ”¾å¤§æŸ¥çœ‹ï¼ˆè§£å‹ç¼©ï¼Œå»¶è¿Ÿ < 1msï¼‰
```

**CacheBlend - ç›®å½•åˆå¹¶**ï¼š
```
ä¼ ç»Ÿç´¢å¼•ï¼šåªèƒ½æŸ¥ä¹¦åï¼ˆPrefix Cacheï¼‰
ç« èŠ‚ç´¢å¼•ï¼šå¯ä»¥æŸ¥"ç¬¬3ç« ç¬¬2èŠ‚"ï¼ˆä»»æ„ä½ç½®å¤ç”¨ï¼‰
æ™ºèƒ½åˆå¹¶ï¼šå¤šæœ¬ä¹¦çš„ç« èŠ‚å¯ä»¥ç»„åˆæˆæ–°ä¹¦ï¼ˆChunk æ‹¼æ¥ï¼‰
```

**Layerwise - åˆ†å±‚å€Ÿé˜…**ï¼š
```
ä¼ ç»Ÿæµç¨‹ï¼šç­‰æ•´æœ¬ä¹¦ç¼–ç›®å®Œæ‰èƒ½å€Ÿï¼ˆå…¨é‡ KV åŠ è½½ï¼‰
åˆ†å±‚å€Ÿé˜…ï¼šç¼–ç›®å¥½ç¬¬1ç« å°±å€Ÿå‡ºç¬¬1ç« ï¼ˆLayer 0 å…ˆä¼ è¾“ï¼‰
å¹¶è¡Œå¤„ç†ï¼šç¼–ç›®å‘˜ç¼–ç¬¬2ç« ï¼Œå€Ÿé˜…å‘˜å€Ÿç¬¬1ç« ï¼ˆPipelineï¼‰
```

### 1.3 ä¼˜åŒ–æŠ€æœ¯å…¨æ™¯å›¾

```mermaid
flowchart TB
    subgraph "åŸå§‹è¯·æ±‚"
        REQ["é•¿ Prompt<br/>8K tokens"]
    end

    subgraph "CacheGen å‹ç¼©å±‚"
        COMP["å‹ç¼©å¼•æ“<br/>å‡å°‘ 70% å­˜å‚¨"]
        COMP_STATS["2GB â†’ 600MB"]
    end

    subgraph "CacheBlend èåˆå±‚"
        BLEND["Chunk è¯†åˆ«<br/>åˆ†éš”ç¬¦: '###'"]
        BLEND_STATS["å¤ç”¨ 3 ä¸ª chunks<br/>å‘½ä¸­ç‡ 85%"]
    end

    subgraph "Layerwise ä¼ è¾“å±‚"
        LAYER["é€å±‚ä¼ è¾“<br/>32 Layers"]
        LAYER_STATS["Layer 0 å…ˆåˆ°è¾¾<br/>Pipeline å¯åŠ¨"]
    end

    subgraph "æ¨ç†å¼•æ“"
        VLLM["vLLM<br/>PagedAttention"]
    end

    REQ --> COMP
    COMP --> COMP_STATS
    COMP_STATS --> BLEND
    BLEND --> BLEND_STATS
    BLEND_STATS --> LAYER
    LAYER --> LAYER_STATS
    LAYER_STATS --> VLLM

    style COMP fill:#e1f5fe
    style BLEND fill:#fff3e0
    style LAYER fill:#e8f5e9
```

### 1.4 ä¸‰å¤§ä¼˜åŒ–æŠ€æœ¯å¯¹æ¯”

| æŠ€æœ¯ | è§£å†³ç—›ç‚¹ | æ”¶ç›Š | ä»£ä»· | é€‚ç”¨åœºæ™¯ |
|------|----------|------|------|----------|
| **CacheGen** | å­˜å‚¨æˆæœ¬é«˜ | èŠ‚çœ 60-70% ç©ºé—´ | å‹ç¼©/è§£å‹ CPU å¼€é”€ | é•¿æ–‡æ¡£ã€å†·æ•°æ® |
| **CacheBlend** | éå‰ç¼€æ— æ³•å¤ç”¨ | æå‡ 40% å‘½ä¸­ç‡ | éœ€è¦é‡æ–°è®¡ç®—éƒ¨åˆ† KV | RAGã€å¯¹è¯ |
| **Layerwise** | ä¼ è¾“å»¶è¿Ÿé«˜ | TTFT é™ä½ 30% | å®ç°å¤æ‚åº¦å¢åŠ  | è·¨èŠ‚ç‚¹ã€Disaggregated |

### âœ… èºæ—‹ 1 éªŒæ”¶

> ä¸€å¥è¯å¤è¿°ï¼šä¸‰å¤§ä¼˜åŒ–æŠ€æœ¯åˆ†åˆ«è§£å†³ KV Cache çš„å­˜å‚¨ã€å¤ç”¨ã€ä¼ è¾“ä¸‰å¤§ç“¶é¢ˆï¼Œåƒå›¾ä¹¦é¦†çš„ç¼©å¾®èƒ¶ç‰‡ã€ç›®å½•åˆå¹¶ã€åˆ†å±‚å€Ÿé˜…ä¸€æ ·æå‡æ•ˆç‡ã€‚

### ğŸ”— ä¸‹ä¸€æ­¥æŒ‡å¼•

ç†è§£ä¼˜åŒ–åŸç†åï¼Œè¿›å…¥ **è®¤çŸ¥é™å‹** â€”â€”æŠŠå›¾ä¹¦é¦†ä¼˜åŒ–é€»è¾‘è½¬åŒ–ä¸ºæŠ€æœ¯ç›´è§‰ã€‚

---

## ğŸ’¨ è®¤çŸ¥é™å‹ï¼šä»ç±»æ¯”åˆ°é€»è¾‘

### ä»å›¾ä¹¦é¦†ä¼˜åŒ–åˆ°æŠ€æœ¯å†³ç­–

**é™å‹ä¸»çº¿**ï¼šæŠŠå›¾ä¹¦é¦†çš„å¸¸è¯†è½¬åŒ–ä¸º KV Cache ä¼˜åŒ–çš„æŠ€æœ¯é€»è¾‘ã€‚

#### 1. ä»€ä¹ˆæ—¶å€™éœ€è¦å‹ç¼©ï¼Ÿ

**å›¾ä¹¦é¦†é€»è¾‘**ï¼š
> çè´µå¤ç±ï¼ˆé«˜é¢‘è®¿é—®ï¼‰æ”¾åœ¨é˜…è§ˆå®¤ï¼Œæ™®é€šä¹¦ç±ï¼ˆä½é¢‘è®¿é—®ï¼‰ç¼©å¾®ä¿å­˜ã€‚

**æŠ€æœ¯æ˜ å°„**ï¼š
```
çƒ­æ•°æ®ï¼ˆHotï¼‰ï¼šæ´»è·ƒå¯¹è¯ â†’ GPU/CPU æ˜¾å­˜ï¼Œä¸å‹ç¼©
æ¸©æ•°æ®ï¼ˆWarmï¼‰ï¼šè¿‘æœŸæ–‡æ¡£ â†’ æœ¬åœ°ç£ç›˜ï¼Œè½»åº¦å‹ç¼©
å†·æ•°æ®ï¼ˆColdï¼‰ï¼šå†å²æ–‡æ¡£ â†’ è¿œç¨‹å­˜å‚¨ï¼ŒCacheGen å‹ç¼©
```

#### 2. CacheBlend çš„"é‡æ–°è®¡ç®—"ç›´è§‰

**å›¾ä¹¦é¦†é€»è¾‘**ï¼š
> åˆå¹¶ä¸¤æœ¬ä¹¦çš„ç›®å½•æ—¶ï¼Œè¿æ¥å¤„éœ€è¦é‡æ–°ç¼–ç›®ï¼ˆå› ä¸ºç« èŠ‚è¾¹ç•Œå¯èƒ½ä¸è¿ç»­ï¼‰ã€‚

**æŠ€æœ¯æ˜ å°„**ï¼š
```
Chunk A + Chunk B æ‹¼æ¥æ—¶ï¼š
- Chunk A çš„ KVï¼šç›´æ¥å¤ç”¨ âœ…
- Chunk B çš„ KVï¼šç›´æ¥å¤ç”¨ âœ…
- è¿æ¥å¤„çš„å‡ ä¸ª tokenï¼šéœ€è¦é‡æ–°è®¡ç®— âš ï¸

é‡æ–°è®¡ç®—æ¯”ä¾‹ï¼šé€šå¸¸ 10-15%ï¼Œæ”¶ç›Šè¿œå¤§äºä»£ä»·
```

#### 3. Layerwise çš„ Pipeline ç›´è§‰

**å›¾ä¹¦é¦†é€»è¾‘**ï¼š
> è¯»è€…ä¸éœ€è¦ç­‰æ•´æœ¬ä¹¦ç¼–ç›®å®Œï¼Œç¼–å¥½ä¸€ç« å°±å¯ä»¥å…ˆçœ‹ä¸€ç« ã€‚

**æŠ€æœ¯æ˜ å°„**ï¼š
```
ä¼ ç»Ÿæ–¹å¼ï¼šç­‰ 32 å±‚ KV å…¨éƒ¨åŠ è½½å®Œæ‰å¼€å§‹æ¨ç†ï¼ˆå»¶è¿Ÿ 100msï¼‰
Layerwiseï¼šLayer 0 åˆ°è¾¾å°±å¼€å§‹æ¨ç† Layer 0ï¼ˆå»¶è¿Ÿ 3msï¼‰
          åŒæ—¶åå°ç»§ç»­åŠ è½½ Layer 1-31
```

### ç†è§£é“ºå«ï¼šä¸ºä»€ä¹ˆä¸èƒ½"æ— è„‘å…¨å¼€"ï¼Ÿ

**åç›´è§‰ç°è±¡**ï¼š
- åœºæ™¯ï¼šçŸ­å¯¹è¯ï¼ˆ< 1K tokensï¼‰
- ç›´è§‰ï¼šå¼€å¯æ‰€æœ‰ä¼˜åŒ–
- ç°å®ï¼šä¼˜åŒ– overhead > æ”¶ç›Šï¼Œåè€Œå˜æ…¢

**æ­£ç¡®ç­–ç•¥**ï¼š
| åœºæ™¯ | CacheGen | CacheBlend | Layerwise |
|------|----------|------------|-----------|
| çŸ­å¯¹è¯ (< 1K) | âŒ | âŒ | âŒ |
| é•¿æ–‡æ¡£ RAG | âœ… | âœ… | âœ… |
| å¤šè½®å¯¹è¯ | âŒ | âœ… | âŒ |
| Disaggregated | âŒ | âŒ | âœ… |

### âœ… è®¤çŸ¥é™å‹éªŒæ”¶

> èƒ½ç”¨å›¾ä¹¦é¦†çš„"å†·çƒ­åˆ†å±‚ã€è¿æ¥é‡ç¼–ã€è¾¹ç¼–è¾¹å€Ÿ"ä¸‰æ®µå¼é€»è¾‘ï¼Œè§£é‡Šä¸‰å¤§ä¼˜åŒ–æŠ€æœ¯çš„é€‚ç”¨åœºæ™¯ã€‚

### ğŸ”— ä¸‹ä¸€æ­¥æŒ‡å¼•

è®¤çŸ¥é™å‹å®Œæˆï¼Œè¿›å…¥ **èºæ—‹ 2ï¼ˆæœºåˆ¶å±‚ï¼‰** â€”â€” æ·±å…¥æºç çº§åˆ«çš„ä¼˜åŒ–å®ç°ã€‚

---

## ğŸŒ€ èºæ—‹ 2ï¼šæœºåˆ¶é—­ç¯ â€” å¦‚ä½•è¿ä½œ

### 2.1 CacheGen å‹ç¼©æœºåˆ¶

CacheGen åˆ©ç”¨ KV Cache çš„åˆ†å¸ƒç‰¹æ€§ï¼Œå°†å…¶ç¼–ç ä¸ºæ›´ç´§å‡‘çš„æ¯”ç‰¹æµè¡¨ç¤ºã€‚

#### å‹ç¼©åŸç†

```python
class CacheGenCompressor:
    """CacheGen KV Cache å‹ç¼©å™¨"""

    def __init__(self, quantization_bits: int = 4):
        self.quantization_bits = quantization_bits

    def compress(self, kv_cache: KVCache) -> CompressedData:
        """
        å‹ç¼© KV Cache

        åŸç†ï¼š
        1. å¯¹ Key/Value çŸ©é˜µè¿›è¡Œéå‡åŒ€é‡åŒ–
        2. åˆ©ç”¨ KV Cache çš„æ—¶é—´/ç©ºé—´å±€éƒ¨æ€§
        3. ä½¿ç”¨ç®—æœ¯ç¼–ç è¿›ä¸€æ­¥å‹ç¼©
        """
        # 1. æå– K å’Œ V çŸ©é˜µ
        k_tensor = kv_cache.k  # [num_layers, num_heads, seq_len, head_dim]
        v_tensor = kv_cache.v

        # 2. éå‡åŒ€é‡åŒ–ï¼ˆ4-bit é»˜è®¤ï¼‰
        k_quantized = self.non_uniform_quantize(
            k_tensor, bits=self.quantization_bits
        )
        v_quantized = self.non_uniform_quantize(
            v_tensor, bits=self.quantization_bits
        )

        # 3. ç®—æœ¯ç¼–ç 
        k_encoded = self.arithmetic_encode(k_quantized)
        v_encoded = self.arithmetic_encode(v_quantized)

        return CompressedData(
            k_data=k_encoded,
            v_data=v_encoded,
            original_size=kv_cache.size_bytes,
            compression_ratio=self.compute_ratio()
        )

    def decompress(self, compressed: CompressedData) -> KVCache:
        """è§£å‹ç¼©ï¼Œæ¢å¤ KV Cache"""
        # 1. ç®—æœ¯è§£ç 
        k_quantized = self.arithmetic_decode(compressed.k_data)
        v_quantized = self.arithmetic_decode(compressed.v_data)

        # 2. åé‡åŒ–
        k_tensor = self.dequantize(k_quantized)
        v_tensor = self.dequantize(v_quantized)

        return KVCache(k=k_tensor, v=v_tensor)
```

#### å‹ç¼©æ”¶ç›Šåˆ†æ

| æ¨¡å‹ | åŸå§‹å¤§å° | CacheGen å | å‹ç¼©ç‡ | è´¨é‡æŸå¤± |
|------|----------|-------------|--------|----------|
| Llama-3.1-8B, 8K | 2.0 GB | 600 MB | 70% | < 0.1% |
| Llama-3.1-70B, 8K | 16.0 GB | 4.8 GB | 70% | < 0.1% |
| Qwen-72B, 32K | 72.0 GB | 21.6 GB | 70% | < 0.1% |

### 2.2 CacheBlend èåˆæœºåˆ¶

CacheBlend å…è®¸å¤ç”¨éå‰ç¼€ä½ç½®çš„ KV Cacheï¼Œé€šè¿‡é‡æ–°è®¡ç®— Chunk è¾¹ç•Œå¤„çš„å°‘é‡ token æ¥å®ç°ã€‚

#### å·¥ä½œåŸç†

```mermaid
flowchart LR
    subgraph "Prompt 1"
        P1_SYS["System Prompt"]
        P1_SEP1["###"]
        P1_C1["Chunk 1"]
        P1_SEP2["###"]
        P1_C2["Chunk 2"]
    end

    subgraph "Prompt 2"
        P2_SYS["System Prompt"]
        P2_SEP1["###"]
        P2_C2["Chunk 2"]
        P2_SEP2["###"]
        P2_C1["Chunk 1"]
    end

    subgraph "KV Cache å¤ç”¨"
        KV_SYS["âœ… System KV"]
        KV_C1["âœ… Chunk 1 KV"]
        KV_C2["âœ… Chunk 2 KV"]
        KV_BLEND["âš ï¸ Blend è¾¹ç•Œ"]
    end

    P1_SYS -.-> KV_SYS
    P1_C1 -.-> KV_C1
    P1_C2 -.-> KV_C2

    P2_SYS -.-> KV_SYS
    P2_C2 -.-> KV_C2
    P2_C1 -.-> KV_C1
    P1_SEP2 -.-> KV_BLEND
```

#### é…ç½®å®ç°

```python
# å¯ç”¨ CacheBlend
import os

os.environ["LMCACHE_ENABLE_BLENDING"] = "True"
os.environ["LMCACHE_BLEND_SPECIAL_STR"] = " ### "  # Chunk åˆ†éš”ç¬¦
os.environ["LMCACHE_USE_LAYERWISE"] = "True"       # Layerwise å¿…é¡»å¼€å¯
os.environ["LMCACHE_BLEND_CHECK_LAYERS"] = "1"     # ç¬¬1å±‚æ£€æŸ¥èåˆç‚¹
os.environ["LMCACHE_BLEND_RECOMPUTE_RATIOS"] = "0.15"  # é‡ç®— 15% tokens

# å¯é€‰ï¼šä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›æå‡è´¨é‡
os.environ["VLLM_ATTENTION_BACKEND"] = "FLASHINFER"
os.environ["LMCACHE_EXTRA_CONFIG"] = '{"enable_sparse": true}'
```

#### Token å¤„ç†ç¤ºä¾‹

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-3.1-8B-Instruct")

# å®šä¹‰ Chunks
sys_prompt = tokenizer.encode("You are a helpful assistant.")
chunk1 = tokenizer.encode("Hello, how are you?" * 500)[1:]  # é•¿æ–‡æœ¬
chunk2 = tokenizer.encode("What's the weather like?" * 500)[1:]
blend_special = tokenizer.encode(" ### ")[1:]

# æ„å»ºç¬¬ä¸€ä¸ª Promptï¼ˆSystem + Chunk1 + Chunk2ï¼‰
prompt1 = (
    sys_prompt +
    blend_special + chunk1 +
    blend_special + chunk2 +
    blend_special +
    tokenizer.encode("Tell me about")[1:]
)

# æ„å»ºç¬¬äºŒä¸ª Promptï¼ˆSystem + Chunk2 + Chunk1ï¼Œé¡ºåºä¸åŒï¼‰
prompt2 = (
    sys_prompt +
    blend_special + chunk2 +
    blend_special + chunk1 +
    blend_special +
    tokenizer.encode("What's up")[1:]
)

# LMCache ä¼šè‡ªåŠ¨è¯†åˆ«å¹¶å¤ç”¨ Systemã€Chunk1ã€Chunk2 çš„ KV Cache
# æ— è®ºå®ƒä»¬åœ¨ Prompt ä¸­çš„é¡ºåºå¦‚ä½•
```

### 2.3 Layerwise ä¼ è¾“æœºåˆ¶

Layerwise KV Transfer å…è®¸åœ¨ KV Cache åŠ è½½å’Œæ¨ç†è®¡ç®—ä¹‹é—´å»ºç«‹ Pipelineï¼Œå‡å°‘ç­‰å¾…æ—¶é—´ã€‚

#### æ¶æ„ç»„ä»¶

```python
class LayerwiseCacheEngine:
    """Layerwise ç¼“å­˜å¼•æ“"""

    def __init__(self, num_layers: int = 32):
        self.num_layers = num_layers
        self.retrieval_generator = None  # åŠ è½½ç”Ÿæˆå™¨
        self.storage_generator = None    # å­˜å‚¨ç”Ÿæˆå™¨

    async def start_load_kv(self, tokens: List[int]):
        """å¯åŠ¨é€å±‚åŠ è½½"""
        # åˆå§‹åŒ– Retrieval Generator
        self.retrieval_generator = self.lmcache_engine.retrieve_layer(tokens)

        # ç¬¬1ä¸ª next(): åˆå§‹åŒ–
        next(self.retrieval_generator)
        # ç¬¬2ä¸ª next(): åŠ è½½ Layer 0
        next(self.retrieval_generator)

        return self.retrieval_generator

    async def wait_for_layer_load(self, layer_idx: int):
        """ç­‰å¾…æŒ‡å®šå±‚åŠ è½½å®Œæˆ"""
        # æ¨è¿› Generator åˆ°ç›®æ ‡å±‚
        for _ in range(layer_idx + 1):
            layer_kv = next(self.retrieval_generator)

        # å¼‚æ­¥åŠ è½½åˆ° GPU
        await self.gpu_connector.batched_to_gpu(layer_kv)

        return layer_kv

    async def save_kv_layer(self, layer_idx: int, kv_data: Tensor):
        """é€å±‚ä¿å­˜ KV"""
        if self.storage_generator is None:
            # é¦–æ¬¡è°ƒç”¨ï¼šåˆ›å»º Storage Generator
            self.storage_generator = self.create_storage_generator()

        # æ¨è¿›åˆ°å½“å‰å±‚
        for _ in range(layer_idx + 1):
            next(self.storage_generator)

        # GPU â†’ CPU ä¼ è¾“
        await self.gpu_connector.batched_from_gpu(kv_data)

        # å­˜å‚¨åˆ°åç«¯
        await self.storage_manager.batched_put(kv_data)
```

#### Pipeline æ‰§è¡Œæµç¨‹

```mermaid
sequenceDiagram
    participant VLLM as vLLM Forward
    participant Load as Layerwise Load
    participant GPU as GPU Memory
    participant Backend as Storage Backend

    Note over VLLM,Backend: åœºæ™¯ï¼šåŠ è½½å¹¶æ¨ç† 32 å±‚

    # åˆå§‹åŒ–
    VLLM->>Load: start_load_kv(tokens)
    Load->>Backend: å¼€å§‹å¼‚æ­¥åŠ è½½ Layer 0

    # Layer 0
    VLLM->>Load: wait_for_layer_load(0)
    Load->>GPU: Layer 0 â†’ GPU
    GPU-->>VLLM: Layer 0 å°±ç»ª
    VLLM->>VLLM: æ¨ç† Layer 0

    # Layer 1 (Pipeline)
    par Load Layer 1
        Load->>Backend: å¼‚æ­¥åŠ è½½ Layer 1
    and Compute Layer 0
        VLLM->>VLLM: ç»§ç»­æ¨ç†...
    end

    # Layer 1
    VLLM->>Load: wait_for_layer_load(1)
    Load->>GPU: Layer 1 â†’ GPU
    GPU-->>VLLM: Layer 1 å°±ç»ª
    VLLM->>VLLM: æ¨ç† Layer 1

    # ä»¥æ­¤ç±»æ¨...
    Note over VLLM,Backend: 32 å±‚å…¨éƒ¨å®Œæˆ
```

#### CUDA Stream åŒæ­¥

```python
class LayerwiseGPUConnector:
    """ç®¡ç† GPU-CPU å†…å­˜ä¼ è¾“çš„ CUDA Stream"""

    def __init__(self):
        # ä¸‰ä¸ª CUDA Stream
        self.current_stream = torch.cuda.current_stream()  # vLLM è®¡ç®—æµ
        self.load_stream = torch.cuda.Stream()             # åŠ è½½æµ
        self.store_stream = torch.cuda.Stream()            # å­˜å‚¨æµ

    def batched_to_gpu(self, cpu_data: CPUPtr, layer_idx: int):
        """CPU â†’ GPU ä¼ è¾“"""
        # åœ¨ load_stream ä¸Šæ‰§è¡Œä¼ è¾“
        with torch.cuda.stream(self.load_stream):
            gpu_data = cpu_data.cuda()

        # å¦‚æœæ˜¯ batch ä¸­æœ€åä¸€ä¸ªè¯·æ±‚ï¼ŒåŒæ­¥ stream
        if self.is_last_in_batch():
            self.current_stream.wait_stream(self.load_stream)

        return gpu_data

    def batched_from_gpu(self, gpu_data: Tensor, layer_idx: int):
        """GPU â†’ CPU ä¼ è¾“"""
        # åœ¨ store_stream ä¸Šæ‰§è¡Œä¼ è¾“
        with torch.cuda.stream(self.store_stream):
            cpu_data = gpu_data.cpu()

        # å¦‚æœæ˜¯ batch ä¸­ç¬¬ä¸€ä¸ªè¯·æ±‚ï¼ŒåŒæ­¥ stream
        if self.is_first_in_batch():
            self.store_stream.wait_stream(self.current_stream)

        return cpu_data
```

### âœ… èºæ—‹ 2 éªŒæ”¶

> èƒ½å¤Ÿè§£é‡Šï¼šCacheGen çš„é‡åŒ–å‹ç¼©åŸç†ã€CacheBlend çš„éå‰ç¼€å¤ç”¨æœºåˆ¶ã€Layerwise çš„ Pipeline ä¼ è¾“é€»è¾‘ã€‚

### ğŸ”— è¡”æ¥é—®é¢˜

ç”Ÿäº§ç¯å¢ƒå¦‚ä½•é…ç½®è¿™äº›ä¼˜åŒ–ï¼Ÿå¦‚ä½•æƒè¡¡å‹ç¼©ç‡ä¸æ€§èƒ½ï¼Ÿè¿›å…¥ **èºæ—‹ 3ï¼ˆå®æˆ˜å±‚ï¼‰**ã€‚

---

## ğŸŒ€ èºæ—‹ 3ï¼šå®æˆ˜é—­ç¯ â€” å¦‚ä½•é©¾é©­

### 3.1 ä¼˜åŒ–é…ç½®å®æˆ˜

#### CacheGen é…ç½®

```yaml
# lmcache-config.yaml
storage:
  remote:
    enabled: true
    backend: "redis"
    endpoint: "redis.cluster.local:6379"

# å¯ç”¨ CacheGen å‹ç¼©
remote_serde: "cachegen"

# å‹ç¼©çº§åˆ«ï¼ˆå¯é€‰ï¼‰
compression:
  algorithm: "cachegen"
  quantization_bits: 4  # 4-bit é‡åŒ–ï¼Œå¹³è¡¡å‹ç¼©ç‡ä¸è´¨é‡
```

```python
# ä»£ç ä¸­å¯ç”¨ CacheGen
import os

# æ–¹å¼1ï¼šç¯å¢ƒå˜é‡
os.environ["LMCACHE_REMOTE_SERDE"] = "cachegen"

# æ–¹å¼2ï¼šè¿è¡Œæ—¶é…ç½®ï¼ˆvLLMï¼‰
# åœ¨ lmcache-config.yaml ä¸­è®¾ç½® remote_serde: "cachegen"
```

#### CacheBlend é…ç½®

```yaml
# lmcache-config.yaml
blending:
  enabled: true
  special_str: " ### "          # Chunk åˆ†éš”ç¬¦
  recompute_ratios: 0.15        # é‡ç®—æ¯”ä¾‹ 15%
  check_layers: [1, 16]         # åœ¨ Layer 1 å’Œ 16 æ£€æŸ¥èåˆ

layerwise:
  enabled: true                 # CacheBlend éœ€è¦ Layerwise

# å¯é€‰ï¼šç¨€ç–æ³¨æ„åŠ›
extra_config:
  enable_sparse: true
```

```python
# ä»£ç ä¸­å¯ç”¨ CacheBlend
import os

os.environ["LMCACHE_ENABLE_BLENDING"] = "True"
os.environ["LMCACHE_BLEND_SPECIAL_STR"] = " ### "
os.environ["LMCACHE_USE_LAYERWISE"] = "True"
os.environ["LMCACHE_BLEND_CHECK_LAYERS"] = "1"
os.environ["LMCACHE_BLEND_RECOMPUTE_RATIOS"] = "0.15"

# ç¨€ç–æ³¨æ„åŠ›ï¼ˆå¯é€‰ï¼‰
os.environ["VLLM_ATTENTION_BACKEND"] = "FLASHINFER"
os.environ["LMCACHE_EXTRA_CONFIG"] = '{"enable_sparse": true}'
```

#### Layerwise é…ç½®

```yaml
# lmcache-config.yaml
layerwise:
  enabled: true
  use_async_load: true          # å¼‚æ­¥åŠ è½½
  buffer_size: "1Gi"            # æ¯å±‚ç¼“å†²å¤§å°
```

### 3.2 ä¸åŒåœºæ™¯çš„ä¼˜åŒ–ç»„åˆ

| åœºæ™¯ | CacheGen | CacheBlend | Layerwise | é¢„æœŸæ”¶ç›Š |
|------|----------|------------|-----------|----------|
| **é•¿æ–‡æ¡£ RAG** | âœ… | âœ… | âœ… | å­˜å‚¨ -70%ï¼ŒTTFT -30% |
| **å¤šè½®å¯¹è¯** | âŒ | âœ… | âŒ | å‘½ä¸­ç‡ +40% |
| **Disaggregated Prefill** | âŒ | âŒ | âœ… | TTFT -30% |
| **è·¨èŠ‚ç‚¹å…±äº«** | âœ… | âŒ | âŒ | å¸¦å®½ -70% |
| **çŸ­å¯¹è¯ (< 1K)** | âŒ | âŒ | âŒ | ä¼˜åŒ– overhead > æ”¶ç›Š |

### 3.3 åæ¨¡å¼

#### âŒ åæ¨¡å¼ 1ï¼šCacheGen å‹ç¼©çƒ­æ•°æ®

- **ç°è±¡**ï¼šæ´»è·ƒå¯¹è¯çš„ KV è¢«å‹ç¼©ï¼ŒTTFT å¢åŠ  50ms
- **æ ¹å› **ï¼šå‹ç¼©/è§£å‹å¼€é”€æŠµæ¶ˆäº†ç¼“å­˜æ”¶ç›Š
- **ä¿®æ­£**ï¼š
  ```yaml
  storage:
    cpu:
      enabled: true
      compression: "none"     # çƒ­æ•°æ®ä¸å‹ç¼©
    disk:
      compression: "cachegen"  # å†·æ•°æ®å‹ç¼©
  ```

#### âŒ åæ¨¡å¼ 2ï¼šCacheBlend åˆ†éš”ç¬¦é€‰æ‹©ä¸å½“

- **ç°è±¡**ï¼šChunk è¯†åˆ«å¤±è´¥ï¼Œå¤ç”¨ç‡ 0%
- **æ ¹å› **ï¼šåˆ†éš”ç¬¦åœ¨æ–‡æœ¬ä¸­è‡ªç„¶å‡ºç°
- **ä¿®æ­£**ï¼š
  ```python
  # ä½¿ç”¨ä¸æ˜“è‡ªç„¶å‡ºç°çš„åˆ†éš”ç¬¦
  os.environ["LMCACHE_BLEND_SPECIAL_STR"] = "<|CHUNK_SEP|>"
  # è€Œä¸æ˜¯å¸¸è§çš„ "###" æˆ– "---"
  ```

#### âŒ åæ¨¡å¼ 3ï¼šLayerwise ç¼“å†²è¿‡å°

- **ç°è±¡**ï¼šPipeline é¢‘ç¹ä¸­æ–­ï¼Œæ€§èƒ½åè€Œä¸‹é™
- **æ ¹å› **ï¼šbuffer_size < layer_size
- **ä¿®æ­£**ï¼š
  ```yaml
  layerwise:
    buffer_size: "2Gi"  # ç¡®ä¿ > å•å±‚ KV å¤§å° Ã— batch_size
  ```

### 3.4 æ€§èƒ½è°ƒä¼˜å†³ç­–æ ‘

```mermaid
flowchart TD
    A[ğŸš€ ä¼˜åŒ–éœ€æ±‚] --> B{ç“¶é¢ˆç±»å‹?}

    B -->|å­˜å‚¨æˆæœ¬é«˜| C[å¯ç”¨ CacheGen]
    B -->|Cache Hit ä½| D[å¯ç”¨ CacheBlend]
    B -->|TTFT é«˜| E[å¯ç”¨ Layerwise]

    C --> C1{æ•°æ®å†·çƒ­?}
    C1 -->|å†·æ•°æ®| C2[é…ç½® remote_serde: cachegen]
    C1 -->|çƒ­æ•°æ®| C3[è·³è¿‡å‹ç¼©]

    D --> D1{Prompt ç»“æ„?}
    D1 -->|å¤š Chunk| D2[é…ç½®åˆ†éš”ç¬¦ + Layerwise]
    D1 -->|å•ä¸€æ–‡æœ¬| D3[CacheBlend æ— æ•ˆ]

    E --> E1{æ¶æ„ç±»å‹?}
    E1 -->|Disaggregated| E2[Layerwise å¿…éœ€]
    E1 -->|å•æœº| E3[è¯„ä¼°æ”¶ç›Šæ˜¯å¦ > overhead]

    style A fill:#e1f5fe
    style C1 fill:#fff3e0
    style D1 fill:#fff3e0
    style E1 fill:#fff3e0
```

#### è°ƒä¼˜æ£€æŸ¥æ¸…å•

```bash
# 1. éªŒè¯ CacheGen å‹ç¼©ç‡
curl -s http://localhost:8000/metrics | grep compression_ratio

# 2. éªŒè¯ CacheBlend å¤ç”¨ç‡
curl -s http://localhost:8000/metrics | grep blend_hit_rate

# 3. éªŒè¯ Layerwise å»¶è¿Ÿ
curl -s http://localhost:8000/metrics | grep layerwise_load_latency

# 4. æ£€æŸ¥å„å±‚åŠ è½½æ—¶é—´
curl -s http://localhost:8000/api/v1/layerwise/stats | jq '.layer_times'

# 5. ç›‘æ§å‹ç¼©/è§£å‹ CPU ä½¿ç”¨ç‡
top -p $(pgrep -d',' -f lmcache)
```

### 3.5 SRE å¯è§‚æµ‹æ€§

#### å…³é”®æŒ‡æ ‡

```yaml
# Prometheus å‘Šè­¦è§„åˆ™
groups:
  - name: lmcache-optimizations
    rules:
      - alert: CacheGenDecompressionSlow
        expr: rate(lmcache_decompression_duration_seconds[5m]) > 0.01
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "CacheGen è§£å‹è€—æ—¶è¿‡é•¿"

      - alert: CacheBlendLowHitRate
        expr: rate(lmcache_blend_hits_total[5m]) / rate(lmcache_blend_lookups_total[5m]) < 0.3
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "CacheBlend å‘½ä¸­ç‡ä½äº 30%"

      - alert: LayerwiseLoadLatencyHigh
        expr: histogram_quantile(0.99, rate(lmcache_layerwise_load_latency_bucket[5m])) > 50
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "Layerwise åŠ è½½å»¶è¿Ÿ > 50ms"
```

#### Grafana Dashboard é…ç½®

```yaml
panels:
  - title: "CacheGen å‹ç¼©ç»Ÿè®¡"
    targets:
      - expr: lmcache_compression_ratio
        legendFormat: "å‹ç¼©ç‡"
      - expr: rate(lmcache_compression_duration_seconds[5m])
        legendFormat: "å‹ç¼©è€—æ—¶"

  - title: "CacheBlend å‘½ä¸­ç‡"
    targets:
      - expr: rate(lmcache_blend_hits_total[5m]) / rate(lmcache_blend_lookups_total[5m])
        legendFormat: "å‘½ä¸­ç‡"

  - title: "Layerwise å±‚åŠ è½½æ—¶é—´"
    targets:
      - expr: histogram_quantile(0.99, rate(lmcache_layerwise_load_latency_bucket[5m]))
        legendFormat: "P99 åŠ è½½å»¶è¿Ÿ"
```

### âœ… èºæ—‹ 3 éªŒæ”¶

> èƒ½å¤Ÿæ ¹æ®ä¸šåŠ¡åœºæ™¯é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–ç»„åˆï¼Œå¹¶èƒ½æ ¹æ®æŒ‡æ ‡è°ƒæ•´é…ç½®å‚æ•°ã€‚

### ğŸ”— ä¸‹ä¸€æ­¥æŒ‡å¼•

è¿›å…¥ **å…ƒçŸ¥è¯†æ€»ç»“** â€”â€” æ²‰æ·€ä¼˜åŒ–æŠ€æœ¯çš„è®¾è®¡æ¨¡å¼ã€‚

---

## å…ƒçŸ¥è¯†æ€»ç»“

### å¤§è§„æ¨¡ç“¶é¢ˆä¸è°ƒä¼˜

#### ä¸‰å¤§ä¼˜åŒ–çš„è¾¹ç•Œ

| æŠ€æœ¯ | æœ€ä½³é€‚ç”¨èŒƒå›´ | æ€§èƒ½æ‹ç‚¹ | é™çº§æ–¹æ¡ˆ |
|------|--------------|----------|----------|
| **CacheGen** | å†·æ•°æ®ã€è·¨èŠ‚ç‚¹ | å‹ç¼©/è§£å‹ > 10ms | é™ä½é‡åŒ–ç²¾åº¦ |
| **CacheBlend** | å¤š Chunk RAG | é‡ç®— > 30% | å¢åŠ  Chunk å¤§å° |
| **Layerwise** | é•¿åºåˆ—ã€Disaggregated | Pipeline ä¸­æ–­é¢‘ç¹ | å¢åŠ  buffer_size |

#### æˆæœ¬æ”¶ç›Šåˆ†æ

| ä¼˜åŒ– | å­˜å‚¨æˆæœ¬ | è®¡ç®—æˆæœ¬ | ç½‘ç»œæˆæœ¬ | æ€»æˆæœ¬å˜åŒ– |
|------|----------|----------|----------|------------|
| CacheGen | -70% | +5% | -70% | -60% |
| CacheBlend | 0% | +10% | 0% | -30%ï¼ˆHit ç‡æå‡ï¼‰ |
| Layerwise | 0% | +2% | 0% | -15%ï¼ˆTTFT é™ä½ï¼‰ |

### è®¾è®¡æ¨¡å¼æ²‰æ·€

| æ¨¡å¼åç§° | é€‚ç”¨åœºæ™¯ | ä¼˜åŒ–ç»„åˆ |
|----------|----------|----------|
| **æè‡´å‹ç¼©æ¨¡å¼** | è¶…å¤§è§„æ¨¡æ–‡æ¡£åº“ | CacheGen + Redis åç«¯ |
| **é«˜å¤ç”¨æ¨¡å¼** | RAG é—®ç­”ç³»ç»Ÿ | CacheBlend + Layerwise |
| **ä½å»¶è¿Ÿæ¨¡å¼** | å®æ—¶å¯¹è¯ | ä»… Layerwiseï¼ˆDisaggregatedï¼‰ |
| **æˆæœ¬ä¼˜å…ˆæ¨¡å¼** | é¢„ç®—æ•æ„Ÿ | CacheGen + S3 åç«¯ |

### ä¸€å¥è¯ Takeaway

> **ä¸‰å¤§ä¼˜åŒ–ä¸æ˜¯"è¶Šå¤šè¶Šå¥½"ï¼Œè€Œæ˜¯"å¯¹ç—‡ä¸‹è¯"â€”â€”CacheGen æ²»å­˜å‚¨ã€CacheBlend æ²»å¤ç”¨ã€Layerwise æ²»ä¼ è¾“ï¼Œæ ¹æ®ä¸šåŠ¡ç‰¹å¾ç²¾å‡†ç»„åˆæ‰èƒ½æ”¶ç›Šæœ€å¤§åŒ–ã€‚**

---

**æœ¬æ¨¡å—è´¨é‡æ£€æŸ¥æ¸…å•**ï¼š

- [x] ä¸‰å±‚èºæ—‹ç»“æ„å®Œæ•´
- [x] æ¯å±‚æœ‰éªŒæ”¶æ ‡å‡†
- [x] å›¾ä¹¦é¦†ç±»æ¯”è´¯ç©¿
- [x] ä¸­å›½æœ¬åœŸåœºæ™¯ï¼ˆçŸ¥è¯†åº“é—®ç­”ï¼‰
- [x] Mermaid æ¶æ„å›¾
- [x] ä¸‰å¤§æŠ€æœ¯å¯¹æ¯”è¡¨
- [x] é…ç½®ç¤ºä¾‹å®Œæ•´
- [x] 3+ åæ¨¡å¼
- [x] åœºæ™¯åŒ–é…ç½®å»ºè®®
- [x] å¯è§‚æµ‹æ€§æŒ‡æ ‡

---

## å»¶ä¼¸é˜…è¯»

### å®˜æ–¹æ–‡æ¡£

- **CacheGen**: https://docs.lmcache.ai/kv_cache_optimizations/compression/cachegen.html
- **CacheBlend**: https://docs.lmcache.ai/kv_cache_optimizations/blending.html
- **Layerwise**: https://docs.lmcache.ai/kv_cache_optimizations/layerwise.html

### ç›¸å…³è®ºæ–‡

1. **CacheGen Paper**:  
   CacheGen: KV Cache Compression and Streaming for Fast Large Language Model Serving  
   https://dl.acm.org/doi/10.1145/3651890.3672274

2. **CacheBlend Paper**:  
   CacheBlend: Fast Large Language Model Serving with Cached Knowledge Fusion  
   https://arxiv.org/abs/2405.16444

### ç›¸å…³æŠ€æœ¯

| æŠ€æœ¯ | å…³è”ç‚¹ | å­¦ä¹ å»ºè®® |
|------|--------|----------|
| **Quantization** | CacheGen åŸºç¡€ | äº†è§£ GPTQ/AWQ |
| **FlashAttention** | CacheBlend å¯é€‰åç«¯ | ç†è§£ç¨€ç–æ³¨æ„åŠ› |
| **CUDA Streams** | Layerwise å®ç°åŸºç¡€ | å­¦ä¹ å¼‚æ­¥ç¼–ç¨‹ |

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2025-02  
**å…³è”æ¨¡å—**: [02-disaggregated-prefill.md](02-disaggregated-prefill.md)ï¼ˆåˆ†å¸ƒå¼é¢„å¡«å……ï¼‰
