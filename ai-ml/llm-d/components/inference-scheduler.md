# Inference Scheduler - æ™ºèƒ½æ¨ç†è°ƒåº¦å™¨

> **æ ¸å¿ƒä»·å€¼**: LLM æ„ŸçŸ¥çš„æ™ºèƒ½è·¯ç”±å¼•æ“,é€šè¿‡å¤šç»´åº¦è¯„åˆ†çªç ´ä¼ ç»Ÿè´Ÿè½½å‡è¡¡çš„æ€§èƒ½ç“¶é¢ˆ  
> **æŠ€æœ¯æ ˆ**: Gateway API + Envoy ext-proc + Go  
> **å…³é”®æŒ‡æ ‡**: TTFT -99%, åå +109% (ç›¸æ¯” K8s Service)

---

## ğŸŒ€ èºæ—‹ 1: æ¦‚å¿µå±‚ - ä¸ºä»€ä¹ˆ K8s Service ä¸å¤Ÿç”¨?

### æœ¬å±‚ç›®æ ‡
ç†è§£ä¼ ç»Ÿè´Ÿè½½å‡è¡¡åœ¨ LLM æ¨ç†åœºæ™¯ä¸‹çš„æ ¹æœ¬æ€§ç¼ºé™·,å»ºç«‹å¯¹"æ™ºèƒ½è°ƒåº¦"å¿…è¦æ€§çš„è®¤çŸ¥ã€‚

---

### 1.1 ä¼ ç»Ÿè´Ÿè½½å‡è¡¡çš„ä¸‰å¤§å‡è®¾

Kubernetes Service çš„ Round-robin ç®—æ³•åŸºäºä»¥ä¸‹å‡è®¾:

| å‡è®¾ | ä¼ ç»Ÿå¾®æœåŠ¡ | LLM æ¨ç† | ç»“æœ |
|------|-----------|---------|------|
| **è¯·æ±‚è€—æ—¶å‡åŒ€** | âœ… 10-100ms | âŒ 100ms-30s (å·® 300x) | çŸ­è¯·æ±‚è¢«é•¿è¯·æ±‚é˜»å¡ |
| **èµ„æºæ¶ˆè€—å¯é¢„æµ‹** | âœ… å›ºå®š CPU/å†…å­˜ | âŒ åŠ¨æ€ KV Cache å¢é•¿ | æŸäº› Pod çªç„¶ OOM |
| **å®ä¾‹å®Œå…¨å¯¹ç­‰** | âœ… æ— çŠ¶æ€ | âŒ ç¼“å­˜å‘½ä¸­ç‡å·®å¼‚ 90% | é‡å¤è®¡ç®—æµªè´¹ |

---

### 1.2 å®é™…ç”Ÿäº§é—®é¢˜æ¡ˆä¾‹

**åœºæ™¯**: 8 ä¸ª vLLM Pod æœåŠ¡ Llama-70B,ä½¿ç”¨ K8s Service Round-robin

```mermaid
sequenceDiagram
    participant C1 as å®¢æˆ·ç«¯ 1<br/>(çŸ­ Prompt 100 tokens)
    participant LB as K8s Service<br/>Round-robin
    participant P1 as Pod 1<br/>(é˜Ÿåˆ—: 5 ä¸ªé•¿è¯·æ±‚)
    participant P2 as Pod 2<br/>(é˜Ÿåˆ—: ç©º)
    
    C1->>LB: è¯·æ±‚ A (é¢„æœŸ 500ms)
    LB->>P1: åˆ†é…åˆ° Pod 1
    Note over P1: æ’é˜Ÿç­‰å¾… 5 ä¸ªé•¿è¯·æ±‚<br/>å®é™…è€—æ—¶: 25 ç§’!
    P1-->>C1: å“åº” (è¶…æ—¶)
    
    Note over P2: Pod 2 ç©ºé—²,ä½†æœªè¢«ä½¿ç”¨
    
    style P1 fill:#ffebee
    style P2 fill:#e8f5e9
```

**é—®é¢˜åˆ†æ**:
1. **ç›²ç›®è·¯ç”±**: Service ä¸çŸ¥é“ Pod 1 å·²è¿‡è½½
2. **ç¼“å­˜æœªåˆ©ç”¨**: å¦‚æœå®¢æˆ·ç«¯ 1 ä¹‹å‰è®¿é—®è¿‡ Pod 2,ç¼“å­˜ç™½ç™½æµªè´¹
3. **é›ªå´©é£é™©**: è¿ç»­å¤šä¸ªé•¿è¯·æ±‚è¢«åˆ†é…åˆ°åŒä¸€ Pod,å¯¼è‡´å•ç‚¹è¿‡è½½

**å®æµ‹å½±å“** (ç”Ÿäº§ç¯å¢ƒ Qwen3-32B):
- TTFT P95: 6.2s (ç”¨æˆ·ä¸å¯æ¥å—)
- æˆåŠŸç‡: 87% (13% è¯·æ±‚è¶…æ—¶)
- GPU åˆ©ç”¨ç‡: 45% (èµ„æºæµªè´¹)

---

### 1.3 llm-d Inference Scheduler çš„è§£å†³æ–¹æ¡ˆ

**æ ¸å¿ƒæ€æƒ³**: åœ¨ Gateway å±‚æ’å…¥ **Endpoint Picker (EPP)** ,åŸºäºè¯·æ±‚ç‰¹å¾ä¸ Pod å®æ—¶çŠ¶æ€åšæ™ºèƒ½å†³ç­–

```mermaid
flowchart LR
    subgraph Traditional [ä¼ ç»Ÿæ–¹æ¡ˆ]
        T_LB[K8s Service<br/>è½®è¯¢] --> T_P1[Pod 1]
        T_LB --> T_P2[Pod 2]
        T_LB --> T_P3[Pod 3]
        
        style T_LB fill:#ffebee
    end
    
    subgraph llm-d [llm-d æ–¹æ¡ˆ]
        L_GW[Gateway] --> L_EPP[Endpoint Picker<br/>æ™ºèƒ½è°ƒåº¦]
        L_EPP -->|é˜Ÿåˆ—ç©ºé—²| L_P1[Pod 1]
        L_EPP -->|ç¼“å­˜å‘½ä¸­ 90%| L_P2[Pod 2]
        L_EPP -.è¿‡æ»¤.-> L_P3[Pod 3<br/>é˜Ÿåˆ—æ»¡]
        
        L_INDEX[(KV Cache<br/>Indexer)] -.ç¼“å­˜è¯„åˆ†.-> L_EPP
        L_PROM[(Prometheus)] -.è´Ÿè½½æŒ‡æ ‡.-> L_EPP
        
        style L_EPP fill:#e1f5fe
        style L_P2 fill:#e8f5e9
        style L_P3 fill:#ffebee
    end
```

**ä¸‰å¤§èƒ½åŠ›**:

1. **è¯·æ±‚ç‰¹å¾æ„ŸçŸ¥**
   ```
   GET /v1/chat/completions
   {
     "prompt": "What is Kubernetes?",  // æå– Prompt
     "max_tokens": 100                 // é¢„æµ‹è€—æ—¶
   }
   ```
   â†’ è®¡ç®— Hash,æŸ¥è¯¢å“ªäº› Pod æœ‰ç¼“å­˜

2. **Pod çŠ¶æ€æ„ŸçŸ¥**
   ```python
   # å®æ—¶æŒ‡æ ‡
   pod_state = {
       "queue_depth": 12,          # é˜Ÿåˆ—æ·±åº¦
       "kv_utilization": 0.73,     # KV Cache å ç”¨
       "cache_blocks": [0,1,2,5],  # æœ¬åœ°ç¼“å­˜å—
       "active_requests": 8        # å½“å‰å¤„ç†æ•°
   }
   ```

3. **å¤šç›®æ ‡ä¼˜åŒ–**
   - æœ€å°åŒ– TTFT (é¦– Token å»¶è¿Ÿ)
   - æœ€å¤§åŒ–ç¼“å­˜å‘½ä¸­ç‡
   - å‡è¡¡è´Ÿè½½åˆ†å¸ƒ

---

### 1.4 å®æµ‹å¯¹æ¯” - Qwen3-32B é«˜ Prefix å¤ç”¨åœºæ™¯

**æµ‹è¯•é…ç½®**:
- æ¨¡å‹: Qwen/Qwen3-32B
- æ‹“æ‰‘: 8x vLLM Pods, 16x H100 (TP=2)
- å·¥ä½œè´Ÿè½½: 150 ç»„å…±äº«å‰ç¼€,æ¯ç»„ 5 ä¸ªå˜ä½“ (6k ç³»ç»Ÿæç¤ºè¯)

**ç»“æœå¯¹æ¯”**:

| æŒ‡æ ‡ | K8s Service | llm-d Scheduler | æå‡ |
|------|-------------|----------------|------|
| **TTFT P50** | 6.2s | **136ms** | ğŸ“‰ 97.8% â†“ |
| **TTFT P95** | 12.5s | **157ms** | ğŸ“‰ 98.7% â†“ |
| **åå (20 QPS)** | 9k tok/s | **11k tok/s** | ğŸ“ˆ +22% |
| **æˆåŠŸç‡** | 87% | **100%** | ğŸ“ˆ +13% |
| **ç¼“å­˜å‘½ä¸­ç‡** | 12% | **89%** | ğŸ“ˆ +77% |

**å…³é”®æ´å¯Ÿ**: åœ¨é«˜ Prefix å¤ç”¨åœºæ™¯ä¸‹,æ™ºèƒ½è°ƒåº¦çš„æ”¶ç›Šå‘ˆæŒ‡æ•°çº§å¢é•¿

---

### âœ… èºæ—‹ 1 éªŒæ”¶æ ‡å‡†

å®Œæˆæœ¬å±‚å­¦ä¹ å,ä½ åº”è¯¥èƒ½å¤Ÿ:

- [ ] åˆ—ä¸¾ä¼ ç»Ÿè´Ÿè½½å‡è¡¡åœ¨ LLM æ¨ç†ä¸‹å¤±æ•ˆçš„ä¸‰å¤§å‡è®¾
- [ ] ç”¨ä¸€å¥è¯è¯´æ˜ Inference Scheduler çš„æ ¸å¿ƒä»·å€¼: _"é€šè¿‡è¯·æ±‚ç‰¹å¾ä¸ Pod çŠ¶æ€çš„æ™ºèƒ½åŒ¹é…,å®ç°ç¼“å­˜å¤ç”¨æœ€å¤§åŒ–ä¸è´Ÿè½½å‡è¡¡"_
- [ ] è¯†åˆ«é«˜ Prefix å¤ç”¨åœºæ™¯ (å¤šè½®å¯¹è¯ã€RAGã€Agent) ä¸ºæœ€ä½³é€‚ç”¨åœºæ™¯

---

### ğŸ”— ä¸‹ä¸€æ­¥

ç†è§£äº†"ä¸ºä»€ä¹ˆéœ€è¦"å,ä¸‹ä¸€å±‚å°†æ·±å…¥ **Filterâ†’Scoreâ†’Select ä¸‰é˜¶æ®µç®—æ³•** ä¸ **Scorer æ’ä»¶çš„å®ç°åŸç†**ã€‚

---

## ğŸ’¨ è®¤çŸ¥é™å‹ - ä»"å¿«é€’åˆ†æ‹£"ç†è§£æ™ºèƒ½è·¯ç”±

### å¸¸è¯†ç±»æ¯”: æ™ºèƒ½å¿«é€’åˆ†æ‹£ç³»ç»Ÿ

æƒ³è±¡ä¸€ä¸ªå¤§å‹å¿«é€’æ¢çº½ä¸­å¿ƒ:

**âŒ ä¼ ç»Ÿè½®è¯¢ (Round-robin)**
```
åŒ…è£¹ A (åŒåŸ,é‡ 1kg)  â†’ å¡è½¦ 1 (å·²è£… 10 å¨è·¨çœè´§)  
åŒ…è£¹ B (è·¨çœ,é‡ 50kg) â†’ å¡è½¦ 2 (ç©ºè½½,å»åŒåŸ)  
åŒ…è£¹ C (ç›®çš„åœ°åŒåŒ…è£¹ A) â†’ å¡è½¦ 3 (å»åæ–¹å‘)
```
**ç»“æœ**: 
- åŒåŸåŒ…è£¹è·Ÿç€è·¨çœè½¦èµ°æ…¢äº† 3 å¤©
- è·¨çœåŒ…è£¹å ç”¨åŒåŸå¿«è½¦,è¿åŠ›æµªè´¹
- ç›¸åŒç›®çš„åœ°çš„åŒ…è£¹åˆ†æ•£è£…è½¦,æ— æ³•æ‰¹é‡ä¼˜åŒ–

---

**âœ… æ™ºèƒ½åˆ†æ‹£ç³»ç»Ÿ (Inference Scheduler)**
```
åŒ…è£¹ A (åŒåŸ,1kg)     â†’ åŒåŸä¸“çº¿è½¦ (è£…æ»¡å°±èµ°,å¿«é€Ÿå‘¨è½¬)
åŒ…è£¹ B (è·¨çœ,50kg)    â†’ è·¨çœå¹²çº¿è½¦ (æ»¡è½½åå‘è½¦,æˆæœ¬ä¼˜åŒ–)
åŒ…è£¹ C (ç›®çš„åœ°åŒ A)   â†’ åŒåŸä¸“çº¿è½¦ (ä¸ A æ‹¼è½¦,é™æœ¬å¢æ•ˆ)
```

**åˆ†æ‹£è§„åˆ™ (æ˜ å°„åˆ°è°ƒåº¦ç®—æ³•)**:
1. **è¿‡æ»¤ (Filter)**: æ’é™¤æ»¡è½½è½¦è¾†ã€åæ–¹å‘çº¿è·¯
2. **è¯„åˆ† (Score)**: 
   - ç›®çš„åœ°åŒ¹é… (ç±»æ¯”: ç¼“å­˜å‘½ä¸­)
   - è½¦è¾†ç©ºé—²åº¦ (ç±»æ¯”: é˜Ÿåˆ—æ·±åº¦)
   - çº¿è·¯æ—¶æ•ˆæ€§ (ç±»æ¯”: é¢„æµ‹å»¶è¿Ÿ)
3. **é€‰æ‹© (Select)**: ç»¼åˆå¾—åˆ†æœ€é«˜çš„è½¦è¾†

---

### æ˜ å°„åˆ° LLM æ¨ç†

| å¿«é€’åœºæ™¯ | LLM æ¨ç† |
|---------|---------|
| **åŒ…è£¹** | æ¨ç†è¯·æ±‚ |
| **ç›®çš„åœ°** | Prompt Hash (å‰ç¼€ç‰¹å¾) |
| **å¡è½¦** | vLLM Pod |
| **è½¦è¾†è½½é‡** | é˜Ÿåˆ—æ·±åº¦ |
| **åŒåŸ/è·¨çœ** | çŸ­/é•¿è¯·æ±‚ |
| **æ‹¼è½¦** | æ‰¹å¤„ç† (Continuous Batching) |
| **æ»¡è½½å‘è½¦** | è¾¾åˆ° `max_num_seqs` è§¦å‘æ¨ç† |

**æ ¸å¿ƒæ´å¯Ÿ**:
- **ä¸æ˜¯æ‰€æœ‰è¯·æ±‚éƒ½å¹³ç­‰**: çŸ­è¯·æ±‚èµ°"å¿«é€Ÿé€šé“",é•¿è¯·æ±‚èµ°"æ‰¹å¤„ç†ä¸“çº¿"
- **ç›®çš„åœ°ç›¸åŒå¯æ‹¼è½¦**: ç›¸åŒ Prefix çš„è¯·æ±‚è·¯ç”±åˆ°åŒä¸€ Pod â†’ ç¼“å­˜å¤ç”¨
- **æ»¡è½½è½¦ä¸å†è£…è´§**: é˜Ÿåˆ—å·²æ»¡çš„ Pod è‡ªåŠ¨è¿‡æ»¤

---

ç°åœ¨ä½ å·²ç»å»ºç«‹äº†ç›´è§‚è®¤çŸ¥,ä¸‹ä¸€å±‚å°†æ­å¼€è°ƒåº¦ç®—æ³•çš„ç²¾ç¡®å®ç°ç»†èŠ‚ã€‚

---

## ğŸŒ€ èºæ—‹ 2: æœºåˆ¶å±‚ - Filterâ†’Scoreâ†’Select ç®—æ³•è¯¦è§£

### æœ¬å±‚ç›®æ ‡
æŒæ¡è°ƒåº¦å™¨çš„ä¸‰é˜¶æ®µå†³ç­–æµç¨‹ã€æ ¸å¿ƒ Scorer çš„æ•°å­¦åŸç†ã€ä¸ KV Cache Indexer çš„ååŒæœºåˆ¶ã€‚

---

### 2.1 è°ƒåº¦æµç¨‹æ—¶åºå›¾

```mermaid
sequenceDiagram
    participant C as å®¢æˆ·ç«¯
    participant GW as Gateway<br/>(Envoy)
    participant EPP as Endpoint Picker<br/>(è°ƒåº¦å™¨)
    participant IDX as KV Cache Indexer
    participant PROM as Prometheus
    participant P1 as Pod 1
    participant P2 as Pod 2
    participant P3 as Pod 3
    
    C->>GW: 1. POST /v1/chat/completions<br/>{prompt, max_tokens}
    GW->>EPP: 2. ext-proc è°ƒç”¨<br/>Header: x-prompt-hash
    
    Note over EPP: é˜¶æ®µ 0: å‘ç°æ‰€æœ‰å€™é€‰ Pod
    EPP->>PROM: 3. æŸ¥è¯¢ Pod åˆ—è¡¨ä¸æ ‡ç­¾
    PROM-->>EPP: InferencePool: [P1, P2, P3]
    
    Note over EPP: é˜¶æ®µ 1: Filter (è¿‡æ»¤)
    EPP->>PROM: 4. æŸ¥è¯¢ queue_depth
    PROM-->>EPP: P1:20, P2:5, P3:100 (æ»¡)
    EPP->>EPP: æ’é™¤ P3 (é˜Ÿåˆ—è¶…é˜ˆå€¼)
    
    Note over EPP: é˜¶æ®µ 2: Score (è¯„åˆ†)
    EPP->>IDX: 5. æŸ¥è¯¢ç¼“å­˜å‘½ä¸­ç‡<br/>Hash(prompt)
    IDX-->>EPP: P1:10%, P2:90%
    
    EPP->>EPP: 6. è®¡ç®—ç»¼åˆå¾—åˆ†<br/>P1: 10*100 + (1-20/50)*50 = 130<br/>P2: 90*100 + (1-5/50)*50 = 945
    
    Note over EPP: é˜¶æ®µ 3: Select (é€‰æ‹©)
    EPP->>EPP: 7. Top-K é€‰æ‹© (K=3)<br/>P2 å¾—åˆ†æœ€é«˜
    
    EPP-->>GW: 8. è¿”å› Pod 2 åœ°å€
    GW->>P2: 9. è½¬å‘è¯·æ±‚
    P2-->>C: 10. æµå¼è¿”å›ç»“æœ
```

**å…³é”®æ—¶é—´èŠ‚ç‚¹**:
- æ­¥éª¤ 2-8: è°ƒåº¦å†³ç­–è€—æ—¶ **<10ms** (ä¸é˜»å¡æ¨ç†)
- æ­¥éª¤ 5: ç¼“å­˜ç´¢å¼•æŸ¥è¯¢ **<1ms** (å†…å­˜å“ˆå¸Œè¡¨)
- æ­¥éª¤ 9-10: å®é™…æ¨ç†è€—æ—¶ 100ms-30s

---

### 2.2 é˜¶æ®µ 1: Filter (è¿‡æ»¤å™¨æ’ä»¶)

#### æ ¸å¿ƒè¿‡æ»¤å™¨å®ç°

**1. Queue Depth Filter (é˜Ÿåˆ—æ·±åº¦è¿‡æ»¤)**

```go
// ä¼ªä»£ç  (Go)
type QueueDepthFilter struct {
    MaxQueueLength int // é»˜è®¤ 50
}

func (f *QueueDepthFilter) Filter(pod *Pod) bool {
    queueDepth := prometheus.Query(
        fmt.Sprintf("vllm_queue_depth{pod=%s}", pod.Name),
    )
    return queueDepth < f.MaxQueueLength
}
```

**é…ç½®ç¤ºä¾‹**:
```yaml
filters:
  - type: queue-depth
    parameters:
      maxQueueLength: 50  # é˜Ÿåˆ—è¶… 50 åˆ™è¿‡æ»¤
```

---

**2. Memory Pressure Filter (å†…å­˜å‹åŠ›è¿‡æ»¤)**

```go
type MemoryPressureFilter struct {
    MaxKVUtilization float64 // é»˜è®¤ 0.95
}

func (f *MemoryPressureFilter) Filter(pod *Pod) bool {
    kvUtil := prometheus.Query(
        fmt.Sprintf("vllm_kv_cache_utilization{pod=%s}", pod.Name),
    )
    return kvUtil < f.MaxKVUtilization
}
```

**è§¦å‘é€»è¾‘**:
```mermaid
flowchart TD
    Start[Pod KV åˆ©ç”¨ç‡] --> Q1{> 95%?}
    Q1 -->|æ˜¯| F1[æ ‡è®°ä¸ºä¸å¯ç”¨<br/>é¿å… OOM]
    Q1 -->|å¦| Q2{> 85%?}
    Q2 -->|æ˜¯| F2[é™ä½è¯„åˆ†<br/>ä¼˜å…ˆå…¶ä»– Pod]
    Q2 -->|å¦| Pass[é€šè¿‡è¿‡æ»¤]
    
    style F1 fill:#ffebee
    style F2 fill:#fff9c4
    style Pass fill:#e8f5e9
```

---

**3. Model Compatibility Filter (æ¨¡å‹å…¼å®¹æ€§è¿‡æ»¤)**

```go
func (f *ModelCompatibilityFilter) Filter(pod *Pod, req *Request) bool {
    // æ£€æŸ¥ Pod æ ‡ç­¾ä¸­çš„æ¨¡å‹ ID
    podModelID := pod.Labels["model-id"]
    
    // æ£€æŸ¥ LoRA Adapter (å¦‚æœæœ‰)
    if req.Adapter != "" {
        return pod.LoadedAdapters.Contains(req.Adapter)
    }
    
    return podModelID == req.ModelID
}
```

**é€‚ç”¨åœºæ™¯**:
- å¤šæ¨¡å‹æœåŠ¡ (åŒä¸€é›†ç¾¤éƒ¨ç½² Llama-70B + Qwen3-32B)
- LoRA å¤šç§Ÿæˆ· (ä¸åŒå®¢æˆ·ä½¿ç”¨ä¸åŒ Adapter)

---

### 2.3 é˜¶æ®µ 2: Score (è¯„åˆ†å™¨æ’ä»¶)

#### Scorer 1: Prefix-Aware Scorer (ç¼“å­˜æ„ŸçŸ¥)

**æ ¸å¿ƒç®—æ³•**: Hash Block åŒ¹é…

```python
# ä¼ªä»£ç 
def prefix_aware_score(pod, request):
    # 1. å°† Prompt åˆ†å—å¹¶è®¡ç®— Hash
    prompt_tokens = tokenize(request.prompt)
    hash_blocks = []
    for i in range(0, len(prompt_tokens), HASH_BLOCK_SIZE):
        block = prompt_tokens[i:i+HASH_BLOCK_SIZE]
        hash_blocks.append(hash(block))
    
    # 2. æŸ¥è¯¢ KV Cache Indexer
    matched_blocks = 0
    for hash_value in hash_blocks:
        if kv_indexer.has_block(pod.id, hash_value):
            matched_blocks += 1
    
    # 3. è®¡ç®—å‘½ä¸­ç‡
    hit_rate = matched_blocks / len(hash_blocks)
    return hit_rate * 100  # è¿”å› 0-100 åˆ†
```

**å‚æ•°è¯¦è§£**:

| å‚æ•° | é»˜è®¤å€¼ | è°ƒä¼˜å»ºè®® |
|------|--------|---------|
| `hashBlockSize` | 5 | Prefix è¶Šé•¿è®¾ç½®è¶Šå¤§ (10-20),è¶ŠçŸ­è¶Šå° (3-5) |
| `weight` | 100 | é«˜ Prefix å¤ç”¨åœºæ™¯ä¿æŒ 100,ä½å¤ç”¨é™åˆ° 30 |

**å®æµ‹æ•ˆæœ** (é«˜ Prefix å¤ç”¨åœºæ™¯):
- ç¼“å­˜å‘½ä¸­ç‡: 12% â†’ **89%** (+77%)
- TTFT P95: 6.2s â†’ **157ms** (-97%)

---

#### Scorer 2: Load-Aware Scorer (è´Ÿè½½æ„ŸçŸ¥)

**æ ¸å¿ƒç®—æ³•**: é˜Ÿåˆ—æ·±åº¦å€’æ•°

```python
def load_aware_score(pod):
    queue_depth = get_queue_depth(pod)
    max_queue = 50  # å®¹é‡ä¸Šé™
    
    # è´Ÿè½½å› å­: é˜Ÿåˆ—è¶Šç©ºå¾—åˆ†è¶Šé«˜
    load_factor = 1 - (queue_depth / max_queue)
    return load_factor * 50  # è¿”å› 0-50 åˆ†
```

**è¯„åˆ†æ›²çº¿**:

```mermaid
%%{init: {'theme':'base'}}%%
graph TD
    subgraph è¯„åˆ†æ›²çº¿
    A[é˜Ÿåˆ—æ·±åº¦ 0<br/>å¾—åˆ† 50] --> B[é˜Ÿåˆ—æ·±åº¦ 10<br/>å¾—åˆ† 40]
    B --> C[é˜Ÿåˆ—æ·±åº¦ 25<br/>å¾—åˆ† 25]
    C --> D[é˜Ÿåˆ—æ·±åº¦ 40<br/>å¾—åˆ† 10]
    D --> E[é˜Ÿåˆ—æ·±åº¦ 50<br/>å¾—åˆ† 0]
    end
    
    style A fill:#e8f5e9
    style E fill:#ffebee
```

**é€‚ç”¨åœºæ™¯**: ä½ Prefix å¤ç”¨å·¥ä½œè´Ÿè½½ (æ‰¹å¤„ç†ã€å•æ¬¡æ¨ç†)

---

#### Scorer 3: Predicted Latency Balancing (é¢„æµ‹å»¶è¿Ÿå¹³è¡¡)

**å®éªŒæ€§åŠŸèƒ½** (v0.3+)

**æ ¸å¿ƒæ€æƒ³**: åŸºäºå†å²æ•°æ®é¢„æµ‹ TTFT/TPOT,é€‰æ‹©å»¶è¿Ÿæœ€ä½çš„ Pod

```python
def predicted_latency_score(pod, request):
    # 1. ä» Prometheus æŸ¥è¯¢å†å² TTFT
    hist_ttft = query_histogram(
        "vllm_time_to_first_token_seconds",
        pod=pod.id,
        prompt_len=len(request.prompt)
    )
    
    # 2. é¢„æµ‹å½“å‰è¯·æ±‚çš„ TTFT
    predicted_ttft = hist_ttft.percentile(0.5)  # ä¸­ä½æ•°
    
    # 3. å»¶è¿Ÿè¶Šä½å¾—åˆ†è¶Šé«˜
    return (1 / predicted_ttft) * 30
```

**é…ç½®ç¤ºä¾‹**:
```yaml
scorers:
  - type: predicted-latency
    weight: 30
    parameters:
      targetMetric: "ttft"  # æˆ– "tpot"
      percentile: 0.5       # P50
```

**å®æµ‹æ•ˆæœ** (é•¿ Prefill åœºæ™¯):
- TTFT P90: 3.2s â†’ **1.1s** (-66%)
- ä½†å¢åŠ è°ƒåº¦å¼€é”€ ~5ms

---

#### Scorer 4: LoRA-Aware Scorer (Adapter æ„ŸçŸ¥)

**v0.5 æ–°å¢åŠŸèƒ½**

**æ ¸å¿ƒç®—æ³•**: Adapter æœ¬åœ°åŒ–è¯„åˆ†

```python
def lora_aware_score(pod, request):
    if request.adapter == "":
        return 0  # æ—  Adapter éœ€æ±‚
    
    # æ£€æŸ¥ Pod æ˜¯å¦å·²åŠ è½½è¯¥ Adapter
    if pod.loaded_adapters.contains(request.adapter):
        return 100  # å®Œå…¨åŒ¹é…
    
    # æ£€æŸ¥ Pod æ˜¯å¦æœ‰ç©ºé—´åŠ è½½æ–° Adapter
    if pod.adapter_slots_available > 0:
        return 50  # å¯ä»¥åŠ è½½ä½†éœ€è¦æ—¶é—´
    
    return 0  # æ— æ³•åŠ è½½
```

**é€‚ç”¨åœºæ™¯**: å¤šç§Ÿæˆ· LoRA æœåŠ¡,é¿å…"é›·é¸£ç¾¤æ•ˆåº”"(æ‰€æœ‰ Pod æŠ¢åŠ è½½åŒä¸€ Adapter)

---

### 2.4 é˜¶æ®µ 3: Select (é€‰æ‹©ä¸å®¹é”™)

#### Top-K é€‰æ‹©ç­–ç•¥

```python
def select_pod(scored_pods):
    # 1. æŒ‰å¾—åˆ†æ’åº
    sorted_pods = sort(scored_pods, by="score", descending=True)
    
    # 2. Top-K é€‰æ‹© (æå‡é²æ£’æ€§)
    K = 3
    candidates = sorted_pods[:K]
    
    # 3. éšæœºæ‰“æ•£ (é¿å…é›ªå´©)
    import random
    selected = random.choice(candidates)
    
    return selected
```

**ä¸ºä»€ä¹ˆä¸æ€»æ˜¯é€‰ç¬¬ä¸€å?**

| ç­–ç•¥ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|
| **Always Top-1** | ç†è®ºæœ€ä¼˜ | å•ç‚¹è¿‡è½½ (é›ªå´©) |
| **Top-K Random** | è´Ÿè½½åˆ†æ•£ | è½»å¾®æ¬¡ä¼˜ (~5%) |

**å®æµ‹å¯¹æ¯”** (20 QPS å¹¶å‘):
- Top-1: TTFT P95 = 200ms, P99 = **3.5s** (é›ªå´©)
- Top-3: TTFT P95 = 220ms, P99 = **450ms** (ç¨³å®š)

---

#### Fallback æœºåˆ¶

```mermaid
flowchart TD
    Start[è°ƒåº¦è¯·æ±‚] --> Q1{æœ‰å¯ç”¨ Pod?}
    Q1 -->|æ˜¯| Normal[Filterâ†’Scoreâ†’Select]
    Q1 -->|å¦| Q2{å…¨éƒ¨è¿‡è½½?}
    
    Q2 -->|æ˜¯| Fallback1[é™çº§: Round-robin]
    Q2 -->|å¦| Fallback2[è¿”å› 503 é”™è¯¯]
    
    Fallback1 --> Retry[è§¦å‘æ‰©å®¹ä¿¡å·]
    Fallback2 --> Alert[å‘Šè­¦: å®¹é‡ä¸è¶³]
    
    style Normal fill:#e8f5e9
    style Fallback1 fill:#fff9c4
    style Fallback2 fill:#ffebee
```

---

### 2.5 ä¸ KV Cache Indexer çš„ååŒ

#### KVEvents äº‹ä»¶æµ

```mermaid
sequenceDiagram
    participant V as vLLM Pod
    participant Z as ZeroMQ<br/>(äº‹ä»¶æµ)
    participant IDX as KV Cache Indexer
    participant EPP as Endpoint Picker
    
    V->>V: 1. Prefill è®¡ç®—å®Œæˆ<br/>ç”Ÿæˆ KV Block 0-10
    V->>Z: 2. å‘å¸ƒ KVEvent<br/>{type: "block_created", blocks: [0-10]}
    Z->>IDX: 3. è®¢é˜…è€…æ¥æ”¶äº‹ä»¶
    IDX->>IDX: 4. æ›´æ–°å†…å­˜ç´¢å¼•<br/>Hash â†’ Pod æ˜ å°„
    
    Note over EPP: ä¸‹ä¸€æ¬¡è°ƒåº¦æ—¶
    EPP->>IDX: 5. æŸ¥è¯¢ç¼“å­˜<br/>Hash(prompt) â†’ [Pod1:90%, Pod2:10%]
    IDX-->>EPP: 6. è¿”å›è¯„åˆ†
```

**äº‹ä»¶ç±»å‹**:

| äº‹ä»¶ | è§¦å‘æ—¶æœº | ç´¢å¼•æ“ä½œ |
|------|---------|---------|
| `block_created` | Prefill å®Œæˆ | æ·»åŠ  Hash â†’ Pod æ˜ å°„ |
| `block_evicted` | KV Cache é©±é€ | åˆ é™¤æ˜ å°„ |
| `block_offloaded` | å¸è½½åˆ° CPU/FS | æ ‡è®°ä¸º"å¯æ¢å¤" |

---

#### ç´¢å¼•æ•°æ®ç»“æ„

```python
# ä¼ªä»£ç 
class KVCacheIndex:
    def __init__(self):
        # Hash Block â†’ [Pod ID, Tier, Timestamp]
        self.index = {}  # Dict[int, List[CacheEntry]]
    
    def add_block(self, hash_value, pod_id, tier="gpu"):
        self.index[hash_value].append(
            CacheEntry(pod_id, tier, time.now())
        )
    
    def query_hit_rate(self, hash_blocks, pod_id):
        hits = 0
        for hash_val in hash_blocks:
            if hash_val in self.index:
                entries = self.index[hash_val]
                if any(e.pod_id == pod_id for e in entries):
                    hits += 1
        return hits / len(hash_blocks)
```

---

### âœ… èºæ—‹ 2 éªŒæ”¶æ ‡å‡†

å®Œæˆæœ¬å±‚å­¦ä¹ å,ä½ åº”è¯¥èƒ½å¤Ÿ:

- [ ] ç”»å‡ºè°ƒåº¦æµç¨‹çš„å®Œæ•´æ—¶åºå›¾ (10 æ­¥)
- [ ] è§£é‡Šä¸‰ä¸ªæ ¸å¿ƒè¿‡æ»¤å™¨çš„è§¦å‘æ¡ä»¶: Queue Depth, Memory Pressure, Model Compatibility
- [ ] è®¡ç®— Prefix-aware Scorer çš„è¯„åˆ†: `matched_blocks / total_blocks * 100`
- [ ] è¯´æ˜ Top-K é€‰æ‹©ç›¸æ¯” Always Top-1 çš„é²æ£’æ€§ä¼˜åŠ¿
- [ ] ç†è§£ KVEvents å¦‚ä½•å®æ—¶æ›´æ–°ç¼“å­˜ç´¢å¼•

---

### ğŸ”— ä¸‹ä¸€æ­¥

æŒæ¡äº†ç®—æ³•åŸç†å,ä¸‹ä¸€å±‚å°†è¿›å…¥ **ç”Ÿäº§ç¯å¢ƒé…ç½®è°ƒä¼˜** ä¸ **æ•…éšœæ’æŸ¥å®æˆ˜**ã€‚

---

## ğŸŒ€ èºæ—‹ 3: å®æˆ˜å±‚ - é…ç½®è°ƒä¼˜ä¸æ•…éšœæ’æŸ¥

### æœ¬å±‚ç›®æ ‡
æŒæ¡ Inference Scheduler çš„ç”Ÿäº§çº§é…ç½®ã€æ ¸å¿ƒå‚æ•°è°ƒä¼˜ç­–ç•¥ã€ç›‘æ§æŒ‡æ ‡ä¸å…¸å‹æ•…éšœæ’æŸ¥æ–¹æ³•ã€‚

---

### 3.1 éƒ¨ç½²é…ç½®æœ€ä½³å®è·µ

#### Helm Chart é…ç½®ç¤ºä¾‹

```yaml
# values.yaml
inferenceExtension:
  # 1. åŸºç¡€é…ç½®
  replicas: 2  # EPP é«˜å¯ç”¨
  resources:
    requests:
      cpu: 500m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 1Gi
  
  # 2. æ’ä»¶é…ç½®
  pluginsCustomConfig:
    filters:
      - type: queue-depth
        parameters:
          maxQueueLength: 50  # æ ¹æ® max_num_seqs è°ƒæ•´
      
      - type: memory-pressure
        parameters:
          maxKVUtilization: 0.95
          checkInterval: 5s
    
    scorers:
      # é«˜ Prefix å¤ç”¨åœºæ™¯ (RAG/å¤šè½®å¯¹è¯)
      - type: prefix-aware
        weight: 100
        parameters:
          hashBlockSize: 5  # 3-20 å¯è°ƒ
          cacheIndexerURL: "http://kv-cache-indexer:9090"
      
      - type: load-aware
        weight: 50
        parameters:
          queueWeightFactor: 0.7
          activeRequestsWeight: 0.3
      
      # å¯é€‰: å®éªŒæ€§åŠŸèƒ½
      # - type: predicted-latency
      #   weight: 30
      #   parameters:
      #     targetMetric: "ttft"
      #     percentile: 0.5
  
  # 3. KV Cache Indexer é›†æˆ
  kvcacheIndexer:
    enabled: true
    zmqSubscriberURL: "tcp://*:5555"
```

---

### 3.2 æ ¸å¿ƒå‚æ•°è°ƒä¼˜æŒ‡å—

#### å‚æ•° 1: hashBlockSize (Hash å—å¤§å°)

**ä½œç”¨**: æ§åˆ¶ç¼“å­˜åŒ¹é…çš„ç²’åº¦

| hashBlockSize | é€‚ç”¨åœºæ™¯ | ç¼“å­˜å‘½ä¸­ç‡ | è®¡ç®—å¼€é”€ |
|--------------|---------|-----------|---------|
| **3** | çŸ­ Prompt (<500 tokens) | ä½ (ç»†ç²’åº¦) | ä½ |
| **5** (é»˜è®¤) | ä¸­ç­‰ Prompt (500-2k) | ä¸­ | ä¸­ |
| **10** | é•¿ Prompt (2k-8k) | é«˜ (ç²—ç²’åº¦) | é«˜ |
| **20** | è¶…é•¿ Prompt (>8k) | å¾ˆé«˜ | å¾ˆé«˜ |

**è°ƒä¼˜åŸåˆ™**:
```python
# ç»éªŒå…¬å¼
optimal_block_size = max(3, min(20, avg_prompt_len / 200))

# ç¤ºä¾‹
# RAG åœºæ™¯ (ç³»ç»Ÿæç¤ºè¯ 6k + ç”¨æˆ·é—®é¢˜ 500)
optimal = (6000 + 500) / 200 = 32.5 â†’ å– 20

# çŸ­å¯¹è¯åœºæ™¯ (å¹³å‡ 200 tokens)
optimal = 200 / 200 = 1 â†’ å– 3 (æœ€å°å€¼)
```

**å®æµ‹å¯¹æ¯”** (6k ç³»ç»Ÿæç¤ºè¯åœºæ™¯):

| hashBlockSize | ç¼“å­˜å‘½ä¸­ç‡ | TTFT P95 | è°ƒåº¦è€—æ—¶ |
|--------------|-----------|----------|---------|
| 3 | 45% | 850ms | 3ms |
| 5 | 72% | 280ms | 5ms |
| 10 | **89%** | **157ms** | 8ms |
| 20 | 91% | 145ms | 15ms |

**å»ºè®®**: 
- ç”Ÿäº§ç¯å¢ƒä¼˜å…ˆé€‰æ‹© **5-10**,å¹³è¡¡æ€§èƒ½ä¸å¼€é”€
- è¶…é•¿ä¸Šä¸‹æ–‡ (>10k) åœºæ™¯ä½¿ç”¨ **15-20**

---

#### å‚æ•° 2: Scorer Weight (è¯„åˆ†æƒé‡)

**åœºæ™¯ 1: é«˜ Prefix å¤ç”¨ (>50%)**
```yaml
scorers:
  - type: prefix-aware
    weight: 100  # ä¸»å¯¼å› ç´ 
  - type: load-aware
    weight: 30   # è¾…åŠ©å› ç´ 
```

**åœºæ™¯ 2: ä½ Prefix å¤ç”¨ (<20%)**
```yaml
scorers:
  - type: load-aware
    weight: 100  # ä¸»å¯¼å› ç´ 
  - type: prefix-aware
    weight: 0    # å…³é—­ç¼“å­˜è¯„åˆ†
```

**åœºæ™¯ 3: æ··åˆå·¥ä½œè´Ÿè½½**
```yaml
scorers:
  - type: prefix-aware
    weight: 60
  - type: load-aware
    weight: 60  # æƒé‡ç›¸ç­‰,ç»¼åˆè€ƒè™‘
```

**åŠ¨æ€è°ƒæ•´ç­–ç•¥**:
```python
# æ ¹æ®å®é™…ç¼“å­˜å‘½ä¸­ç‡åŠ¨æ€è°ƒæ•´
def adjust_weights(cache_hit_rate):
    if cache_hit_rate > 0.7:
        # é«˜å‘½ä¸­ç‡ â†’ å¼ºåŒ–ç¼“å­˜æ„ŸçŸ¥
        return {"prefix": 100, "load": 30}
    elif cache_hit_rate < 0.2:
        # ä½å‘½ä¸­ç‡ â†’ å¼±åŒ–ç¼“å­˜æ„ŸçŸ¥
        return {"prefix": 20, "load": 100}
    else:
        # ä¸­ç­‰å‘½ä¸­ç‡ â†’ å¹³è¡¡
        return {"prefix": 60, "load": 60}
```

---

#### å‚æ•° 3: maxQueueLength (é˜Ÿåˆ—æ·±åº¦é˜ˆå€¼)

**å…³ç³»**: åº”ä¸ vLLM çš„ `max_num_seqs` å¯¹é½

```yaml
# vLLM Deployment
env:
  - name: VLLM_MAX_NUM_SEQS
    value: "256"  # æœ€å¤§å¹¶å‘åºåˆ—æ•°

# Inference Scheduler
filters:
  - type: queue-depth
    parameters:
      maxQueueLength: 200  # è®¾ä¸º max_num_seqs çš„ 80%
```

**è°ƒä¼˜é€»è¾‘**:
```mermaid
flowchart TD
    Start[é˜Ÿåˆ—æ·±åº¦ç›‘æ§] --> Q1{å¹³å‡é˜Ÿåˆ— > 80%?}
    Q1 -->|æ˜¯| A1[é€‰é¡¹ 1: é™ä½ maxQueueLength<br/>å¼ºåˆ¶æµé‡åˆ†æ•£]
    Q1 -->|å¦| Q2{TTFT æŠ–åŠ¨å¤§?}
    
    Q2 -->|æ˜¯| A2[é€‰é¡¹ 2: æé«˜ maxQueueLength<br/>å…è®¸æ‰¹å¤„ç†]
    Q2 -->|å¦| OK[ä¿æŒå½“å‰é…ç½®]
    
    A1 --> V1[éªŒè¯: TTFT P95 ä¸‹é™?]
    A2 --> V2[éªŒè¯: ååæå‡?]
    
    style A1 fill:#fff9c4
    style A2 fill:#fff9c4
    style OK fill:#e8f5e9
```

---

### 3.3 ç›‘æ§æŒ‡æ ‡ä¸å‘Šè­¦

#### æ ¸å¿ƒæŒ‡æ ‡ä»ªè¡¨ç›˜

```yaml
# Grafana Dashboard JSON
{
  "panels": [
    {
      "title": "ç¼“å­˜å‘½ä¸­ç‡",
      "targets": [{
        "expr": "rate(kv_cache_hit_total[5m]) / rate(kv_cache_lookup_total[5m])"
      }],
      "thresholds": [
        {"value": 0.5, "color": "red"},
        {"value": 0.7, "color": "yellow"},
        {"value": 0.9, "color": "green"}
      ]
    },
    {
      "title": "è°ƒåº¦å»¶è¿Ÿ",
      "targets": [{
        "expr": "histogram_quantile(0.95, rate(epp_scheduling_duration_seconds_bucket[5m]))"
      }],
      "alert": "P95 > 50ms"
    },
    {
      "title": "Pod è´Ÿè½½åˆ†å¸ƒ",
      "targets": [{
        "expr": "vllm_queue_depth"
      }],
      "type": "heatmap"
    }
  ]
}
```

---

#### å››å±‚å‘Šè­¦è§„åˆ™

```yaml
# 1. ä¸šåŠ¡å±‚å‘Šè­¦ (SLO è¿çº¦)
- alert: HighTTFT
  expr: |
    histogram_quantile(0.95, 
      rate(vllm_time_to_first_token_seconds_bucket[5m])
    ) > 0.2
  for: 5m
  severity: critical
  annotations:
    summary: "TTFT P95 è¶…è¿‡ 200ms SLO"
    runbook: "æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡ã€é˜Ÿåˆ—æ·±åº¦"

# 2. åº”ç”¨å±‚å‘Šè­¦ (è°ƒåº¦å¼‚å¸¸)
- alert: LowCacheHitRate
  expr: |
    rate(kv_cache_hit_total[10m]) / 
    rate(kv_cache_lookup_total[10m]) < 0.3
  for: 10m
  severity: warning
  annotations:
    summary: "ç¼“å­˜å‘½ä¸­ç‡ä½äº 30%"
    action: "æ£€æŸ¥ hashBlockSize é…ç½®æˆ–å·¥ä½œè´Ÿè½½å˜åŒ–"

# 3. èµ„æºå±‚å‘Šè­¦ (è°ƒåº¦å™¨è‡ªèº«)
- alert: EPPHighLatency
  expr: |
    histogram_quantile(0.95,
      rate(epp_scheduling_duration_seconds_bucket[5m])
    ) > 0.05
  for: 5m
  severity: warning
  annotations:
    summary: "è°ƒåº¦å™¨ P95 å»¶è¿Ÿè¶… 50ms"
    action: "æ£€æŸ¥ KV Indexer è¿æ¥æˆ–å¢åŠ  EPP å‰¯æœ¬"

# 4. åŸºç¡€è®¾æ–½å‘Šè­¦ (Pod å¥åº·)
- alert: EPPPodDown
  expr: up{job="inference-scheduler"} == 0
  for: 1m
  severity: critical
```

---

### 3.4 å…¸å‹æ•…éšœæ’æŸ¥å†³ç­–æ ‘

#### é—®é¢˜ 1: ç¼“å­˜å‘½ä¸­ç‡ä½ (<30%)

```mermaid
flowchart TD
    Start[ç¼“å­˜å‘½ä¸­ç‡ < 30%] --> Q1{å·¥ä½œè´Ÿè½½æ˜¯å¦å˜åŒ–?}
    Q1 -->|æ˜¯| Fix1[é¢„æœŸè¡Œä¸º:<br/>æ–°ç”¨æˆ·/æ–°è¯é¢˜æ­£å¸¸]
    Q1 -->|å¦| Q2{hashBlockSize åˆé€‚?}
    
    Q2 -->|è¿‡å°| Fix2[å¢å¤§ hashBlockSize<br/>5 â†’ 10]
    Q2 -->|è¿‡å¤§| Fix3[å‡å° hashBlockSize<br/>10 â†’ 5]
    Q2 -->|åˆé€‚| Q3{KV Indexer æ­£å¸¸?}
    
    Q3 -->|å¼‚å¸¸| Fix4[æ£€æŸ¥ ZeroMQ è¿æ¥<br/>kubectl logs kv-indexer]
    Q3 -->|æ­£å¸¸| Fix5[æ£€æŸ¥ vLLM KVEvents<br/>æ˜¯å¦å¯ç”¨ PREFIX_CACHING]
    
    style Fix1 fill:#e8f5e9
    style Fix2 fill:#fff9c4
    style Fix3 fill:#fff9c4
    style Fix4 fill:#ffebee
    style Fix5 fill:#ffebee
```

**è°ƒè¯•å‘½ä»¤**:
```bash
# 1. æ£€æŸ¥ KV Indexer è¿æ¥
kubectl exec -it epp-pod -- curl http://kv-cache-indexer:9090/metrics | grep index_size

# 2. æ£€æŸ¥ vLLM Prefix Caching çŠ¶æ€
kubectl exec -it vllm-pod -- curl localhost:8000/metrics | grep prefix_cache

# 3. æ‰‹åŠ¨éªŒè¯ç¼“å­˜æŸ¥è¯¢
curl -X POST http://kv-indexer:9090/query \
  -d '{"prompt_hash": [123, 456, 789], "pods": ["pod1", "pod2"]}'
```

---

#### é—®é¢˜ 2: è°ƒåº¦å»¶è¿Ÿçªå¢ (P95 >50ms)

| æ ¹å›  | æ’æŸ¥æ–¹æ³• | è§£å†³æ–¹æ¡ˆ |
|------|---------|---------|
| **KV Indexer æ…¢æŸ¥è¯¢** | `kubectl top pod kv-indexer` | å¢åŠ  Indexer å†…å­˜æˆ–ä¼˜åŒ–ç´¢å¼•ç»“æ„ |
| **Prometheus æŸ¥è¯¢è¶…æ—¶** | `curl -w "%{time_total}" prom-url` | å¢åŠ  Prometheus èµ„æºæˆ–å‡å°‘æŸ¥è¯¢é¢‘ç‡ |
| **EPP Pod èµ„æºä¸è¶³** | `kubectl top pod epp-pod` | å¢åŠ  CPU limits æˆ–æ°´å¹³æ‰©å±• |
| **ç½‘ç»œå»¶è¿Ÿ** | `kubectl exec epp -- ping vllm-pod` | æ£€æŸ¥ CNI é…ç½®æˆ–èŠ‚ç‚¹äº²å’Œæ€§ |

---

#### é—®é¢˜ 3: è´Ÿè½½ä¸å‡ (æŸäº› Pod é˜Ÿåˆ—æ·±åº¦ >100)

**ç—‡çŠ¶**: 
```
Pod 1: queue_depth = 120
Pod 2: queue_depth = 5
Pod 3: queue_depth = 8
```

**æ ¹å› åˆ†æ**:

```python
# æ£€æŸ¥è¯„åˆ†é€»è¾‘
def debug_scoring(pods, request):
    for pod in pods:
        prefix_score = calculate_prefix_score(pod, request)
        load_score = calculate_load_score(pod)
        total = prefix_score * 100 + load_score * 50
        
        print(f"Pod {pod.id}:")
        print(f"  Prefix: {prefix_score} â†’ {prefix_score * 100}")
        print(f"  Load: {load_score} â†’ {load_score * 50}")
        print(f"  Total: {total}")
```

**å¸¸è§åŸå› **:

1. **ç¼“å­˜äº²å’Œæ€§è¿‡å¼º**: `prefix-aware` æƒé‡è¿‡é«˜
   ```yaml
   # è°ƒæ•´å‰
   scorers:
     - type: prefix-aware
       weight: 100
     - type: load-aware
       weight: 10  # æƒé‡å¤ªä½!
   
   # è°ƒæ•´å
   scorers:
     - type: prefix-aware
       weight: 70
     - type: load-aware
       weight: 50  # æé«˜æƒé‡
   ```

2. **Top-K æœªå¯ç”¨**: æ€»æ˜¯é€‰æ‹©ç¬¬ä¸€å
   ```yaml
   selection:
     topK: 3  # å¯ç”¨ Top-3 éšæœº
   ```

3. **æŸä¸ª Pod çœŸçš„æœ‰ç¼“å­˜ä¼˜åŠ¿**: é¢„æœŸè¡Œä¸º,è§¦å‘æ‰©å®¹

---

### 3.5 æ€§èƒ½ä¼˜åŒ– Checklist

#### å»¶è¿Ÿä¼˜åŒ– (TTFT)

- [ ] **ç¼“å­˜å‘½ä¸­ç‡ >70%**
  - è°ƒæ•´ `hashBlockSize` åŒ¹é… Prompt é•¿åº¦
  - ç¡®ä¿ KV Indexer å®æ—¶æ›´æ–° (<1s å»¶è¿Ÿ)

- [ ] **é˜Ÿåˆ—æ·±åº¦ <30**
  - é™ä½ `maxQueueLength` å¼ºåˆ¶åˆ†æ•£
  - æˆ–è§¦å‘ HPA æ‰©å®¹

- [ ] **è°ƒåº¦å»¶è¿Ÿ <10ms**
  - ä¼˜åŒ– Prometheus æŸ¥è¯¢ (å¢åŠ ç¼“å­˜)
  - KV Indexer ä½¿ç”¨å†…å­˜ç´¢å¼•

---

#### ååä¼˜åŒ– (Throughput)

- [ ] **è´Ÿè½½å‡è¡¡åº¦ >80%**
  - æé«˜ `load-aware` æƒé‡
  - å¯ç”¨ Top-K é€‰æ‹©

- [ ] **æ‰¹å¤„ç†å¤§å°æœ€å¤§åŒ–**
  - å…è®¸é˜Ÿåˆ—é€‚å½“å †ç§¯ (`maxQueueLength: 100`)
  - é…åˆ vLLM `max_num_batched_tokens`

- [ ] **ç¼“å­˜å¤ç”¨ç‡ >50%**
  - åˆ†æå·¥ä½œè´Ÿè½½ Prefix åˆ†å¸ƒ
  - è€ƒè™‘é¢„çƒ­å¸¸è§ Prompt

---

#### æˆæœ¬ä¼˜åŒ–

- [ ] **GPU åˆ©ç”¨ç‡ >70%**
  - é¿å…è¿‡åº¦åˆ†æ•£ (é™ä½ Pod æ•°é‡)
  - æé«˜å• Pod é˜Ÿåˆ—ä¸Šé™

- [ ] **å‡å°‘å†·å¯åŠ¨**
  - å¯ç”¨ Scale-to-Zero å‰è¯„ä¼°å†·å¯åŠ¨æˆæœ¬
  - ä½¿ç”¨ Prefix Caching å‡å°‘é‡å¤è®¡ç®—

---

### âœ… èºæ—‹ 3 éªŒæ”¶æ ‡å‡†

å®Œæˆæœ¬å±‚å­¦ä¹ å,ä½ åº”è¯¥èƒ½å¤Ÿ:

- [ ] é…ç½®é€‚åˆç”Ÿäº§çš„ Inference Scheduler Helm Chart
- [ ] æ ¹æ®å·¥ä½œè´Ÿè½½ç‰¹å¾è°ƒä¼˜ `hashBlockSize` å’Œ Scorer æƒé‡
- [ ] å»ºç«‹å››å±‚ç›‘æ§æŒ‡æ ‡ä½“ç³»å¹¶è®¾ç½®å‘Šè­¦è§„åˆ™
- [ ] ä½¿ç”¨æ•…éšœå†³ç­–æ ‘è¯Šæ–­ç¼“å­˜å‘½ä¸­ç‡ä½ã€è°ƒåº¦å»¶è¿Ÿé«˜ã€è´Ÿè½½ä¸å‡ç­‰é—®é¢˜
- [ ] æ‰§è¡Œæ€§èƒ½ä¼˜åŒ– Checklist,å¹³è¡¡å»¶è¿Ÿã€ååä¸æˆæœ¬

---

### ğŸ“ æ€»ç»“

**Inference Scheduler çš„ç”Ÿäº§ä»·å€¼**:
- **æ€§èƒ½**: é«˜ Prefix å¤ç”¨åœºæ™¯ä¸‹ TTFT -99%, åå +109%
- **çµæ´»**: æ’ä»¶åŒ–æ¶æ„,æ”¯æŒè‡ªå®šä¹‰ Filter/Scorer
- **å¯è§‚æµ‹**: ä¸°å¯Œçš„æŒ‡æ ‡ä¸æ•…éšœå†³ç­–æ ‘
- **ä½ä¾µå…¥**: åŸºäº Gateway API,æ— éœ€ä¿®æ”¹ vLLM ä»£ç 

**ä¸‹ä¸€æ­¥**:
- ğŸ“– é˜…è¯» [KV Cache Management](./kv-cache.md) äº†è§£ç¼“å­˜ç´¢å¼•çš„å®ç°ç»†èŠ‚
- ğŸ§ª éƒ¨ç½² [Inference Scheduling Well-Lit Path](../integration/production-patterns.md#inference-scheduling)
- ğŸ“Š æ ¹æ®å®é™…å·¥ä½œè´Ÿè½½æŒç»­è°ƒä¼˜ Scorer æƒé‡

---

## ğŸ”— ç›¸å…³ç»„ä»¶

- [**KV Cache Management**](./kv-cache.md) - ç¼“å­˜ç´¢å¼•ä¸ºè°ƒåº¦å™¨æä¾›å‘½ä¸­ç‡è¯„åˆ†
- [**P/D Disaggregation**](./pd-disaggregation.md) - è°ƒåº¦å™¨éœ€è¯†åˆ« Prefill/Decode Pod
- [**Production Patterns**](../integration/production-patterns.md) - Inference Scheduling Well-Lit Path

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [Inference Scheduler æ¶æ„æ–‡æ¡£](https://github.com/llm-d/llm-d-inference-scheduler/blob/main/docs/architecture.md)
- [Intelligent Inference Scheduling Blog](https://llm-d.ai/blog/intelligent-inference-scheduling-with-llm-d)
- [Gateway API Inference Extension](https://github.com/kubernetes-sigs/gateway-api-inference-extension)
