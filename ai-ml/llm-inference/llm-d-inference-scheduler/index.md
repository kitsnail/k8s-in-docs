# llm-d Inference Scheduler - æ’ä»¶åŒ–æ¨ç†è·¯ç”±å¼•æ“

> **æ ¸å¿ƒä»·å€¼**: åŸºäº Gateway API çš„å¯æ‰©å±• LLM æ¨ç†è°ƒåº¦å™¨,é€šè¿‡ Filter-Scorer-Picker ä¸‰å±‚æ’ä»¶å®ç°æ™ºèƒ½è·¯ç”±  
> **æŠ€æœ¯æ ˆ**: Gateway API Inference Extension + Envoy ext-proc + Go  
> **å…³é”®æŒ‡æ ‡**: TTFT -99%, åå +109%, KV-cache å‘½ä¸­ç‡ >89%

---

## ğŸŒ€ èºæ—‹ 1: æ¦‚å¿µå±‚ - ä¸ºä»€ä¹ˆéœ€è¦ä¸“ç”¨æ¨ç†è°ƒåº¦å™¨?

### æœ¬å±‚ç›®æ ‡
ç†è§£ LLM æ¨ç†çš„èµ„æºç‰¹æ€§ä¸ä¼ ç»Ÿè´Ÿè½½å‡è¡¡çš„çŸ›ç›¾,å»ºç«‹å¯¹"æ™ºèƒ½è°ƒåº¦"å¿…è¦æ€§çš„è®¤çŸ¥,æŒæ¡ llm-d Inference Scheduler åœ¨ Gateway API ç”Ÿæ€ä¸­çš„æ¶æ„å®šä½ã€‚

---

### 1.1 LLM æ¨ç†çš„ä¸‰å¤§èµ„æºç‰¹æ€§

ä¼ ç»Ÿå¾®æœåŠ¡çš„è´Ÿè½½å‡è¡¡åŸºäºä»¥ä¸‹å‡è®¾:
- âœ… è¯·æ±‚å¤„ç†æ—¶é—´ç›¸å¯¹å‡åŒ€ (10-100ms)
- âœ… èµ„æºæ¶ˆè€—å¯é¢„æµ‹ (å›ºå®š CPU/å†…å­˜)
- âœ… æ— çŠ¶æ€,å®ä¾‹é—´å®Œå…¨å¯¹ç­‰

**ä½† LLM æ¨ç†å½»åº•æ‰“ç ´äº†è¿™äº›å‡è®¾:**

| ç»´åº¦ | ä¼ ç»ŸæœåŠ¡ | LLM æ¨ç† | é—®é¢˜ |
|------|---------|---------|------|
| **è¯·æ±‚è€—æ—¶** | 10-100ms | 100ms-30s (å·® 300x) | çŸ­è¯·æ±‚è¢«é•¿è¯·æ±‚é˜»å¡ |
| **å†…å­˜éœ€æ±‚** | å›ºå®š | KV Cache åŠ¨æ€å¢é•¿ | æŸäº› Pod çªç„¶ OOM |
| **çŠ¶æ€ä¾èµ–** | æ— çŠ¶æ€ | ç¼“å­˜å‘½ä¸­ç‡å·®å¼‚ 90% | é‡å¤è®¡ç®—æµªè´¹ |

**æ ¸å¿ƒçŸ›ç›¾**: Round-robin è´Ÿè½½å‡è¡¡æ— æ³•æ„ŸçŸ¥è¿™äº›å·®å¼‚,å¯¼è‡´:
- ğŸ“‰ **TTFT æŠ–åŠ¨**: P95 å»¶è¿Ÿå¯è¾¾ P50 çš„ 20 å€
- ğŸ’¸ **èµ„æºæµªè´¹**: ç¼“å­˜å‘½ä¸­ç‡ä» 90% é™è‡³ 12%
- âš ï¸ **é›ªå´©é£é™©**: é•¿è¯·æ±‚å †ç§¯å¯¼è‡´å• Pod è¿‡è½½

---

### 1.2 ç”Ÿäº§ç—›ç‚¹æ¡ˆä¾‹ - åŒ11 AI å®¢æœå´©æºƒ

**åœºæ™¯**: æŸç”µå•†å¹³å°åœ¨åŒ11 æµé‡æ´ªå³°æœŸçš„ AI å®¢æœç³»ç»Ÿ

```mermaid
sequenceDiagram
    participant U1 as ç”¨æˆ· 1<br/>(è¯¢é—®è®¢å•çŠ¶æ€)
    participant U2 as ç”¨æˆ· 2<br/>(å¤æ‚é€€è´§é—®é¢˜)
    participant LB as K8s Service<br/>Round-robin
    participant P1 as Pod 1<br/>(é˜Ÿåˆ—: 5 ä¸ªé•¿è¯·æ±‚)
    participant P2 as Pod 2<br/>(é˜Ÿåˆ—: ç©º)
    
    U1->>LB: "æˆ‘çš„å¿«é€’åˆ°å“ªäº†?"
    LB->>P1: è·¯ç”±åˆ° Pod 1
    Note over P1: æ’é˜Ÿç­‰å¾… 5 ä¸ªé•¿è¯·æ±‚<br/>é¢„æœŸ 0.5s â†’ å®é™… 25s
    P1--xU1: è¶…æ—¶å¤±è´¥
    
    U2->>LB: "å¦‚ä½•å¤„ç†å•†å“æŸå?"
    LB->>P2: è·¯ç”±åˆ° Pod 2  
    P2-->>U2: 200ms å“åº”
    
    Note over P2: Pod 2 ç©ºé—²,ä½†ä¼ ç»Ÿ LB<br/>æ— æ³•æ™ºèƒ½åˆ†é…æ›´å¤šæµé‡
    
    style P1 fill:#ffebee
    style P2 fill:#e8f5e9
```

**å®æµ‹æ•°æ®**:
- æˆåŠŸç‡: **87%** (13% è¶…æ—¶)
- TTFT P95: **6.2s** (ç”¨æˆ·ä¸å¯æ¥å—)
- GPU åˆ©ç”¨ç‡: **45%** (èµ„æºä¸¥é‡æµªè´¹)

**æ ¹æœ¬åŸå› **: K8s Service å¯¹ä»¥ä¸‹ä¿¡æ¯**å®Œå…¨ç›²è§†**:
1. è¯·æ±‚ç‰¹å¾ (çŸ­ Prompt vs é•¿ Prompt)
2. Pod çŠ¶æ€ (é˜Ÿåˆ—æ·±åº¦ã€KV Cache å ç”¨)
3. ç¼“å­˜äº²å’Œæ€§ (å“ªäº› Pod æœ‰å†å²ä¸Šä¸‹æ–‡)

---

### 1.3 llm-d Inference Scheduler çš„æ¶æ„å®šä½

**æ ¸å¿ƒå®šä½**: **Gateway å±‚çš„æ™ºèƒ½è·¯ç”±å†³ç­–å¼•æ“**

llm-d Inference Scheduler å¹¶éç‹¬ç«‹çš„è´Ÿè½½å‡è¡¡å™¨,è€Œæ˜¯é€šè¿‡ **Envoy ext-proc** æ‰©å±•ç°æœ‰ Gateway (Istio/Envoy Gateway/kgateway) çš„èƒ½åŠ›:

```mermaid
flowchart TB
    subgraph Client [å®¢æˆ·ç«¯]
        APP[åº”ç”¨ç¨‹åº<br/>OpenAI SDK]
    end
    
    subgraph Gateway [Kubernetes Gateway API]
        GW[Envoy Gateway<br/>HTTPRoute]
        EXT[ext-proc<br/>Extension Point]
    end
    
    subgraph EPP [Endpoint Picker Plugin - llm-d]
        FILTER[Filter å±‚<br/>è¿‡æ»¤ä¸å¯ç”¨ Pod]
        SCORER[Scorer å±‚<br/>å¤šç»´åº¦è¯„åˆ†]
        PICKER[Picker å±‚<br/>é€‰æ‹©æœ€ä¼˜ Pod]
        
        FILTER --> SCORER --> PICKER
    end
    
    subgraph Backend [InferencePool]
        P1[vLLM Pod 1]
        P2[vLLM Pod 2]
        P3[vLLM Pod 3]
    end
    
    subgraph DataPlane [æ•°æ®å¹³é¢]
        IDX[(KV Cache<br/>Indexer)]
        PROM[(Prometheus)]
    end
    
    APP -->|HTTP/2 æµå¼| GW
    GW -->|è°ƒç”¨æ’ä»¶| EXT
    EXT <-->|è¯·æ±‚/å“åº”| EPP
    
    EPP -->|æŸ¥è¯¢ç¼“å­˜| IDX
    EPP -->|æŸ¥è¯¢æŒ‡æ ‡| PROM
    
    EPP -.é€‰æ‹© Pod.-> GW
    GW -->|è·¯ç”±è¯·æ±‚| P1 & P2 & P3
    
    style EPP fill:#e1f5fe
    style Gateway fill:#fff9c4
    style Backend fill:#e8f5e9
    style DataPlane fill:#f3e5f5
```

**ä¸ GIE (Gateway API Inference Extension) çš„å…³ç³»**:

| é¡¹ç›® | èŒè´£ | å…³ç³» |
|------|------|------|
| **GIE (Upstream)** | å®šä¹‰ API èµ„æº (`InferencePool`, `InferenceModel`) ä¸è°ƒåº¦æ¡†æ¶ | ä¸Šæ¸¸é¡¹ç›®,é€šç”¨æ¨ç†è°ƒåº¦æ ‡å‡† |
| **llm-d Scheduler** | å®ç° llm-d ç‰¹å®šåŠŸèƒ½ (P/D åˆ†ç¦»ã€Precise Prefix Cache) | æ‰©å±• GIE,ä¸“æ³¨ LLM åœºæ™¯ |

**åŠŸèƒ½åˆ†å±‚**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  llm-d Inference Scheduler             â”‚  llm-d ç‰¹å®šå®ç°
â”‚  â”œâ”€ P/D Disaggregation                 â”‚  - Prefill/Decode åˆ†ç¦»
â”‚  â”œâ”€ Precise Prefix Cache Scorer        â”‚  - å®æ—¶ KV Cache è¿½è¸ª
â”‚  â””â”€ NoHit LRU Scorer                   â”‚  - å†·è¯·æ±‚è´Ÿè½½å‡è¡¡
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Gateway API Inference Extension (GIE) â”‚  é€šç”¨æ¨ç†è°ƒåº¦æ¡†æ¶
â”‚  â”œâ”€ InferencePool CRD                  â”‚  - API èµ„æºå®šä¹‰
â”‚  â”œâ”€ Scheduler Plugin Framework         â”‚  - æ’ä»¶æ‰©å±•æœºåˆ¶
â”‚  â””â”€ Prefix Cache Scorer (åŸºç¡€ç‰ˆ)        â”‚  - å†å²ä¼°ç®—å¼ç¼“å­˜è¯„åˆ†
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Gateway API                           â”‚  Kubernetes æ ‡å‡†
â”‚  â”œâ”€ HTTPRoute                          â”‚  - è·¯ç”±é…ç½®
â”‚  â””â”€ ext-proc Extension Point           â”‚  - æ‰©å±•ç‚¹æœºåˆ¶
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 1.4 ä¸‰å±‚æ’ä»¶æ¶æ„ - Filter â†’ Scorer â†’ Picker

**æ ¸å¿ƒè®¾è®¡å“²å­¦**: **ç»„åˆä¼˜äºç»§æ‰¿,æ’ä»¶ä¼˜äºç¡¬ç¼–ç **

```mermaid
flowchart LR
    subgraph Phase1 [é˜¶æ®µ 1: Filter - è¿‡æ»¤]
        F1[Queue Depth<br/>Filter]
        F2[Memory<br/>Pressure Filter]
        F3[Model<br/>Compatibility]
        
        PODS[å€™é€‰ Pod åˆ—è¡¨] --> F1 --> F2 --> F3
    end
    
    subgraph Phase2 [é˜¶æ®µ 2: Scorer - è¯„åˆ†]
        S1[Prefix Cache<br/>Scorer<br/>æƒé‡ 100]
        S2[Load Aware<br/>Scorer<br/>æƒé‡ 50]
        S3[Session<br/>Affinity<br/>æƒé‡ 30]
        
        F3 --> S1 & S2 & S3
        S1 & S2 & S3 --> SUM[åŠ æƒæ±‚å’Œ]
    end
    
    subgraph Phase3 [é˜¶æ®µ 3: Picker - é€‰æ‹©]
        SUM --> TOPK[Top-K é€‰æ‹©<br/>K=3]
        TOPK --> RAND[éšæœºæ‰“æ•£]
        RAND --> SELECT[é€‰å®š Pod]
    end
    
    style Phase1 fill:#ffebee
    style Phase2 fill:#fff9c4
    style Phase3 fill:#e8f5e9
```

**è®¾è®¡ä¼˜åŠ¿**:

| ç»´åº¦ | ä¼ ç»Ÿç¡¬ç¼–ç  | llm-d æ’ä»¶åŒ– |
|------|-----------|------------|
| **æ‰©å±•æ€§** | ä¿®æ”¹æ ¸å¿ƒä»£ç  | æ–°å¢æ’ä»¶æ–‡ä»¶ |
| **ç»„åˆæ€§** | å›ºå®šé€»è¾‘ | çµæ´»é…ç½®ç»„åˆ |
| **æµ‹è¯•æ€§** | é›†æˆæµ‹è¯• | æ’ä»¶å•å…ƒæµ‹è¯• |
| **ç¤¾åŒºåŒ–** | ç»´æŠ¤è€…ä¸»å¯¼ | ç¤¾åŒºè´¡çŒ®æ’ä»¶ |

**å®é™…æ”¶ç›Š** (Qwen3-32B é«˜ Prefix å¤ç”¨åœºæ™¯):

| æŒ‡æ ‡ | K8s Service | llm-d Scheduler | æå‡ |
|------|-------------|----------------|------|
| **TTFT P50** | 6.2s | **136ms** | ğŸ“‰ 97.8% â†“ |
| **TTFT P95** | 12.5s | **157ms** | ğŸ“‰ 98.7% â†“ |
| **ç¼“å­˜å‘½ä¸­ç‡** | 12% | **89%** | ğŸ“ˆ +77% |
| **åå (20 QPS)** | 9k tok/s | **11k tok/s** | ğŸ“ˆ +22% |

---

### âœ… èºæ—‹ 1 éªŒæ”¶æ ‡å‡†

å®Œæˆæœ¬å±‚å­¦ä¹ å,ä½ åº”è¯¥èƒ½å¤Ÿ:

- [ ] åˆ—ä¸¾ LLM æ¨ç†ä¸ä¼ ç»Ÿå¾®æœåŠ¡çš„ä¸‰å¤§å·®å¼‚: èµ„æºéœ€æ±‚ä¸å‡ã€çŠ¶æ€ä¾èµ–ã€è€—æ—¶æ³¢åŠ¨
- [ ] ç”¨ä¸€å¥è¯è¯´æ˜ llm-d Inference Scheduler çš„æ ¸å¿ƒä»·å€¼: _"é€šè¿‡ Gateway API ext-proc æ‰©å±•ç‚¹å®ç°è¯·æ±‚ç‰¹å¾ä¸ Pod çŠ¶æ€æ„ŸçŸ¥çš„æ™ºèƒ½è·¯ç”±"_
- [ ] ç†è§£ llm-d Scheduler ä¸ GIE çš„åˆ†å·¥: GIE æä¾›æ¡†æ¶,llm-d å®ç° LLM ä¸“å±åŠŸèƒ½
- [ ] è¯´æ˜ä¸‰å±‚æ’ä»¶æ¶æ„çš„èŒè´£: Filter (æ’é™¤) â†’ Scorer (è¯„åˆ†) â†’ Picker (é€‰æ‹©)

---

### ğŸ”— ä¸‹ä¸€æ­¥

ç†è§£äº†"ä¸ºä»€ä¹ˆéœ€è¦"å’Œ"æ˜¯ä»€ä¹ˆ"å,ä¸‹ä¸€å±‚å°†æ·±å…¥ **Filter-Scorer-Picker ä¸‰é˜¶æ®µç®—æ³•çš„åº•å±‚æœºåˆ¶** ä¸ **æ ¸å¿ƒæ’ä»¶çš„æ•°å­¦åŸç†**

---

## ğŸ’¨ è®¤çŸ¥é™å‹ - ä»"å¿«é€’è°ƒåº¦ä¸­å¿ƒ"ç†è§£æ™ºèƒ½è·¯ç”±

### å¸¸è¯†ç±»æ¯”: æ™ºèƒ½å¿«é€’åˆ†æ‹£ç³»ç»Ÿ

æƒ³è±¡ä¸€ä¸ªåŒ11 æœŸé—´çš„å¿«é€’æ¢çº½ä¸­å¿ƒ,æ¯ç§’å¤„ç†æ•°åƒä¸ªåŒ…è£¹:

**âŒ ä¼ ç»Ÿè½®è¯¢ (Round-robin) - ç›²ç›®æ’é˜Ÿ**

```
åŒ…è£¹ A (åŒåŸ,1kg,é¢„æœŸ 1å¤©é€è¾¾)   â†’ è½¦è¾† 1 (é˜Ÿåˆ—: 10 å¨è·¨çœè´§,5å¤©é€è¾¾)  
åŒ…è£¹ B (è·¨çœ,50kg,å¯æ‰¹é‡è¿è¾“)   â†’ è½¦è¾† 2 (ç©ºè½½,å»å¾€åŒåŸ)  
åŒ…è£¹ C (ç›®çš„åœ°ä¸ A ç›¸åŒ)         â†’ è½¦è¾† 3 (å»åæ–¹å‘)
```

**ç»“æœ**: 
- åŒåŸå¿«é€’è·Ÿç€è·¨çœè½¦èµ°æ…¢äº† 5 å¤© (TTFT åŠ£åŒ–)
- è·¨çœå¤§ä»¶å ç”¨åŒåŸå¿«è½¦,è¿åŠ›æµªè´¹ (èµ„æºåˆ©ç”¨ç‡ä½)
- ç›¸åŒç›®çš„åœ°çš„åŒ…è£¹åˆ†æ•£è£…è½¦,æ— æ³•æ‹¼è½¦ä¼˜åŒ– (ç¼“å­˜æœªå¤ç”¨)

---

**âœ… æ™ºèƒ½åˆ†æ‹£ç³»ç»Ÿ (llm-d Scheduler) - ä¸‰é˜¶æ®µå†³ç­–**

```mermaid
flowchart LR
    subgraph åŒ…è£¹å…¥åº“ [åŒ…è£¹å…¥åº“]
        P1[åŒ…è£¹ A<br/>åŒåŸ 1kg]
        P2[åŒ…è£¹ B<br/>è·¨çœ 50kg]
        P3[åŒ…è£¹ C<br/>åŒç›®çš„åœ°]
    end
    
    subgraph é˜¶æ®µ1 [é˜¶æ®µ 1: è¿‡æ»¤ä¸å¯ç”¨è½¦è¾†]
        F[æ’é™¤:<br/>âŒ æ»¡è½½è½¦è¾†<br/>âŒ åæ–¹å‘çº¿è·¯<br/>âŒ æ•…éšœè½¦è¾†]
    end
    
    subgraph é˜¶æ®µ2 [é˜¶æ®µ 2: è¯„åˆ†ä¼˜é€‰]
        S1[ç›®çš„åœ°åŒ¹é…<br/>åŒåŸ +100 åˆ†]
        S2[è½¦è¾†ç©ºé—²åº¦<br/>ç©ºè½½ +50 åˆ†]
        S3[çº¿è·¯æ—¶æ•ˆæ€§<br/>å¿«çº¿ +30 åˆ†]
    end
    
    subgraph é˜¶æ®µ3 [é˜¶æ®µ 3: é€‰æ‹©è½¦è¾†]
        SEL[Top-3 éšæœº<br/>é¿å…æ‰å †]
    end
    
    P1 & P2 & P3 --> F
    F --> S1 & S2 & S3
    S1 & S2 & S3 --> SEL
    
    SEL -.åŒ…è£¹ A.-> V1[åŒåŸä¸“çº¿è½¦<br/>å¿«é€Ÿå‘¨è½¬]
    SEL -.åŒ…è£¹ B.-> V2[è·¨çœå¹²çº¿è½¦<br/>æ‰¹é‡è¿è¾“]
    SEL -.åŒ…è£¹ C.-> V1
    
    style é˜¶æ®µ1 fill:#ffebee
    style é˜¶æ®µ2 fill:#fff9c4
    style é˜¶æ®µ3 fill:#e8f5e9
```

**åˆ†æ‹£è§„åˆ™æ˜ å°„åˆ°è°ƒåº¦ç®—æ³•**:

| å¿«é€’åœºæ™¯ | LLM æ¨ç† | è°ƒåº¦å±‚ |
|---------|---------|-------|
| **åŒ…è£¹ç±»å‹** (åŒåŸ/è·¨çœ) | è¯·æ±‚é•¿åº¦ (çŸ­/é•¿ Prompt) | - |
| **ç›®çš„åœ°** | Prompt Hash (å‰ç¼€ç‰¹å¾) | - |
| **è½¦è¾†** | vLLM Pod | - |
| **è½¦è¾†è½½é‡** | é˜Ÿåˆ—æ·±åº¦ (`queue_length`) | - |
| **æ»¡è½½è½¦** | é˜Ÿåˆ—å·²æ»¡ (`> max_num_seqs`) | **Filter** |
| **åæ–¹å‘çº¿è·¯** | æ¨¡å‹ä¸åŒ¹é… (`model_id`) | **Filter** |
| **æ‹¼è½¦è·¯çº¿** | ç¼“å­˜å‘½ä¸­ (ç›¸åŒ Prefix) | **Scorer** |
| **è½¦è¾†ç©ºé—²åº¦** | è´Ÿè½½å› å­ (`1 - queue/max`) | **Scorer** |
| **æ»¡è½½å‘è½¦** | æ‰¹å¤„ç†è§¦å‘ (`max_num_batched_tokens`) | vLLM å¼•æ“ |
| **Top-3 éšæœº** | é¿å…å•è½¦è¿‡è½½ | **Picker** |

---

### ä¸ºä»€ä¹ˆéœ€è¦"æ™ºèƒ½"è€Œé"ç®€å•"?

**åœºæ™¯ 1: ç¼“å­˜äº²å’Œæ€§ (ç›®çš„åœ°æ‹¼è½¦)**

```
åŒ…è£¹ D (å»å¾€åŒ—äº¬æœé˜³åŒºæŸå°åŒº)  
åŒ…è£¹ E (å»å¾€åŒ—äº¬æœé˜³åŒºåŒä¸€å°åŒº)

æ™ºèƒ½åˆ†æ‹£: D å’Œ E éƒ½è£…ä¸Šè½¦è¾† 4 (å·²å»è¿‡è¯¥å°åŒº,ç†Ÿæ‚‰è·¯çº¿)
â†’ èŠ‚çœ 90% çš„å¯¼èˆªæ—¶é—´ (ç±»æ¯”: KV Cache å‘½ä¸­)
```

**åœºæ™¯ 2: è´Ÿè½½å‡è¡¡ (è½¦è¾†ç©ºé—²åº¦)**

```
è½¦è¾† 1: é˜Ÿåˆ— 100 ä»¶
è½¦è¾† 2: é˜Ÿåˆ— 5 ä»¶

Round-robin å¯èƒ½ç»§ç»­å¾€è½¦è¾† 1 å¡ â†’ è¶…è½½
æ™ºèƒ½åˆ†æ‹£: æ–°åŒ…è£¹ä¼˜å…ˆåˆ†é…è½¦è¾† 2 â†’ å‡è¡¡è´Ÿè½½
```

**åœºæ™¯ 3: å®¹é”™ (Top-K éšæœº)**

```
å‡è®¾è½¦è¾† 3 è¯„åˆ†æœ€é«˜ (100 åˆ†)
è½¦è¾† 4 å’Œ 5 è¯„åˆ†ä¹Ÿä¸é”™ (98 åˆ†)

Always Top-1: æ‰€æœ‰åŒ…è£¹éƒ½ç»™è½¦è¾† 3 â†’ é›ªå´©
Top-3 Random: åœ¨å‰ 3 åä¸­éšæœº â†’ è´Ÿè½½åˆ†æ•£
```

---

### æ ¸å¿ƒæ´å¯Ÿ

1. **ä¸æ˜¯æ‰€æœ‰è¯·æ±‚éƒ½å¹³ç­‰**: 
   - çŸ­è¯·æ±‚èµ°"å¿«é€Ÿé€šé“"(ä½è´Ÿè½½ Pod)
   - é•¿è¯·æ±‚èµ°"æ‰¹å¤„ç†ä¸“çº¿"(é«˜åå Pod)

2. **å†å²çŠ¶æ€å¯å¤ç”¨**:
   - ç›¸åŒ Prefix è·¯ç”±åˆ°åŒä¸€ Pod â†’ ç¼“å­˜å‘½ä¸­ â†’ TTFT -90%

3. **åŠ¨æ€è°ƒæ•´ç­–ç•¥**:
   - é«˜ Prefix å¤ç”¨åœºæ™¯: `prefix-aware` æƒé‡ 100
   - ä½ Prefix å¤ç”¨åœºæ™¯: `load-aware` æƒé‡ 100

---

ç°åœ¨ä½ å·²ç»å»ºç«‹äº†ç›´è§‚è®¤çŸ¥,ä¸‹ä¸€å±‚å°†æ­å¼€è°ƒåº¦ç®—æ³•çš„ç²¾ç¡®å®ç°ç»†èŠ‚

---

## ğŸŒ€ èºæ—‹ 2: æœºåˆ¶å±‚ - Filterâ†’Scoreâ†’Select ä¸‰é˜¶æ®µç®—æ³•

### æœ¬å±‚ç›®æ ‡
æŒæ¡è°ƒåº¦å™¨çš„ä¸‰é˜¶æ®µå†³ç­–æµç¨‹ã€æ ¸å¿ƒæ’ä»¶çš„æ•°å­¦åŸç†ã€ä¸ KV Cache Indexer çš„ååŒæœºåˆ¶ã€é…ç½®ç³»ç»Ÿçš„ YAML ç»“æ„ã€‚

---

### 2.1 å®Œæ•´è°ƒåº¦æµç¨‹æ—¶åºå›¾

```mermaid
sequenceDiagram
    participant C as å®¢æˆ·ç«¯
    participant GW as Gateway<br/>(Envoy)
    participant EPP as Endpoint Picker<br/>(è°ƒåº¦å™¨)
    participant IDX as KV Cache Indexer
    participant PROM as Prometheus
    participant P1 as Pod 1
    participant P2 as Pod 2
    participant P3 as Pod 3
    
    C->>GW: 1. POST /v1/chat/completions<br/>{prompt, max_tokens}
    GW->>EPP: 2. ext-proc è°ƒç”¨<br/>Header: x-prompt-hash, x-model-id
    
    Note over EPP: é˜¶æ®µ 0: å‘ç°å€™é€‰ Pod
    EPP->>PROM: 3. æŸ¥è¯¢ InferencePool
    PROM-->>EPP: Pods: [P1, P2, P3]
    
    Note over EPP: é˜¶æ®µ 1: Filter (è¿‡æ»¤)
    EPP->>EPP: 4a. Queue Depth Filter
    EPP->>EPP: 4b. Memory Pressure Filter
    EPP->>EPP: 4c. Model Compatibility Filter
    EPP->>EPP: ç»“æœ: æ’é™¤ P3 (é˜Ÿåˆ—æ»¡)
    
    Note over EPP: é˜¶æ®µ 2: Score (è¯„åˆ†)
    EPP->>IDX: 5a. æŸ¥è¯¢ç¼“å­˜å‘½ä¸­ç‡<br/>Hash(prompt)
    IDX-->>EPP: P1:10%, P2:90%
    
    EPP->>PROM: 5b. æŸ¥è¯¢ queue_depth
    PROM-->>EPP: P1:20, P2:5
    
    EPP->>EPP: 6. è®¡ç®—ç»¼åˆå¾—åˆ†<br/>P1: 10*100 + (1-20/50)*50 = 130<br/>P2: 90*100 + (1-5/50)*50 = 945
    
    Note over EPP: é˜¶æ®µ 3: Select (é€‰æ‹©)
    EPP->>EPP: 7. Top-K é€‰æ‹© (K=3)<br/>éšæœºæ‰“æ•£
    
    EPP-->>GW: 8. è¿”å› Pod 2 åœ°å€
    GW->>P2: 9. è½¬å‘è¯·æ±‚
    P2-->>C: 10. æµå¼è¿”å› Token
```

**å…³é”®æ—¶é—´èŠ‚ç‚¹**:
- æ­¥éª¤ 2-8: è°ƒåº¦å†³ç­–è€—æ—¶ **<10ms** (ä¸é˜»å¡æ¨ç†)
- æ­¥éª¤ 5a: ç¼“å­˜ç´¢å¼•æŸ¥è¯¢ **<1ms** (å†…å­˜å“ˆå¸Œè¡¨)
- æ­¥éª¤ 5b: Prometheus æŸ¥è¯¢ **<5ms** (æŒ‡æ ‡ç¼“å­˜)

---

### 2.2 é˜¶æ®µ 1: Filter æ’ä»¶æ¶æ„

#### Filter æ¥å£å®šä¹‰

```go
// pkg/plugins/filter/interface.go
package filter

import "sigs.k8s.io/gateway-api-inference-extension/pkg/epp/scheduling/types"

type Filter interface {
    // Name è¿”å›æ’ä»¶åç§°
    Name() string
    
    // Filter è¿‡æ»¤ä¸å¯ç”¨ Pod
    // è¿”å›å€¼: é€šè¿‡è¿‡æ»¤çš„ Pod åˆ—è¡¨
    Filter(ctx *types.SchedulingContext, pods []types.Pod) []types.Pod
}
```

---

#### æ ¸å¿ƒ Filter å®ç°

**Filter 1: Queue Depth Filter (é˜Ÿåˆ—æ·±åº¦è¿‡æ»¤)**

```go
// ä¼ªä»£ç 
type QueueDepthFilter struct {
    name          string
    maxQueueLength int  // é»˜è®¤ 50
}

func (f *QueueDepthFilter) Filter(ctx *types.SchedulingContext, pods []types.Pod) []types.Pod {
    filtered := []types.Pod{}
    
    for _, pod := range pods {
        // ä» Prometheus æŸ¥è¯¢é˜Ÿåˆ—æ·±åº¦
        queueDepth := getQueueDepth(pod.Name)
        
        if queueDepth < f.maxQueueLength {
            filtered = append(filtered, pod)
        } else {
            log.Debug("Pod %s filtered: queue_depth=%d > max=%d", 
                pod.Name, queueDepth, f.maxQueueLength)
        }
    }
    
    return filtered
}
```

**é…ç½®ç¤ºä¾‹**:
```yaml
plugins:
  - type: queue-depth-filter
    parameters:
      maxQueueLength: 50  # é˜Ÿåˆ—è¶… 50 åˆ™è¿‡æ»¤
```

---

**Filter 2: ByLabel Filter (æ ‡ç­¾é€‰æ‹©å™¨)**

```go
// pkg/plugins/filter/by_label.go
type ByLabel struct {
    name          string
    label         string     // æ ‡ç­¾é”®
    validValues   []string   // å…è®¸çš„å€¼åˆ—è¡¨
    allowsNoLabel bool       // æ˜¯å¦å…è®¸æ— æ ‡ç­¾ Pod
}

func (f *ByLabel) Filter(ctx *types.SchedulingContext, pods []types.Pod) []types.Pod {
    filtered := []types.Pod{}
    
    for _, pod := range pods {
        podLabels := pod.GetPod().Labels
        labelValue, exists := podLabels[f.label]
        
        // å¤„ç†æ— æ ‡ç­¾æƒ…å†µ
        if !exists {
            if f.allowsNoLabel {
                filtered = append(filtered, pod)
            }
            continue
        }
        
        // æ£€æŸ¥å€¼æ˜¯å¦åœ¨å…è®¸åˆ—è¡¨ä¸­
        if contains(f.validValues, labelValue) {
            filtered = append(filtered, pod)
        }
    }
    
    return filtered
}
```

**é…ç½®ç¤ºä¾‹** (P/D åˆ†ç¦»åœºæ™¯):
```yaml
plugins:
  # Decode Filter
  - type: by-label
    name: decode-filter
    parameters:
      label: "llm-d.ai/role"
      validValues: ["decode", "both"]
      allowsNoLabel: false
  
  # Prefill Filter  
  - type: by-label
    name: prefill-filter
    parameters:
      label: "llm-d.ai/role"
      validValues: ["prefill"]
      allowsNoLabel: false
```

---

#### Filter é“¾å¼æ‰§è¡Œ

```mermaid
flowchart TD
    Start[å€™é€‰ Pod åˆ—è¡¨<br/>P1, P2, P3, P4] --> F1[Filter 1:<br/>Queue Depth]
    F1 -->|æ’é™¤ P3| F2[Filter 2:<br/>Memory Pressure]
    F2 -->|æ’é™¤ P4| F3[Filter 3:<br/>Model Compatibility]
    F3 --> End[å¯ç”¨ Pod<br/>P1, P2]
    
    style Start fill:#e8f5e9
    style End fill:#e8f5e9
    style F1 fill:#fff9c4
    style F2 fill:#fff9c4
    style F3 fill:#fff9c4
```

---

### 2.3 é˜¶æ®µ 2: Scorer æ’ä»¶æ¶æ„

#### Scorer æ¥å£å®šä¹‰

```go
// pkg/plugins/scorer/interface.go
package scorer

type Scorer interface {
    Name() string
    
    // Score ä¸º Pod è®¡ç®—å¾—åˆ† (0-1 èŒƒå›´)
    // æœ€ç»ˆå¾—åˆ† = score * weight
    Score(ctx *types.SchedulingContext, pod types.Pod) float64
}
```

---

#### Scorer 1: Precise Prefix Cache Scorer

**æ ¸å¿ƒç®—æ³•**: Hash Block åŒ¹é…

```python
# ä¼ªä»£ç 
def prefix_cache_score(pod, request):
    # 1. å°† Prompt åˆ†å—å¹¶è®¡ç®— Hash
    prompt_tokens = tokenize(request.prompt)
    hash_blocks = []
    
    for i in range(0, len(prompt_tokens), HASH_BLOCK_SIZE):
        block = prompt_tokens[i:i+HASH_BLOCK_SIZE]
        hash_val = hash(block, seed=HASH_SEED)
        hash_blocks.append(hash_val)
    
    # 2. æŸ¥è¯¢ KV Cache Indexer
    matched_blocks = 0
    for hash_val in hash_blocks:
        if kv_indexer.has_block(pod.id, hash_val):
            matched_blocks += 1
    
    # 3. è®¡ç®—å‘½ä¸­ç‡ (0-1)
    hit_rate = matched_blocks / len(hash_blocks)
    return hit_rate
```

**é…ç½®å‚æ•°**:

| å‚æ•° | é»˜è®¤å€¼ | è°ƒä¼˜å»ºè®® |
|------|--------|---------|
| `blockSize` | 64 | **å¿…é¡»**ä¸ vLLM `--block-size` ä¸€è‡´ |
| `hashSeed` | "12345" | **å¿…é¡»**ä¸ vLLM `PYTHONHASHSEED` ä¸€è‡´ |
| `maxPrefixBlocksToMatch` | 256 | é™åˆ¶ç´¢å¼•æŸ¥è¯¢æ¬¡æ•°,é¿å…é•¿ Prompt æ‹–æ…¢è°ƒåº¦ |

**é…ç½®ç¤ºä¾‹**:
```yaml
plugins:
  - type: precise-prefix-cache-scorer
    parameters:
      tokenProcessorConfig:
        blockSize: 64
        hashSeed: "12345"
      indexerConfig:
        kvBlockIndexConfig:
          enableMetrics: true
        tokenizersPoolConfig:
          modelName: "Qwen/Qwen3-32B"
          hf:
            huggingFaceToken: "${HF_TOKEN}"  # è‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡
```

---

#### Scorer 2: Load-Aware Scorer

**æ ¸å¿ƒç®—æ³•**: é˜Ÿåˆ—æ·±åº¦å€’æ•°

```python
def load_aware_score(pod):
    queue_depth = get_queue_depth(pod)
    max_queue = 50  # å®¹é‡ä¸Šé™
    
    # è´Ÿè½½å› å­: é˜Ÿåˆ—è¶Šç©ºå¾—åˆ†è¶Šé«˜
    load_factor = 1 - (queue_depth / max_queue)
    return load_factor  # è¿”å› 0-1
```

**è¯„åˆ†æ›²çº¿**:

```mermaid
%%{init: {'theme':'base', 'themeVariables': {'xyChart': {'backgroundColor': 'transparent'}}}}%%
xychart-beta
    title "Load-Aware Scorer è¯„åˆ†æ›²çº¿"
    x-axis "é˜Ÿåˆ—æ·±åº¦" [0, 10, 20, 30, 40, 50]
    y-axis "å¾—åˆ†" 0 --> 1
    line [1.0, 0.8, 0.6, 0.4, 0.2, 0.0]
```

**é…ç½®ç¤ºä¾‹**:
```yaml
plugins:
  - type: load-aware-scorer
    parameters:
      threshold: 50  # é˜Ÿåˆ—æ·±åº¦é˜ˆå€¼
```

---

#### Scorer 3: NoHit LRU Scorer (å†·è¯·æ±‚è´Ÿè½½å‡è¡¡)

**æ ¸å¿ƒæ€æƒ³**: ä¸ºæ²¡æœ‰ç¼“å­˜å‘½ä¸­çš„è¯·æ±‚åˆ†æ•£è´Ÿè½½,é¿å…æ–°è¯·æ±‚é›†ä¸­åˆ›å»º KV Block å¯¼è‡´å• Pod å†…å­˜å‹åŠ›

```python
def no_hit_lru_score(pod, request):
    # 1. æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜å‘½ä¸­
    if has_cache_hit(pod, request):
        return 0.5  # ä¸­æ€§å¾—åˆ†,ä¸å½±å“ç¼“å­˜æ„ŸçŸ¥è·¯ç”±
    
    # 2. å†·è¯·æ±‚: æŸ¥è¯¢ LRU ç¼“å­˜
    last_used_time = lru_cache.get(pod.id)
    
    if last_used_time is None:
        # ä»æœªæœåŠ¡è¿‡å†·è¯·æ±‚ â†’ æœ€é«˜åˆ†
        return 1.0
    
    # 3. æ ¹æ®æœ€åä½¿ç”¨æ—¶é—´è®¡ç®—å¾—åˆ†
    time_since_last_use = now() - last_used_time
    score = normalize(time_since_last_use, max=3600)  # 1å°æ—¶å½’ä¸€åŒ–
    
    return score  # è¶Šä¹…æœªç”¨å¾—åˆ†è¶Šé«˜
```

**é…ç½®ç¤ºä¾‹**:
```yaml
plugins:
  - type: no-hit-lru-scorer
    parameters:
      prefixPluginName: "precise-prefix-cache-scorer"  # ä¾èµ–ç¼“å­˜è¯„åˆ†æ’ä»¶
      lruSize: 2048  # LRU ç¼“å­˜å¤§å°
```

---

#### å¤š Scorer åŠ æƒæ±‚å’Œ

```python
# æœ€ç»ˆå¾—åˆ†è®¡ç®—
def calculate_final_score(pod, request, scorers):
    total_score = 0
    
    for scorer, weight in scorers:
        base_score = scorer.score(pod, request)  # 0-1
        weighted_score = base_score * weight
        total_score += weighted_score
    
    return total_score

# é…ç½®ç¤ºä¾‹
scorers = [
    (PrefixCacheScorer(), weight=100),
    (LoadAwareScorer(), weight=50),
    (NoHitLRUScorer(), weight=30)
]

# Pod A å¾—åˆ†è®¡ç®—
score_A = (0.9 * 100) + (0.6 * 50) + (0.2 * 30) = 90 + 30 + 6 = 126
# Pod B å¾—åˆ†è®¡ç®—
score_B = (0.1 * 100) + (0.9 * 50) + (0.8 * 30) = 10 + 45 + 24 = 79
# â†’ é€‰æ‹© Pod A
```

---

### 2.4 é˜¶æ®µ 3: Picker é€‰æ‹©ç­–ç•¥

#### Top-K éšæœºé€‰æ‹©

```python
def select_pod(scored_pods, K=3):
    # 1. æŒ‰å¾—åˆ†æ’åº
    sorted_pods = sort(scored_pods, by="score", descending=True)
    
    # 2. Top-K é€‰æ‹©
    candidates = sorted_pods[:K]
    
    # 3. éšæœºæ‰“æ•£
    selected = random.choice(candidates)
    
    return selected
```

**ä¸ºä»€ä¹ˆä¸æ€»æ˜¯é€‰ç¬¬ä¸€å?**

| ç­–ç•¥ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|---------|
| **Always Top-1** | ç†è®ºæœ€ä¼˜ | å•ç‚¹è¿‡è½½ (é›ªå´©) | ä½å¹¶å‘ (<10 QPS) |
| **Top-K Random** | è´Ÿè½½åˆ†æ•£ | è½»å¾®æ¬¡ä¼˜ (~5%) | é«˜å¹¶å‘ (>20 QPS) |

**å®æµ‹å¯¹æ¯”** (20 QPS å¹¶å‘):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç­–ç•¥       â”‚ P95 TTFTâ”‚ P99 TTFTâ”‚ æ ‡å‡†å·®   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Always Top-1 â”‚ 200ms   â”‚ 3.5s    â”‚ 850ms    â”‚
â”‚ Top-3 Random â”‚ 220ms   â”‚ 450ms   â”‚ 120ms    â”‚ â† ç¨³å®šæ€§æ›´å¥½
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2.5 é…ç½®ç³»ç»Ÿæ¶æ„

#### YAML é…ç½®ç»“æ„

```yaml
apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: EndpointPickerConfig

# 1. æ’ä»¶å®ä¾‹åŒ–
plugins:
  - name: my-filter         # å¯é€‰,é»˜è®¤ä¸º type
    type: by-label          # æ’ä»¶ç±»å‹
    parameters:             # æ’ä»¶å‚æ•°
      label: "role"
      validValues: ["decode"]
  
  - type: precise-prefix-cache-scorer
    parameters:
      tokenProcessorConfig:
        blockSize: 64
      indexerConfig:
        tokenizersPoolConfig:
          modelName: "Qwen/Qwen3-32B"

# 2. è°ƒåº¦é…ç½®æ–‡ä»¶ (SchedulingProfile)
schedulingProfiles:
  - name: default           # Profile åç§°
    plugins:
      - pluginRef: my-filter          # å¼•ç”¨æ’ä»¶å®ä¾‹
      - pluginRef: precise-prefix-cache-scorer
        weight: 100                   # Scorer æƒé‡
```

---

#### P/D åˆ†ç¦»é…ç½®ç¤ºä¾‹

```yaml
apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: EndpointPickerConfig

plugins:
  # Profile Handler (å†³å®šä½¿ç”¨å“ªä¸ª Profile)
  - type: pd-profile-handler
    parameters:
      threshold: 10              # æ–°å¢ Token æ•°é˜ˆå€¼
      hashBlockSize: 5
      decodeProfile: "decode"    # Decode Profile åç§°
      prefillProfile: "prefill"  # Prefill Profile åç§°
  
  # Prefill Header (è®¾ç½® P/D åˆ†ç¦»æ ‡è®°)
  - type: prefill-header-handler
    parameters:
      prefillProfile: "prefill"
  
  # Cache Scorer (å…±äº«)
  - type: precise-prefix-cache-scorer
    parameters:
      tokenProcessorConfig:
        blockSize: 5
  
  # Filters
  - type: by-label
    name: prefill-filter
    parameters:
      label: "llm-d.ai/role"
      validValues: ["prefill"]
  
  - type: by-label
    name: decode-filter
    parameters:
      label: "llm-d.ai/role"
      validValues: ["decode", "both"]
      allowsNoLabel: true  # å…¼å®¹æ— æ ‡ç­¾ Pod
  
  # Picker
  - type: max-score-picker

# ä¸¤ä¸ª Profile
schedulingProfiles:
  - name: prefill
    plugins:
      - pluginRef: prefill-filter
      - pluginRef: precise-prefix-cache-scorer
        weight: 100
      - pluginRef: max-score-picker
  
  - name: decode
    plugins:
      - pluginRef: decode-filter
      - pluginRef: precise-prefix-cache-scorer
        weight: 100
      - pluginRef: max-score-picker
```

---

### 2.6 ä¸ KV Cache Indexer çš„ååŒ

#### KVEvents äº‹ä»¶æµ

```mermaid
sequenceDiagram
    participant V as vLLM Pod
    participant Z as ZeroMQ<br/>(äº‹ä»¶æµ)
    participant IDX as KV Cache Indexer
    participant EPP as Endpoint Picker
    
    V->>V: 1. Prefill è®¡ç®—å®Œæˆ<br/>ç”Ÿæˆ KV Block 0-10
    V->>Z: 2. å‘å¸ƒ KVEvent<br/>{type: "block_created", blocks: [0-10]}
    Z->>IDX: 3. è®¢é˜…è€…æ¥æ”¶äº‹ä»¶
    IDX->>IDX: 4. æ›´æ–°å†…å­˜ç´¢å¼•<br/>Hash â†’ Pod æ˜ å°„
    
    Note over EPP: ä¸‹ä¸€æ¬¡è°ƒåº¦æ—¶
    EPP->>IDX: 5. æŸ¥è¯¢ç¼“å­˜<br/>Hash(prompt)
    IDX-->>EPP: 6. è¿”å›å‘½ä¸­ç‡<br/>Pod A:90%, Pod B:10%
```

**äº‹ä»¶ç±»å‹**:

| äº‹ä»¶ | è§¦å‘æ—¶æœº | ç´¢å¼•æ“ä½œ |
|------|---------|---------|
| `block_created` | Prefill å®Œæˆ | æ·»åŠ  Hash â†’ Pod æ˜ å°„ |
| `block_evicted` | KV Cache é©±é€ | åˆ é™¤æ˜ å°„ |
| `block_offloaded` | å¸è½½åˆ° CPU/FS | æ ‡è®°ä¸º"å¯æ¢å¤" |

---

### âœ… èºæ—‹ 2 éªŒæ”¶æ ‡å‡†

å®Œæˆæœ¬å±‚å­¦ä¹ å,ä½ åº”è¯¥èƒ½å¤Ÿ:

- [ ] ç”»å‡ºè°ƒåº¦æµç¨‹çš„å®Œæ•´æ—¶åºå›¾ (10 æ­¥)
- [ ] å®ç°ä¸€ä¸ªç®€å•çš„ Filter æ’ä»¶ (Go ä¼ªä»£ç )
- [ ] è®¡ç®— Prefix-aware Scorer çš„è¯„åˆ†: `matched_blocks / total_blocks`
- [ ] è§£é‡Š Top-K é€‰æ‹©ç›¸æ¯” Always Top-1 çš„ä¼˜åŠ¿
- [ ] ç¼–å†™ P/D åˆ†ç¦»çš„ EndpointPickerConfig YAML

---

### ğŸ”— ä¸‹ä¸€æ­¥

æŒæ¡äº†åº•å±‚æœºåˆ¶å,ä¸‹ä¸€å±‚æˆ‘ä»¬å°†è¿›å…¥ **ç”Ÿäº§ç¯å¢ƒé…ç½®è°ƒä¼˜** ä¸ **æ•…éšœæ’æŸ¥å®æˆ˜**

---

## ğŸŒ€ èºæ—‹ 3: å®æˆ˜å±‚ - æ’ä»¶é…ç½®ä¸æ•…éšœæ’æŸ¥

### æœ¬å±‚ç›®æ ‡
æŒæ¡ Inference Scheduler çš„ç”Ÿäº§çº§é…ç½®ã€æ ¸å¿ƒå‚æ•°è°ƒä¼˜ç­–ç•¥ã€ç›‘æ§æŒ‡æ ‡ä½“ç³»ä¸å…¸å‹æ•…éšœæ’æŸ¥å†³ç­–æ ‘ã€‚

---

### 3.1 éƒ¨ç½²æ¶æ„ä¸é«˜å¯ç”¨

#### åŸºç¡€éƒ¨ç½²æ‹“æ‰‘

```mermaid
flowchart TB
    subgraph Gateway [Gateway å±‚]
        GW1[Envoy Gateway<br/>Pod 1]
        GW2[Envoy Gateway<br/>Pod 2]
    end
    
    subgraph EPP [EPP å±‚ - é«˜å¯ç”¨]
        EPP1[Scheduler<br/>Pod 1]
        EPP2[Scheduler<br/>Pod 2]
    end
    
    subgraph Data [æ•°æ®å¹³é¢]
        IDX[(KV Cache<br/>Indexer)]
        PROM[(Prometheus)]
    end
    
    subgraph Backend [vLLM Pods]
        V1[vLLM 1]
        V2[vLLM 2]
        V3[vLLM 3]
    end
    
    GW1 & GW2 <-->|ext-proc gRPC| EPP1 & EPP2
    EPP1 & EPP2 -->|æŸ¥è¯¢| IDX
    EPP1 & EPP2 -->|æŸ¥è¯¢| PROM
    GW1 & GW2 -->|HTTP/2| V1 & V2 & V3
    
    style Gateway fill:#e1f5fe
    style EPP fill:#fff9c4
    style Data fill:#f3e5f5
    style Backend fill:#e8f5e9
```

**é«˜å¯ç”¨é…ç½®**:

```yaml
# EPP Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-scheduler
spec:
  replicas: 2  # è‡³å°‘ 2 å‰¯æœ¬
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1  # ä¿è¯è‡³å°‘ 1 å‰¯æœ¬å¯ç”¨
  
  template:
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: inference-scheduler
              topologyKey: kubernetes.io/hostname  # ä¸åŒèŠ‚ç‚¹
      
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1000m
          memory: 1Gi
```

---

### 3.2 æ ¸å¿ƒå‚æ•°è°ƒä¼˜çŸ©é˜µ

#### å‚æ•° 1: hashBlockSize (Hash å—å¤§å°)

**å½±å“**: ç¼“å­˜åŒ¹é…çš„ç²’åº¦

| hashBlockSize | é€‚ç”¨åœºæ™¯ | ç¼“å­˜å‘½ä¸­ç‡ | è®¡ç®—å¼€é”€ | æ¨èå€¼ |
|--------------|---------|-----------|---------|-------|
| 3 | çŸ­ Prompt (<500 tokens) | ä½ (ç»†ç²’åº¦) | ä½ | RAG é—®ç­” |
| 5 | ä¸­ç­‰ Prompt (500-2k) | ä¸­ | ä¸­ | **é»˜è®¤æ¨è** |
| 10 | é•¿ Prompt (2k-8k) | é«˜ (ç²—ç²’åº¦) | é«˜ | é•¿ä¸Šä¸‹æ–‡å¯¹è¯ |
| 20 | è¶…é•¿ Prompt (>8k) | å¾ˆé«˜ | å¾ˆé«˜ | æ–‡æ¡£åˆ†æ |

**è°ƒä¼˜å…¬å¼**:

```python
# ç»éªŒå…¬å¼
optimal_block_size = max(3, min(20, avg_prompt_len / 200))

# ç¤ºä¾‹
# RAG åœºæ™¯ (ç³»ç»Ÿæç¤ºè¯ 6k + ç”¨æˆ·é—®é¢˜ 500)
optimal = (6000 + 500) / 200 = 32.5 â†’ å– 20

# çŸ­å¯¹è¯åœºæ™¯ (å¹³å‡ 200 tokens)
optimal = 200 / 200 = 1 â†’ å– 3 (æœ€å°å€¼)
```

**å®æµ‹å¯¹æ¯”** (6k ç³»ç»Ÿæç¤ºè¯åœºæ™¯):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ blockSize â”‚ ç¼“å­˜å‘½ä¸­ç‡ â”‚ TTFT P95 â”‚ è°ƒåº¦è€—æ—¶ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3         â”‚ 45%        â”‚ 850ms    â”‚ 3ms      â”‚
â”‚ 5         â”‚ 72%        â”‚ 280ms    â”‚ 5ms      â”‚
â”‚ 10        â”‚ 89%        â”‚ 157ms    â”‚ 8ms      â”‚ â† æ¨è
â”‚ 20        â”‚ 91%        â”‚ 145ms    â”‚ 15ms     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### å‚æ•° 2: Scorer Weight (è¯„åˆ†æƒé‡)

**åœºæ™¯çŸ©é˜µ**:

| Prefix å¤ç”¨ç‡ | prefix-aware æƒé‡ | load-aware æƒé‡ | é€‚ç”¨å·¥ä½œè´Ÿè½½ |
|-------------|------------------|----------------|-------------|
| **>70%** | 100 | 30 | å¤šè½®å¯¹è¯ã€Agent |
| **50-70%** | 70 | 60 | æ··åˆå·¥ä½œè´Ÿè½½ |
| **30-50%** | 50 | 80 | RAG (åŠ¨æ€æ£€ç´¢) |
| **<30%** | 0 | 100 | æ‰¹å¤„ç†æ¨ç† |

**åŠ¨æ€è°ƒæ•´ç­–ç•¥**:

```python
# æ ¹æ®å®é™…ç¼“å­˜å‘½ä¸­ç‡åŠ¨æ€è°ƒæ•´
def adjust_weights(cache_hit_rate):
    if cache_hit_rate > 0.7:
        # é«˜å‘½ä¸­ç‡ â†’ å¼ºåŒ–ç¼“å­˜æ„ŸçŸ¥
        return {"prefix": 100, "load": 30}
    elif cache_hit_rate < 0.3:
        # ä½å‘½ä¸­ç‡ â†’ å¼±åŒ–ç¼“å­˜æ„ŸçŸ¥
        return {"prefix": 0, "load": 100}
    else:
        # ä¸­ç­‰å‘½ä¸­ç‡ â†’ å¹³è¡¡
        return {"prefix": 60, "load": 60}
```

**é…ç½®ç¤ºä¾‹**:

```yaml
# é«˜ Prefix å¤ç”¨åœºæ™¯
schedulingProfiles:
  - name: default
    plugins:
      - pluginRef: precise-prefix-cache-scorer
        weight: 100
      - pluginRef: load-aware-scorer
        weight: 30

# ä½ Prefix å¤ç”¨åœºæ™¯
schedulingProfiles:
  - name: default
    plugins:
      - pluginRef: load-aware-scorer
        weight: 100
      # ä¸å¯ç”¨ prefix-cache-scorer
```

---

#### å‚æ•° 3: maxQueueLength (é˜Ÿåˆ—æ·±åº¦é˜ˆå€¼)

**å…³ç³»**: åº”ä¸ vLLM çš„ `max_num_seqs` å¯¹é½

```yaml
# vLLM Deployment
env:
  - name: VLLM_MAX_NUM_SEQS
    value: "256"  # æœ€å¤§å¹¶å‘åºåˆ—æ•°

# Inference Scheduler
plugins:
  - type: queue-depth-filter
    parameters:
      maxQueueLength: 200  # è®¾ä¸º max_num_seqs çš„ 80%
```

**è°ƒä¼˜é€»è¾‘**:

```mermaid
flowchart TD
    Start[é˜Ÿåˆ—æ·±åº¦ç›‘æ§] --> Q1{å¹³å‡é˜Ÿåˆ— > 80%?}
    Q1 -->|æ˜¯| A1[é€‰é¡¹ 1: é™ä½ maxQueueLength<br/>å¼ºåˆ¶æµé‡åˆ†æ•£]
    Q1 -->|å¦| Q2{TTFT æŠ–åŠ¨å¤§?}
    
    Q2 -->|æ˜¯| A2[é€‰é¡¹ 2: æé«˜ maxQueueLength<br/>å…è®¸æ‰¹å¤„ç†]
    Q2 -->|å¦| OK[ä¿æŒå½“å‰é…ç½®]
    
    A1 --> V1[éªŒè¯: TTFT P95 ä¸‹é™?]
    A2 --> V2[éªŒè¯: ååæå‡?]
    
    style A1 fill:#fff9c4
    style A2 fill:#fff9c4
    style OK fill:#e8f5e9
```

---

### 3.3 ç›‘æ§æŒ‡æ ‡ä½“ç³»

#### å››å±‚ç›‘æ§é‡‘å­—å¡”

```mermaid
flowchart TB
    subgraph L1 [L1: ä¸šåŠ¡æŒ‡æ ‡ - SLI/SLO]
        B1[TTFT P95 < 200ms]
        B2[åå > 10k tok/s]
        B3[æˆåŠŸç‡ > 99.9%]
    end
    
    subgraph L2 [L2: åº”ç”¨æŒ‡æ ‡ - Scheduler]
        A1[ç¼“å­˜å‘½ä¸­ç‡]
        A2[è°ƒåº¦å»¶è¿Ÿ]
        A3[Filter è¿‡æ»¤ç‡]
    end
    
    subgraph L3 [L3: èµ„æºæŒ‡æ ‡ - vLLM]
        R1[é˜Ÿåˆ—æ·±åº¦]
        R2[KV åˆ©ç”¨ç‡]
        R3[æ´»è·ƒè¯·æ±‚æ•°]
    end
    
    subgraph L4 [L4: åŸºç¡€è®¾æ–½ - K8s]
        I1[Pod å¥åº·çŠ¶æ€]
        I2[EPP å‰¯æœ¬å¯ç”¨]
    end
    
    B1 --> A1 & A2
    B2 --> R1
    A1 --> R2
    A2 --> I2
    
    style L1 fill:#e1f5fe
    style L2 fill:#fff9c4
    style L3 fill:#fff3e0
    style L4 fill:#f3e5f5
```

---

#### æ ¸å¿ƒ Prometheus æŒ‡æ ‡

```yaml
# 1. Scheduler è°ƒåº¦æŒ‡æ ‡
- metric: epp_scheduling_duration_seconds
  type: histogram
  labels: [profile_name, scheduler_pod]
  
- metric: kv_cache_hit_total
  type: counter
  labels: [pod_name]
  
- metric: kv_cache_lookup_total
  type: counter
  labels: [pod_name]

# 2. vLLM æ¨ç†æŒ‡æ ‡
- metric: vllm_time_to_first_token_seconds
  type: histogram
  labels: [model_name, pod_name]
  
- metric: vllm_queue_depth
  type: gauge
  labels: [pod_name]
  
- metric: vllm_kv_cache_utilization
  type: gauge
  labels: [pod_name]

# 3. EPP å¥åº·æŒ‡æ ‡
- metric: epp_plugin_errors_total
  type: counter
  labels: [plugin_name, error_type]
```

---

#### å…³é”®å‘Šè­¦è§„åˆ™

```yaml
groups:
  - name: inference-scheduler-slo
    rules:
      # å‘Šè­¦ 1: TTFT è¶… SLO
      - alert: HighTTFT
        expr: |
          histogram_quantile(0.95, 
            rate(vllm_time_to_first_token_seconds_bucket[5m])
          ) > 0.2
        for: 5m
        severity: critical
        annotations:
          summary: "TTFT P95 è¶…è¿‡ 200ms SLO"
          runbook: "æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡ã€é˜Ÿåˆ—æ·±åº¦"
      
      # å‘Šè­¦ 2: ç¼“å­˜å‘½ä¸­ç‡ä½
      - alert: LowCacheHitRate
        expr: |
          rate(kv_cache_hit_total[10m]) / 
          rate(kv_cache_lookup_total[10m]) < 0.3
        for: 10m
        severity: warning
        annotations:
          summary: "ç¼“å­˜å‘½ä¸­ç‡ä½äº 30%"
          action: "æ£€æŸ¥ hashBlockSize æˆ–å·¥ä½œè´Ÿè½½å˜åŒ–"
      
      # å‘Šè­¦ 3: è°ƒåº¦å»¶è¿Ÿé«˜
      - alert: EPPHighLatency
        expr: |
          histogram_quantile(0.95,
            rate(epp_scheduling_duration_seconds_bucket[5m])
          ) > 0.05
        for: 5m
        severity: warning
        annotations:
          summary: "è°ƒåº¦å™¨ P95 å»¶è¿Ÿè¶… 50ms"
          action: "æ£€æŸ¥ KV Indexer è¿æ¥æˆ–å¢åŠ  EPP å‰¯æœ¬"
      
      # å‘Šè­¦ 4: EPP ä¸å¯ç”¨
      - alert: EPPPodDown
        expr: up{job="inference-scheduler"} == 0
        for: 1m
        severity: critical
        annotations:
          summary: "Inference Scheduler Pod ä¸å¯ç”¨"
```

---

### 3.4 å…¸å‹æ•…éšœæ’æŸ¥å†³ç­–æ ‘

#### é—®é¢˜ 1: ç¼“å­˜å‘½ä¸­ç‡ä½ (<30%)

```mermaid
flowchart TD
    Start[ç¼“å­˜å‘½ä¸­ç‡ < 30%] --> Q1{å·¥ä½œè´Ÿè½½æ˜¯å¦å˜åŒ–?}
    Q1 -->|æ˜¯| Fix1[é¢„æœŸè¡Œä¸º:<br/>æ–°ç”¨æˆ·/æ–°è¯é¢˜æ­£å¸¸]
    Q1 -->|å¦| Q2{hashBlockSize åˆé€‚?}
    
    Q2 -->|è¿‡å°| Fix2[å¢å¤§ hashBlockSize<br/>5 â†’ 10]
    Q2 -->|è¿‡å¤§| Fix3[å‡å° hashBlockSize<br/>10 â†’ 5]
    Q2 -->|åˆé€‚| Q3{KV Indexer æ­£å¸¸?}
    
    Q3 -->|å¼‚å¸¸| Fix4[æ£€æŸ¥ ZeroMQ è¿æ¥<br/>kubectl logs kv-indexer]
    Q3 -->|æ­£å¸¸| Fix5[æ£€æŸ¥ vLLM KVEvents<br/>æ˜¯å¦å¯ç”¨ PREFIX_CACHING]
    
    style Fix1 fill:#e8f5e9
    style Fix2 fill:#fff9c4
    style Fix3 fill:#fff9c4
    style Fix4 fill:#ffebee
    style Fix5 fill:#ffebee
```

**è°ƒè¯•å‘½ä»¤**:

```bash
# 1. æ£€æŸ¥ KV Indexer è¿æ¥
kubectl exec -it epp-pod -- curl http://kv-cache-indexer:9090/metrics | grep index_size

# 2. æ£€æŸ¥ vLLM Prefix Caching çŠ¶æ€
kubectl exec -it vllm-pod -- curl localhost:8000/metrics | grep prefix_cache

# 3. æ‰‹åŠ¨éªŒè¯ç¼“å­˜æŸ¥è¯¢
curl -X POST http://kv-indexer:9090/query \
  -d '{"prompt_hash": [123, 456, 789], "pods": ["pod1", "pod2"]}'
  
# 4. æ£€æŸ¥ hashBlockSize æ˜¯å¦åŒ¹é…
kubectl get cm scheduler-config -o yaml | grep blockSize
kubectl exec vllm-pod -- env | grep VLLM_BLOCK_SIZE
```

---

#### é—®é¢˜ 2: è°ƒåº¦å»¶è¿Ÿçªå¢ (P95 >50ms)

| æ ¹å›  | æ’æŸ¥æ–¹æ³• | è§£å†³æ–¹æ¡ˆ |
|------|---------|---------|
| **KV Indexer æ…¢æŸ¥è¯¢** | `kubectl top pod kv-indexer` | å¢åŠ  Indexer å†…å­˜æˆ–ä¼˜åŒ–ç´¢å¼•ç»“æ„ |
| **Prometheus æŸ¥è¯¢è¶…æ—¶** | `curl -w "%{time_total}" prom-url` | å¢åŠ  Prometheus èµ„æºæˆ–å‡å°‘æŸ¥è¯¢é¢‘ç‡ |
| **EPP Pod èµ„æºä¸è¶³** | `kubectl top pod epp-pod` | å¢åŠ  CPU limits æˆ–æ°´å¹³æ‰©å±• |
| **ç½‘ç»œå»¶è¿Ÿ** | `kubectl exec epp -- ping vllm-pod` | æ£€æŸ¥ CNI é…ç½®æˆ–èŠ‚ç‚¹äº²å’Œæ€§ |

**è°ƒè¯•è„šæœ¬**:

```bash
#!/bin/bash
# è°ƒåº¦å»¶è¿Ÿè¯Šæ–­è„šæœ¬

echo "=== 1. EPP Pod èµ„æºä½¿ç”¨ ==="
kubectl top pod -l app=inference-scheduler

echo "=== 2. Prometheus æŸ¥è¯¢å»¶è¿Ÿ ==="
time curl -s http://prometheus:9090/api/v1/query \
  -d 'query=vllm_queue_depth' > /dev/null

echo "=== 3. KV Indexer å¥åº·æ£€æŸ¥ ==="
kubectl exec -it kv-indexer-pod -- curl localhost:9090/health

echo "=== 4. è°ƒåº¦è€—æ—¶åˆ†å¸ƒ ==="
kubectl exec -it epp-pod -- curl localhost:9091/metrics | \
  grep epp_scheduling_duration_seconds_bucket
```

---

#### é—®é¢˜ 3: è´Ÿè½½ä¸å‡ (æŸäº› Pod é˜Ÿåˆ— >100)

**ç—‡çŠ¶**:

```
Pod 1: queue_depth = 120
Pod 2: queue_depth = 5
Pod 3: queue_depth = 8
```

**æ ¹å› åˆ†æ**:

```python
# æ£€æŸ¥è¯„åˆ†é€»è¾‘
def debug_scoring(pods, request):
    for pod in pods:
        prefix_score = calculate_prefix_score(pod, request)
        load_score = calculate_load_score(pod)
        total = prefix_score * 100 + load_score * 50
        
        print(f"Pod {pod.id}:")
        print(f"  Prefix: {prefix_score} â†’ {prefix_score * 100}")
        print(f"  Load: {load_score} â†’ {load_score * 50}")
        print(f"  Total: {total}")
```

**å¸¸è§åŸå› **:

1. **ç¼“å­˜äº²å’Œæ€§è¿‡å¼º**: `prefix-aware` æƒé‡è¿‡é«˜

   ```yaml
   # è°ƒæ•´å‰
   scorers:
     - type: prefix-aware
       weight: 100
     - type: load-aware
       weight: 10  # æƒé‡å¤ªä½!
   
   # è°ƒæ•´å
   scorers:
     - type: prefix-aware
       weight: 70
     - type: load-aware
       weight: 50  # æé«˜æƒé‡
   ```

2. **Top-K æœªå¯ç”¨**: æ€»æ˜¯é€‰æ‹©ç¬¬ä¸€å

   ```yaml
   plugins:
     - type: max-score-picker
       parameters:
         topK: 3  # å¯ç”¨ Top-3 éšæœº
   ```

3. **æŸä¸ª Pod çœŸçš„æœ‰ç¼“å­˜ä¼˜åŠ¿**: é¢„æœŸè¡Œä¸º,è§¦å‘æ‰©å®¹

---

### 3.5 æ’ä»¶å¼€å‘æœ€ä½³å®è·µ

#### æ–°å¢ Filter æ’ä»¶æ¨¡æ¿

```go
// pkg/plugins/filter/my_filter.go
package filter

import (
    "sigs.k8s.io/gateway-api-inference-extension/pkg/epp/scheduling/plugins"
    "sigs.k8s.io/gateway-api-inference-extension/pkg/epp/scheduling/types"
)

// MyFilter ç¤ºä¾‹è¿‡æ»¤å™¨
type MyFilter struct {
    name      string
    threshold int  // è‡ªå®šä¹‰å‚æ•°
}

var _ plugins.Filter = &MyFilter{}  // æ¥å£æ–­è¨€

// NewMyFilter æ„é€ å‡½æ•°
func NewMyFilter(name string, threshold int) (plugins.Filter, error) {
    return &MyFilter{
        name:      name,
        threshold: threshold,
    }, nil
}

// Name è¿”å›æ’ä»¶åç§°
func (f *MyFilter) Name() string {
    return f.name
}

// Filter å®ç°è¿‡æ»¤é€»è¾‘
func (f *MyFilter) Filter(ctx *types.SchedulingContext, pods []types.Pod) []types.Pod {
    filtered := []types.Pod{}
    
    for _, pod := range pods {
        // è‡ªå®šä¹‰è¿‡æ»¤é€»è¾‘
        if meetsCriteria(pod, f.threshold) {
            filtered = append(filtered, pod)
        }
    }
    
    return filtered
}

func meetsCriteria(pod types.Pod, threshold int) bool {
    // å®ç°ä½ çš„åˆ¤æ–­é€»è¾‘
    return true
}
```

**æµ‹è¯•ç”¨ä¾‹**:

```go
// pkg/plugins/filter/my_filter_test.go
package filter

import (
    "testing"
    "sigs.k8s.io/gateway-api-inference-extension/pkg/epp/scheduling/types"
)

func TestMyFilter(t *testing.T) {
    filter, err := NewMyFilter("test-filter", 50)
    if err != nil {
        t.Fatalf("Failed to create filter: %v", err)
    }
    
    pods := []types.Pod{
        // æ„é€ æµ‹è¯• Pod
    }
    
    filtered := filter.Filter(nil, pods)
    
    if len(filtered) != expectedCount {
        t.Errorf("Expected %d pods, got %d", expectedCount, len(filtered))
    }
}
```

---

### âœ… èºæ—‹ 3 éªŒæ”¶æ ‡å‡†

å®Œæˆæœ¬å±‚å­¦ä¹ å,ä½ åº”è¯¥èƒ½å¤Ÿ:

- [ ] é…ç½® EPP é«˜å¯ç”¨éƒ¨ç½² (è‡³å°‘ 2 å‰¯æœ¬ + Pod åäº²å’Œæ€§)
- [ ] æ ¹æ®å·¥ä½œè´Ÿè½½ç‰¹å¾è°ƒä¼˜ `hashBlockSize` å’Œ Scorer æƒé‡
- [ ] å»ºç«‹å››å±‚ç›‘æ§æŒ‡æ ‡ä½“ç³»å¹¶è®¾ç½®å‘Šè­¦è§„åˆ™
- [ ] ä½¿ç”¨æ•…éšœå†³ç­–æ ‘è¯Šæ–­ç¼“å­˜å‘½ä¸­ç‡ä½ã€è°ƒåº¦å»¶è¿Ÿé«˜ã€è´Ÿè½½ä¸å‡ç­‰é—®é¢˜
- [ ] å®ç°ä¸€ä¸ªè‡ªå®šä¹‰ Filter æ’ä»¶ (å‚è€ƒæ¨¡æ¿)

---

### ğŸ“ æ€»ç»“

**llm-d Inference Scheduler çš„ç”Ÿäº§ä»·å€¼**:

1. **æ€§èƒ½**: 
   - é«˜ Prefix å¤ç”¨åœºæ™¯ TTFT -99%
   - ååæå‡ +109% (ç›¸æ¯” K8s Service)

2. **çµæ´»**: 
   - æ’ä»¶åŒ–æ¶æ„,æ— éœ€ä¿®æ”¹æ ¸å¿ƒä»£ç 
   - æ”¯æŒè‡ªå®šä¹‰ Filter/Scorer/Picker

3. **å¯è§‚æµ‹**: 
   - ä¸°å¯Œçš„ Prometheus æŒ‡æ ‡
   - å®Œæ•´çš„æ•…éšœæ’æŸ¥å†³ç­–æ ‘

4. **äº‘åŸç”Ÿ**: 
   - åŸºäº Gateway API æ ‡å‡†
   - ä¸ GIE ä¸Šä¸‹æ¸¸ç”Ÿæ€æ— ç¼é›†æˆ

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**:

- ğŸ“– æ·±å…¥é˜…è¯» [KV Cache Indexer](../kv-cache-indexer/) äº†è§£ç¼“å­˜ç´¢å¼•å®ç°
- ğŸ§ª éƒ¨ç½²æµ‹è¯•ç¯å¢ƒéªŒè¯é…ç½®å‚æ•°
- ğŸ“Š æ ¹æ®å®é™…å·¥ä½œè´Ÿè½½æŒç»­è°ƒä¼˜ Scorer æƒé‡
- ğŸš€ å¼€å‘è‡ªå®šä¹‰æ’ä»¶æ»¡è¶³ç‰¹å®šä¸šåŠ¡éœ€æ±‚

---

## ğŸ”— æ·±å…¥é˜…è¯»

- [**KV Cache Indexer**](../kv-cache-indexer/) - ä¸ºè°ƒåº¦å™¨æä¾›ç¼“å­˜å‘½ä¸­ç‡è¯„åˆ†
- [**llm-d å¹³å°æ¶æ„**](../../llm-d/) - Inference Scheduler åœ¨ llm-d ç”Ÿæ€ä¸­çš„å®šä½
- [**Gateway API Inference Extension**](https://github.com/kubernetes-sigs/gateway-api-inference-extension) - ä¸Šæ¸¸ GIE é¡¹ç›®

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [llm-d Inference Scheduler GitHub](https://github.com/llm-d/llm-d-inference-scheduler)
- [Architecture Documentation](https://github.com/llm-d/llm-d-inference-scheduler/blob/main/docs/architecture.md)
- [Plugin Development Guide](https://github.com/llm-d/llm-d-inference-scheduler/blob/main/docs/create_new_filter.md)
